{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Environmental Science Analysis","text":"<p>Fall 2024 | 16:375:501 Environmental Science Analysis Rutgers University, Department of Environmental Sciences</p>"},{"location":"#schedule","title":"Schedule","text":"Week topic Week 1 Course introduction Week 2 Introduction to environmental datasets, Install Python (Windows, Mac, Amarel) Week 3 Core Python Language Week 4 Scientific Computing with Python Week 5 Working with tabular data in Python Week 6 Correlation and regressions Week 7 Time series analysis Week 8 Environmental data visualization Week 9 Working with multi-dimensional data Week 10 Making maps Week 11 Spatial data analysis Week 12 Environmental science packages in Python Weeks 13 &amp; 14 Final Project"},{"location":"Schedule/","title":"Schedule","text":""},{"location":"Schedule/#schedule","title":"Schedule","text":"Week topic Week 1 Course introduction Week 2 Introduction to environmental datasets, Install Python (Windows, Mac, Amarel) Week 3 Core Python Language Week 4 Scientific Computing with Python Week 5 Working with tabular data in Python Week 6 Correlation and regressions Week 7 Time series analysis Week 8 Environmental data visualization Week 9 Spatial data analysis Week 10 Working with multi-dimensional data Week 11 Making maps Week 12 Reproducible research Week 13 Environmental science packages in Python Week 14 Final Project"},{"location":"Syllabus/","title":"Syllabus","text":""},{"location":"Syllabus/#part-1-course-information","title":"Part 1: Course Information","text":"<p>Class Time and Location: Online Asynchronous </p>"},{"location":"Syllabus/#instructor","title":"Instructor:","text":"<p>Xiaomeng Jin Department of Environmental Sciences Office: ENR 230 Email: xiaomeng.jin@rutgers.edu Office Hour: TBD</p>"},{"location":"Syllabus/#part-2-overview","title":"Part 2: Overview","text":"<p>This course will introduce data analysis techniques for applications in environmental sciences. The course will teach students scientific programming in Python, statistical analysis, visualization, spatial analysis techniques that are commonly used to process and interpret environmental datasets. The course is designed to be accessible for graduate and upper-level undergraduate students in environmental sciences or other related disciplines.  </p>"},{"location":"Syllabus/#part-3-course-structure","title":"Part 3: Course Structure","text":"<p>Format: This is an online asynchronous course, meaning that we do not \u2018meet\u2019, not even via the web. Therefore, you decide when to do the work. To prevent you from procrastinating too much, you will have an assignment due each week for the first 12 weeks. Your assignment each week is to follow the instructions to complete a Jupyter notebook. By the end of the semester, you should have a notebook collection that you can use as coding recipe for your final project and your future research/work.   Textbook: There is no required textbook. All materials will come from free online resources and the course website itself.  Computers: Students will have the option to use their laptop, Amarel (the university\u2019s high performance computing cluster), or Google\u2019s Colaboratory (https://colab.research.google.com) to work on their assignments and final project.  </p>"},{"location":"Syllabus/#part-4-grading-policy","title":"Part 4: Grading Policy","text":""},{"location":"Syllabus/#weekly-assignments-70","title":"Weekly Assignments (70%)","text":"<p>Type 1: Python Programming \u2022   Total: 100 \u2022   All questions complete: 50 \u2022   All questions correct: 30  \u2022   Clean, elegant, efficient code: rate between 0 and 10  \u2022   Clear comments and explanations: rate between 0 and 10 </p> <p>Type 2: Weekly Quiz  \u2022   Multiple choice or short answer questions</p> <p>Lowest grade on an assignment will be dropped. </p>"},{"location":"Syllabus/#final-project-30","title":"Final Project (30%)","text":"<p>The goal of the final project is to assess your ability to combine and apply the skills you have learned in class in the context of a real-world research problem. Our class has mostly focused on tools for environmental data analysis, so this must be the focus of your final project. Specifically, we seek to assess your ability to do the following tasks:  \u2022   Discover and download real datasets in standard formats (e.g. CSV, netCDF)  \u2022   Load the data into pandas or xarray, performing any necessary data cleanup (dealing with missing values, proper time encoding, etc.) along the way.  \u2022   Perform realistic scientific calculation involving, for example tasks such as data grouping, aggregating, correlation analysis, trend analysis.  \u2022   Visualize your results in well-formatted plots.   \u2022   Clearly document your analysis to make it reproducible.  \u2022   Publish your final project as a GitHub repository. </p>"},{"location":"Syllabus/#grading","title":"Grading","text":"<p>\u2022   Total: 100  \u2022   Data: 30  \u2022   Statistical analysis: 30  \u2022   Visualization: 20  \u2022   Clean, efficient, reproducible code: 20 </p>"},{"location":"Week_2_install_python_amarel/","title":"Install Mamba and Python: Amarel User","text":"<ul> <li> <p>Request Amarel Account from Rutgers Office of Advanced Computing</p> </li> <li> <p>Connect to Amarel Open OnDemand </p> </li> <li>Click Clusters </li> <li>Choose Amarel Cluster Shell Access </li> <li>Enter your password </li> <li> <p>In the terminal, do the following commands (one line each time). If you're using Windows, type 'Ctrl+c' to copy and 'Ctrl+Shift+v' to paste command. </p> </li> <li> <p>Install Miniforge using: </p> </li> </ul> <pre><code>wget \"https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-$(uname)-$(uname -m).sh\"\nbash Miniforge3-$(uname)-$(uname -m).sh\n</code></pre> <pre><code>    Agree license term: yes \n    Confirm install location: ENTER\n    Do you wish to update your shell profile to automatically initialize conda: yes\n</code></pre> <ul> <li>Close terminal window, and reopen a terminal window. Test if Mamba and Conda have been successfully installed</li> </ul> <pre><code>mamba\n</code></pre> <p>You should see</p> <pre><code>conda is a tool for managing and deploying applications, environments and packages. \n....\n</code></pre> <ul> <li>Create a new environment <code>esa_env</code>: </li> </ul> <pre><code>mamba create -n esa_env python=3.9 jupyter jupyterlab notebook numpy scipy ipython pandas matplotlib cartopy geopandas xarray dask netCDF4 seaborn statsmodels pooch\n</code></pre> <ul> <li> <p>Next, go back to Amarel Open OnDemand. This time, we will launch a personal jupyter. Click on 'Interactive Apps', choose 'Personal Jupyter'. </p> </li> <li> <p>Settings for Personal Jupyter: </p> </li> </ul> <pre><code>    Number of hours: 10 \n    Number of cores: 1 \n    Gigabytes of memory: 10 \n    Partition: main\n    Leave Reservation and slurm feature blank \n    conda path: /home/YOURNETID/miniforge3\n    conda environment: esa_env\n</code></pre> <ul> <li> <p>You should see Jupyter lab page automatically opened in your web browser. </p> </li> <li> <p>In the Jupyter Lab, go to File -&gt; Open from Path. Enter the path of your home folder: /home/YOURNETID/</p> </li> <li> <p>Once you're at your home folder, open a new Jupyter notebook by clicking the + sign. Choose Notebook. </p> </li> <li> <p>Rename the Notebook to be 'Lecture_2_Install_Python.ipynb'</p> </li> <li> <p>Enter the following code in the Notebook to test if you successfully installed all necessary packages:</p> </li> </ul> <pre><code>import xarray as xr\nimport pandas as pd\nimport geopandas as gpd\n</code></pre> <p>If no errors, enter the following to test the plotting functions:</p> <pre><code>ds = xr.tutorial.load_dataset(\"air_temperature\")\nds.air[0,:,:].plot()\n</code></pre> <p>-Download and submit this Notebook as your assignment. </p>"},{"location":"Week_2_install_python_mac/","title":"Install Mamba and Python: Mac User","text":"<ul> <li> <p>Open Terminal (Launchpad -&gt; Other -&gt; Terminal)</p> </li> <li> <p>Install Miniforge using: </p> </li> </ul> <pre><code>curl -L -O \"https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-$(uname)-$(uname -m).sh\"\nbash Miniforge3-$(uname)-$(uname -m).sh\n</code></pre> <ul> <li>Install Mamba on your laptop:</li> </ul> <pre><code>    Agree license term: yes \n    Confirm install location: ENTER\n    Do you wish to update your shell profile to automatically initialize conda: yes\n</code></pre> <ul> <li>Close terminal window, and reopen a terminal window. Test if Mamba and Conda have been successfully installed</li> </ul> <pre><code>mamba\n</code></pre> <p>You should see</p> <pre><code>conda is a tool for managing and deploying applications, environments and packages. \n....\n</code></pre> <ul> <li>In the terminal, create a new environment <code>esa_env</code>: </li> </ul> <pre><code>mamba create -n esa_env python=3.9 jupyter jupyterlab notebook numpy scipy ipython pandas matplotlib cartopy geopandas xarray dask netCDF4 seaborn statsmodels pooch\n</code></pre> <ul> <li>After it's finished, activate the environment: </li> </ul> <pre><code>mamba activate esa_env\n</code></pre> <ul> <li>Invoke Jupyter Lab: </li> </ul> <pre><code>jupyter lab\n</code></pre> <ul> <li> <p>You should see Jupyter lab page automatically opened in your web browser. If not, copy and paste one of the URLs listed to your web browser.</p> </li> <li> <p>In the Jupyter Lab, go to File -&gt; Open from Path. Enter the path of your course folder. </p> </li> <li> <p>If you don't know the folder path, find the folder in Finder, right click on the folder, press Option, and click Copy \"environmental_science_analysis\" as Pathname. </p> </li> <li> <p>Once you're at your course folder, open a new Jupyter notebook by clicking the + sign. Choose Notebook. </p> </li> <li> <p>Rename the Notebook to be 'Lecture_2_Install_Python.ipynb'</p> </li> <li> <p>Enter the following code in the Notebook to test if you successfully installed all necessary packages:</p> </li> </ul> <pre><code>import xarray as xr\nimport pandas as pd\nimport geopandas as gpd\n</code></pre> <p>If no errors, enter the following to test the plotting functions:</p> <pre><code>ds = xr.tutorial.load_dataset(\"air_temperature\")\nds.air[0,:,:].plot()\n</code></pre> <p>-Submit this Jupyter Notebook as your assignment. </p>"},{"location":"Week_2_install_python_windows/","title":"Install Mamba and Python: Windows User","text":"<ul> <li> <p>Go to Miniforge Website.</p> </li> <li> <p>Open Minoforge page, download and execute the Windows installer.</p> </li> <li> <p>When asked about the Installation Type: Choose 'Just Me'</p> </li> <li> <p>Follow the default settings for the Advanced Installation Option. </p> </li> <li> <p>After installing Miniforge, open the Miniforge Prompt </p> </li> <li> <p>Test if Mamba and Conda have been successfully installed by entering the following in Miniforge Prompt. </p> </li> </ul> <pre><code>mamba\n</code></pre> <p>You should see</p> <pre><code>conda is a tool for managing and deploying applications, environments and packages. \n....\n</code></pre> <ul> <li>In the terminal, create a new environment <code>esa_env</code>: </li> </ul> <pre><code>mamba create -n esa_env python=3.9 jupyter jupyterlab notebook numpy scipy ipython pandas matplotlib cartopy geopandas xarray dask netCDF4 seaborn statsmodels pooch\n</code></pre> <ul> <li>After it's finished, activate the environment: </li> </ul> <pre><code>mamba activate esa_env\n</code></pre> <ul> <li>Invoke Jupyter Lab and specify the directory (e.g., if your course folder is located at E disk, specify it as E:/): </li> </ul> <pre><code>jupyter lab --notebook-dir=E:/ \n</code></pre> <ul> <li> <p>You should see Jupyter lab page automatically opened in your web browser. If not, copy and paste one of the URLs listed to your web browser.</p> </li> <li> <p>In the Jupyter Lab, you should see the directory of the disk on the left. Browse through the content and enter your course folder by clicking on it. </p> </li> <li> <p>Once you're at your course folder, open a new Jupyter notebook by clicking the + sign. Choose Notebook. </p> </li> <li> <p>Rename the Notebook to be 'Lecture_2_Install_Python.ipynb'</p> </li> <li> <p>Enter the following code in the Notebook to test if you successfully installed all necessary packages:</p> </li> </ul> <pre><code>import xarray as xr\nimport pandas as pd\nimport geopandas as gpd\n</code></pre> <p>If no errors, enter the following to test the plotting functions:</p> <pre><code>ds = xr.tutorial.load_dataset(\"air_temperature\")\nds.air[0,:,:].plot()\n</code></pre> <p>-Submit this Jupyter Notebook as your assignment. </p>"},{"location":"Week_3_Core_Python/","title":"Week 3 Core Python Language","text":"In\u00a0[1]: Copied! <pre># comments are anything that comes after the \"#\" symbol\na = 1       # assign 1 to variable a\nb = \"hello\" # assign \"hello\" to variable b\n</pre> # comments are anything that comes after the \"#\" symbol a = 1       # assign 1 to variable a b = \"hello\" # assign \"hello\" to variable b <p>HintsThe following identifiers are used as reserved words, or keywords of the language, and cannot be used as ordinary identifiers. They must be spelled exactly as written here:</p> <pre><code>False      class      finally    is         return\nNone       continue   for        lambda     try\nTrue       def        from       nonlocal   while\nand        del        global     not        with\nas         elif       if         or         yield\nassert     else       import     pass\nbreak      except     in         raise</code></pre> <p>Additionally, the following a built in functions which are always available in your namespace once you open a python interpreter</p> <pre><code>abs() dict() help() min() setattr() all() dir() hex() next() slice() any()\ndivmod() id() object() sorted() ascii() enumerate() input() oct() staticmethod()\nbin() eval() int() open() str() bool() exec() isinstance() ord() sum() bytearray()\nfilter() issubclass() pow() super() bytes() float() iter() print() tuple()\ncallable() format() len() property() type() chr() frozenset() list() range()\nvars() classmethod() getattr() locals() repr() zip() compile() globals() map()\nreversed() __import__() complex() hasattr() max() round() delattr() hash()\nmemoryview() set()</code></pre> In\u00a0[2]: Copied! <pre># how to we see our variables?\nprint(a)\nprint(b)\nprint(a,b)\n</pre> # how to we see our variables? print(a) print(b) print(a,b) <pre>1\nhello\n1 hello\n</pre> <p>All variables are objects. Every object has a type (class). To find out what type your variables are</p> In\u00a0[3]: Copied! <pre># as a shortcut, iPython notebooks will automatically print whatever is on the last line\ntype(b)\n</pre> # as a shortcut, iPython notebooks will automatically print whatever is on the last line type(b) Out[3]: <pre>str</pre> In\u00a0[4]: Copied! <pre>type(a) is int\n</pre> type(a) is int Out[4]: <pre>True</pre> <p>Hints Different objects attributes and methods, which can be accessed via the syntax <code>variable.method</code></p> <p>IPython will autocomplete if you press <code>&lt;tab&gt;</code> to show you the methods available.</p> In\u00a0[5]: Copied! <pre># this returns the method itself\nb.capitalize\n</pre> # this returns the method itself b.capitalize Out[5]: <pre>&lt;function str.capitalize()&gt;</pre> In\u00a0[6]: Copied! <pre># this calls the method\nb.capitalize()\n# there are lots of other methods\n</pre> # this calls the method b.capitalize() # there are lots of other methods Out[6]: <pre>'Hello'</pre> In\u00a0[7]: Copied! <pre># binary operations act differently on different types of objects\nc = 'World'\nprint(b + c)\nprint(a + 2)\nprint(a + b)\n</pre> # binary operations act differently on different types of objects c = 'World' print(b + c) print(a + 2) print(a + b) <pre>helloWorld\n3\n</pre> <pre>\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[7], line 5\n      3 print(b + c)\n      4 print(a + 2)\n----&gt; 5 print(a + b)\n\nTypeError: unsupported operand type(s) for +: 'int' and 'str'</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[8]: Copied! <pre># addition / subtraction\n1+1-5\n</pre> # addition / subtraction 1+1-5 Out[8]: <pre>-3</pre> In\u00a0[9]: Copied! <pre># multiplication\n5 * 10\n</pre> # multiplication 5 * 10 Out[9]: <pre>50</pre> In\u00a0[10]: Copied! <pre># division\n1/2\n</pre> # division 1/2 Out[10]: <pre>0.5</pre> In\u00a0[11]: Copied! <pre># that was automatically converted to a float\ntype(1/2)\n</pre> # that was automatically converted to a float type(1/2) Out[11]: <pre>float</pre> In\u00a0[12]: Copied! <pre># exponentiation\n2**4\n</pre> # exponentiation 2**4 Out[12]: <pre>16</pre> In\u00a0[13]: Copied! <pre># rounding\nround(9/10)\n</pre> # rounding round(9/10) Out[13]: <pre>1</pre> In\u00a0[14]: Copied! <pre># built in complex number support\n(1+2j) / (3-4j)\n</pre> # built in complex number support (1+2j) / (3-4j) Out[14]: <pre>(-0.2+0.4j)</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[15]: Copied! <pre>True and True\n</pre> True and True Out[15]: <pre>True</pre> In\u00a0[16]: Copied! <pre>True and False\n</pre> True and False Out[16]: <pre>False</pre> In\u00a0[17]: Copied! <pre># logic\n\n(not True) or (not False)\n</pre> # logic  (not True) or (not False) Out[17]: <pre>True</pre> In\u00a0[18]: Copied! <pre>True or True\n</pre> True or True Out[18]: <pre>True</pre> In\u00a0[19]: Copied! <pre>x = 4\nx &lt; 5 and  x &lt; 10\n</pre> x = 4 x &lt; 5 and  x &lt; 10 Out[19]: <pre>True</pre> In\u00a0[20]: Copied! <pre>x = 4\nx &lt; 5 or x &lt; 4\n</pre> x = 4 x &lt; 5 or x &lt; 4 Out[20]: <pre>True</pre> In\u00a0[21]: Copied! <pre>x = 4\nx &lt; 5 and x &lt; 4\n</pre> x = 4 x &lt; 5 and x &lt; 4 Out[21]: <pre>False</pre> In\u00a0[22]: Copied! <pre>not(x &lt; 5 and x &lt; 10)\n</pre> not(x &lt; 5 and x &lt; 10) Out[22]: <pre>False</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[50]: Copied! <pre>x = 100\nif x &gt; 0:\n    print('Positive Number')\nelif x &lt; 0:\n    print('Negative Number')\nelse:\n    print ('Zero!')\n</pre> x = 100 if x &gt; 0:     print('Positive Number') elif x &lt; 0:     print('Negative Number') else:     print ('Zero!') <pre>Positive Number\n</pre> In\u00a0[51]: Copied! <pre># Blocks are closed by indentation level\nif x &gt; 0:\n    print('Positive Number')\n    if x &gt;= 100:\n        print('Huge number!')\n</pre> # Blocks are closed by indentation level if x &gt; 0:     print('Positive Number')     if x &gt;= 100:         print('Huge number!') <pre>Positive Number\nHuge number!\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[52]: Copied! <pre># make a loop \ncount = 0\nwhile count &lt; 10:\n    # bad way\n    # count = count + 1\n    # better way\n    count += 1\nprint(count)\n</pre> # make a loop  count = 0 while count &lt; 10:     # bad way     # count = count + 1     # better way     count += 1 print(count) <pre>10\n</pre> <p>Hint: Be careful with the conditions. Avoid defining an infinite loop.</p> In\u00a0[53]: Copied! <pre># use range\nfor i in range(5):\n    print(i)\n</pre> # use range for i in range(5):     print(i) <pre>0\n1\n2\n3\n4\n</pre> In\u00a0[54]: Copied! <pre># Reverse the order\nfor i in range(5,0,-1):\n    print(i)\n</pre> # Reverse the order for i in range(5,0,-1):     print(i) <pre>5\n4\n3\n2\n1\n</pre> <p>Important point: in python, we always count from 0!</p> In\u00a0[55]: Copied! <pre># what is range?\ntype(range)\n</pre> # what is range? type(range) Out[55]: <pre>type</pre> In\u00a0[56]: Copied! <pre>range?\n</pre> range? <pre>Init signature: range(self, /, *args, **kwargs)\nDocstring:     \nrange(stop) -&gt; range object\nrange(start, stop[, step]) -&gt; range object\n\nReturn an object that produces a sequence of integers from start (inclusive)\nto stop (exclusive) by step.  range(i, j) produces i, i+1, i+2, ..., j-1.\nstart defaults to 0, and stop is omitted!  range(4) produces 0, 1, 2, 3.\nThese are exactly the valid indices for a list of 4 elements.\nWhen step is given, it specifies the increment (or decrement).\nType:           type\nSubclasses:     </pre> In\u00a0[57]: Copied! <pre># iterate over a list we make up\nfor pet in ['dog', 'cat', 'fish']:\n    print(pet, len(pet))\n</pre> # iterate over a list we make up for pet in ['dog', 'cat', 'fish']:     print(pet, len(pet)) <pre>dog 3\ncat 3\nfish 4\n</pre> <p>What is the thing in brackets? A list! Lists are one of the core python data structures.</p> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[58]: Copied! <pre>l = ['dog', 'cat', 'fish']\ntype(l)\n</pre> l = ['dog', 'cat', 'fish'] type(l) Out[58]: <pre>list</pre> In\u00a0[37]: Copied! <pre># list have lots of methods\nl.sort()\nl\n</pre> # list have lots of methods l.sort() l Out[37]: <pre>['cat', 'dog', 'fish']</pre> In\u00a0[38]: Copied! <pre># we can convert a range to a list\nr = list(range(5))\nr\n</pre> # we can convert a range to a list r = list(range(5)) r Out[38]: <pre>[0, 1, 2, 3, 4]</pre> In\u00a0[39]: Copied! <pre>while r:\n    p = r.pop()\n    print('p:', p)\n    print('r:', r)\n</pre> while r:     p = r.pop()     print('p:', p)     print('r:', r) <pre>p: 4\nr: [0, 1, 2, 3]\np: 3\nr: [0, 1, 2]\np: 2\nr: [0, 1]\np: 1\nr: [0]\np: 0\nr: []\n</pre> <p>There are many different ways to interact with lists. Exploring them is part of the fun of python.</p> <p>list.append(x) Add an item to the end of the list. Equivalent to a[len(a):] = [x].</p> <p>list.extend(L) Extend the list by appending all the items in the given list. Equivalent to a[len(a):] = L.</p> <p>list.insert(i, x) Insert an item at a given position. The first argument is the index of the element before which to insert, so a.insert(0, x) inserts at the front of the list, and a.insert(len(a), x) is equivalent to a.append(x).</p> <p>list.remove(x) Remove the first item from the list whose value is x. It is an error if there is no such item.</p> <p>list.pop([i]) Remove the item at the given position in the list, and return it. If no index is specified, a.pop() removes and returns the last item in the list. (The square brackets around the i in the method signature denote that the parameter is optional, not that you should type square brackets at that position. You will see this notation frequently in the Python Library Reference.)</p> <p>list.clear() Remove all items from the list. Equivalent to del a[:].</p> <p>list.index(x) Return the index in the list of the first item whose value is x. It is an error if there is no such item.</p> <p>list.count(x) Return the number of times x appears in the list.</p> <p>list.sort() Sort the items of the list in place.</p> <p>list.reverse() Reverse the elements of the list in place.</p> <p>list.copy() Return a shallow copy of the list. Equivalent to a[:].</p> <p>Don't assume you know how list operations work!</p> In\u00a0[40]: Copied! <pre># \"add\" two lists\nx = list(range(5))\ny = list(range(10,15))\nz = x + y\nz\n</pre> # \"add\" two lists x = list(range(5)) y = list(range(10,15)) z = x + y z Out[40]: <pre>[0, 1, 2, 3, 4, 10, 11, 12, 13, 14]</pre> In\u00a0[41]: Copied! <pre># access items from a list\nprint('first', z[0])\nprint('last', z[-1])\nprint('first 3', z[:3])\nprint('last 3', z[-3:])\nprint('middle, skipping every other item', z[5:10:2])\n</pre> # access items from a list print('first', z[0]) print('last', z[-1]) print('first 3', z[:3]) print('last 3', z[-3:]) print('middle, skipping every other item', z[5:10:2]) <pre>first 0\nlast 14\nfirst 3 [0, 1, 2]\nlast 3 [12, 13, 14]\nmiddle, skipping every other item [10, 12, 14]\n</pre> <p>MEMORIZE THIS SYNTAX! It is central to so much of python and often proves confusing for users coming from other languages.</p> <p>In terms of set notation, python indexing is left inclusive, right exclusive. If you remember this, you will never go wrong.</p> In\u00a0[42]: Copied! <pre># that means we get an error from the following\nN = len(z)\nz[N]\n</pre> # that means we get an error from the following N = len(z) z[N] <pre>\n---------------------------------------------------------------------------\nIndexError                                Traceback (most recent call last)\nCell In[42], line 3\n      1 # that means we get an error from the following\n      2 N = len(z)\n----&gt; 3 z[N]\n\nIndexError: list index out of range</pre> In\u00a0[43]: Copied! <pre># this index notation also applies to strings\nname = 'Xiaomeng Jin'\nprint(name[:4])\n</pre> # this index notation also applies to strings name = 'Xiaomeng Jin' print(name[:4]) <pre>Xiao\n</pre> In\u00a0[44]: Copied! <pre>print(name[:-4])\n</pre> print(name[:-4]) <pre>Xiaomeng\n</pre> In\u00a0[45]: Copied! <pre>print(name[-3:])\n</pre> print(name[-3:]) <pre>Jin\n</pre> In\u00a0[46]: Copied! <pre># you can also test for the presence of items in a list\n5 in z\n</pre> # you can also test for the presence of items in a list 5 in z Out[46]: <pre>False</pre> <p>Lists are not meant for math! They don't have a datatype.</p> In\u00a0[47]: Copied! <pre>z[4] = 'fish'\nz\n</pre> z[4] = 'fish' z Out[47]: <pre>[0, 1, 2, 3, 'fish', 10, 11, 12, 13, 14]</pre> <p>Python is full of tricks for iterating and working with lists</p> In\u00a0[48]: Copied! <pre># a cool python trick: list comprehension\nsquares = [n**2 for n in range(5)]\nsquares\n</pre> # a cool python trick: list comprehension squares = [n**2 for n in range(5)] squares Out[48]: <pre>[0, 1, 4, 9, 16]</pre> In\u00a0[49]: Copied! <pre># iterate over two lists together uzing zip\nfor item1, item2 in zip(x,y):\n    print('first:', item1, 'second:', item2)\n</pre> # iterate over two lists together uzing zip for item1, item2 in zip(x,y):     print('first:', item1, 'second:', item2) <pre>first: 0 second: 10\nfirst: 1 second: 11\nfirst: 2 second: 12\nfirst: 3 second: 13\nfirst: 4 second: 14\n</pre> <p>Define a list from a range of values, check if an element exists in the list.</p> In\u00a0[\u00a0]: Copied! <pre>\n</pre> <p>In this problem, we will explore the basic data structures and flow controls of python by manually parsing a CSV file.</p> <p>Note that this is a futile exercise. In the \"real world\" you should never manually parse a CSV file. There are utilities out there that will do it for you much more quickly and efficiently. However, it is a useful exercise for learning python.</p> <p>Before starting the python part, use the JupyterLab file browser to browse to this file. Click to open it. What do you see?</p> <p>Now we will begin the process of reading the file with python</p> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> <p>It should be a familiar type we learned about in class.</p> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"Week_3_Core_Python/#week-3-core-python-language","title":"Week 3 Core Python Language\u00b6","text":"<p>Mostly copied from the official python tutorial</p>"},{"location":"Week_3_Core_Python/#1-invoking-python","title":"1. Invoking Python\u00b6","text":"<p>There are three main ways to use python.</p> <ol> <li>By running a python file, e.g. <code>python myscript.py</code></li> <li>Through an interactive console (python interpreter or ipython shell)</li> <li>In an interactive Jupyter Lab</li> </ol> <p>We will be using the Jupyter Lab.</p>"},{"location":"Week_3_Core_Python/#2-basic-variables-numbers-and-string","title":"2. Basic Variables: Numbers and String\u00b6","text":""},{"location":"Week_3_Core_Python/#exercise-2","title":"Exercise 2:\u00b6","text":"<p>Define a float variable d = 8. Print the type of the variable.</p>"},{"location":"Week_3_Core_Python/#3-math","title":"3. Math\u00b6","text":"<p>Basic arithmetic and boolean logic is part of the core python library.</p>"},{"location":"Week_3_Core_Python/#exercise-3","title":"Exercise 3:\u00b6","text":"<p>Let a = 2, b = 3.3, c = 2, calculate the following equation.</p> <p>$y = 6a^3 - \\frac{8b^2}{4c} + 11$</p>"},{"location":"Week_3_Core_Python/#4-logic","title":"4. Logic:\u00b6","text":"<p><code>and</code>: Returns True if both statements are true</p> <p><code>or</code>: Returns True if one of the statements is true</p> <p><code>not</code>: Reverse the result, returns False if the result is true</p>"},{"location":"Week_3_Core_Python/#exercise-4","title":"Exercise 4:\u00b6","text":"<p>For each of the following expressions, guess whether they evaluate to <code>True</code> or <code>False</code>. Then type them to check your answers.</p> <ol> <li>1&lt;=1</li> <li>1!=1</li> <li>123 == '123'</li> <li>1!=1 and 1&lt;=1</li> <li>1!=1 or 1&lt;=1</li> <li>'good' != 'bad'</li> </ol>"},{"location":"Week_3_Core_Python/#5-conditionals","title":"5. Conditionals\u00b6","text":"<p>Conditional statements are an essential part of programming in Python. They allow you to make decisions based on the values of variables or the result of comparisons.</p> <p>Hint: In Python, indentation is MANDATORY. Blocks are closed by indentation level.</p>"},{"location":"Week_3_Core_Python/#exercise-5","title":"Exercise 5:\u00b6","text":"<p>Given a number <code>x</code>, print if it is an odd or even number.</p>"},{"location":"Week_3_Core_Python/#6-loop","title":"6 Loop\u00b6","text":"<p>A loop is an instruction that repeats multiple times as long as some condition is met. Loops are useful for iterating over sequences (like lists, strings, or ranges) or performing a task multiple times.</p>"},{"location":"Week_3_Core_Python/#while-loop","title":"while loop\u00b6","text":"<p>A while loop repeatedly executes a block of code as long as a specified condition is True.</p>"},{"location":"Week_3_Core_Python/#for-loop","title":"for loop\u00b6","text":"<p>A for loop is used to iterate over a sequence (such as a list, tuple, string, or range) and execute a block of code for each item in that sequence.</p>"},{"location":"Week_3_Core_Python/#exercise","title":"Exercise:\u00b6","text":"<p>Create a loop from 100 to 1, if odd number, print 'odd' and the number, or print 'even' and the number.</p>"},{"location":"Week_3_Core_Python/#7-lists","title":"7. Lists\u00b6","text":"<p>In Python, a list is a built-in data type that allows you to store an ordered collection of items. These items can be of any data type, including integers, strings, floating-point numbers, or even other lists. Lists are mutable, meaning that you can change their content after they've been created (e.g., by adding, removing, or modifying elements).</p>"},{"location":"Week_3_Core_Python/#exercise-7","title":"Exercise 7:\u00b6","text":""},{"location":"Week_3_Core_Python/#8-assignment-python-lists-and-loops","title":"8. Assignment:  Python Lists and Loops\u00b6","text":""},{"location":"Week_3_Core_Python/#81-open-the-file-using-the-open-function","title":"8.1 Open the file using the <code>open</code> function\u00b6","text":"<p>Specifically, run the command</p> <pre><code>file = open('esa_roster_fall_2024.csv')</code></pre>"},{"location":"Week_3_Core_Python/#82-use-the-help-function-to-get-the-documentation-for-your-new-variable-file","title":"8.2 Use the <code>help</code> function to get the documentation for your new variable <code>file</code>\u00b6","text":"<p>This will produce a long list of methods you can use with <code>file</code>.</p>"},{"location":"Week_3_Core_Python/#83-read-the-lines-of-the-file-into-a-variable-called-lines","title":"8.3 Read the lines of the file into a variable called <code>lines</code>\u00b6","text":"<p>Hint: use the documentation above to find the method that sounds most likely to do what you want.</p>"},{"location":"Week_3_Core_Python/#84-display-lines-at-the-end-of-a-cell-in-order-to-see-its-contents","title":"8.4 Display <code>lines</code> at the end of a cell in order to see its contents\u00b6","text":""},{"location":"Week_3_Core_Python/#85-display-the-number-of-students-in-class","title":"8.5 Display the number of students in class\u00b6","text":""},{"location":"Week_3_Core_Python/#86-use-slicing-to-display-the-first-three-items-of-the-list-and-the-last-3","title":"8.6 Use slicing to display the first three items of the list. And the last 3\u00b6","text":""},{"location":"Week_3_Core_Python/#87-now-iterate-through-lines-and-print-the-item-if-it-contains-your-netid","title":"8.7 Now iterate through <code>lines</code> and <code>print</code> the item if it contains your NetID\u00b6","text":""},{"location":"Week_4_Numpy/","title":"Week 4: Scientific Computing in Python","text":"In\u00a0[1]: Copied! <pre>import numpy as np\n</pre> import numpy as np In\u00a0[4]: Copied! <pre># find out what version we have\nnp.__version__\n</pre> # find out what version we have np.__version__ Out[4]: <pre>'2.0.0'</pre> In\u00a0[\u00a0]: Copied! <pre># find out what is in our namespace\ndir()\n</pre> # find out what is in our namespace dir() In\u00a0[\u00a0]: Copied! <pre># find out what's in numpy\ndir(np)\n</pre> # find out what's in numpy dir(np) <p>The numpy documentation is crucial!</p> <p>http://docs.scipy.org/doc/numpy/reference/</p> In\u00a0[14]: Copied! <pre>from IPython.display import Image\nImage(url='http://docs.scipy.org/doc/numpy/_images/threefundamental.png')\n</pre> from IPython.display import Image Image(url='http://docs.scipy.org/doc/numpy/_images/threefundamental.png') Out[14]: In\u00a0[7]: Copied! <pre># create an array from a list\na = np.array([9,0,2,1,0])\n</pre> # create an array from a list a = np.array([9,0,2,1,0]) In\u00a0[8]: Copied! <pre># find out the datatype\na.dtype\n</pre> # find out the datatype a.dtype Out[8]: <pre>dtype('int64')</pre> In\u00a0[9]: Copied! <pre># find out the shape\na.shape\n</pre> # find out the shape a.shape Out[9]: <pre>(5,)</pre> In\u00a0[10]: Copied! <pre># what is the shape\ntype(a.shape)\n</pre> # what is the shape type(a.shape) Out[10]: <pre>tuple</pre> In\u00a0[11]: Copied! <pre># another array with a different datatype and shape\nb = np.array([[5,3,1,9],[9,2,3,0]], dtype=np.float64)\n</pre> # another array with a different datatype and shape b = np.array([[5,3,1,9],[9,2,3,0]], dtype=np.float64) In\u00a0[12]: Copied! <pre># array with 3 rows x 4 columns\na_2d = np.array([[3,2,0,1],[9,1,8,7],[4,0,1,6]]) \na_2d\n</pre> # array with 3 rows x 4 columns a_2d = np.array([[3,2,0,1],[9,1,8,7],[4,0,1,6]])  a_2d Out[12]: <pre>array([[3, 2, 0, 1],\n       [9, 1, 8, 7],\n       [4, 0, 1, 6]])</pre> In\u00a0[13]: Copied! <pre># check dtype and shape\nb.dtype, b.shape\n</pre> # check dtype and shape b.dtype, b.shape Out[13]: <pre>(dtype('float64'), (2, 4))</pre> <p>Important Concept: The fastest varying dimension is the last dimension! The outer level of the hierarchy is the first dimension. (This is called \"c-style\" indexing)</p> In\u00a0[73]: Copied! <pre># create some uniform arrays\nc = np.zeros((9,9))\nd = np.ones((3,6,3), dtype=np.complex128)\ne = np.full((3,3), np.pi)\ne = np.ones_like(c)\nf = np.zeros_like(d)\n# Random arrays\ng = np.random.rand(3,4)\n</pre> # create some uniform arrays c = np.zeros((9,9)) d = np.ones((3,6,3), dtype=np.complex128) e = np.full((3,3), np.pi) e = np.ones_like(c) f = np.zeros_like(d) # Random arrays g = np.random.rand(3,4) <p>The <code>np.arange()</code> function is used to generate an array with evenly spaced values within a given interval. <code>np.arange()</code> can be used with one, two, or three parameters to specify the start, stop, and step values. If only one value is passed to the function, it will be interpreted as the stop value:</p> In\u00a0[16]: Copied! <pre># create some ranges\nnp.arange(10)\n</pre> # create some ranges np.arange(10) Out[16]: <pre>array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])</pre> In\u00a0[17]: Copied! <pre># arange is left inclusive, right exclusive\nnp.arange(2,4,0.25)\n</pre> # arange is left inclusive, right exclusive np.arange(2,4,0.25) Out[17]: <pre>array([2.  , 2.25, 2.5 , 2.75, 3.  , 3.25, 3.5 , 3.75])</pre> <p>Similarly, the <code>np.linspace()</code> function is used to construct an array with evenly spaced numbers over a given interval. However, instead of the step parameter, <code>np.linspace()</code> takes a num parameter to specify the number of samples within the given interval:</p> In\u00a0[18]: Copied! <pre># linearly spaced\nnp.linspace(2,4,20)\n</pre> # linearly spaced np.linspace(2,4,20) Out[18]: <pre>array([2.        , 2.10526316, 2.21052632, 2.31578947, 2.42105263,\n       2.52631579, 2.63157895, 2.73684211, 2.84210526, 2.94736842,\n       3.05263158, 3.15789474, 3.26315789, 3.36842105, 3.47368421,\n       3.57894737, 3.68421053, 3.78947368, 3.89473684, 4.        ])</pre> <p>Note that unlike <code>np.arange()</code>, <code>np.linspace()</code> includes the stop value by default (this can be changed by passing <code>endpoint=True</code>). Finally, it should be noted that while we could have used <code>np.arange()</code> to generate the same array in the above example, it is recommended to use <code>np.linspace()</code> when a non-integer step (e.g. 0.25) is desired.</p> In\u00a0[19]: Copied! <pre>np.linspace(2,4,20, endpoint = False)\n</pre> np.linspace(2,4,20, endpoint = False) Out[19]: <pre>array([2. , 2.1, 2.2, 2.3, 2.4, 2.5, 2.6, 2.7, 2.8, 2.9, 3. , 3.1, 3.2,\n       3.3, 3.4, 3.5, 3.6, 3.7, 3.8, 3.9])</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[20]: Copied! <pre>x = np.linspace(-4, 4, 9)\nx\n</pre> x = np.linspace(-4, 4, 9) x Out[20]: <pre>array([-4., -3., -2., -1.,  0.,  1.,  2.,  3.,  4.])</pre> In\u00a0[21]: Copied! <pre>y = np.linspace(-5, 5, 11)\ny\n</pre> y = np.linspace(-5, 5, 11) y Out[21]: <pre>array([-5., -4., -3., -2., -1.,  0.,  1.,  2.,  3.,  4.,  5.])</pre> In\u00a0[22]: Copied! <pre>x_2d, y_2d = np.meshgrid(x, y)\n</pre>   x_2d, y_2d = np.meshgrid(x, y) In\u00a0[23]: Copied! <pre>x_2d\n</pre> x_2d Out[23]: <pre>array([[-4., -3., -2., -1.,  0.,  1.,  2.,  3.,  4.],\n       [-4., -3., -2., -1.,  0.,  1.,  2.,  3.,  4.],\n       [-4., -3., -2., -1.,  0.,  1.,  2.,  3.,  4.],\n       [-4., -3., -2., -1.,  0.,  1.,  2.,  3.,  4.],\n       [-4., -3., -2., -1.,  0.,  1.,  2.,  3.,  4.],\n       [-4., -3., -2., -1.,  0.,  1.,  2.,  3.,  4.],\n       [-4., -3., -2., -1.,  0.,  1.,  2.,  3.,  4.],\n       [-4., -3., -2., -1.,  0.,  1.,  2.,  3.,  4.],\n       [-4., -3., -2., -1.,  0.,  1.,  2.,  3.,  4.],\n       [-4., -3., -2., -1.,  0.,  1.,  2.,  3.,  4.],\n       [-4., -3., -2., -1.,  0.,  1.,  2.,  3.,  4.]])</pre> In\u00a0[24]: Copied! <pre>y_2d\n</pre> y_2d Out[24]: <pre>array([[-5., -5., -5., -5., -5., -5., -5., -5., -5.],\n       [-4., -4., -4., -4., -4., -4., -4., -4., -4.],\n       [-3., -3., -3., -3., -3., -3., -3., -3., -3.],\n       [-2., -2., -2., -2., -2., -2., -2., -2., -2.],\n       [-1., -1., -1., -1., -1., -1., -1., -1., -1.],\n       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n       [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n       [ 2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.],\n       [ 3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.],\n       [ 4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.],\n       [ 5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.]])</pre> In\u00a0[25]: Copied! <pre># get some individual elements of xx\nx_2d[0,0], x_2d[-1,-1], x_2d[3,-5]\n</pre> # get some individual elements of xx x_2d[0,0], x_2d[-1,-1], x_2d[3,-5] Out[25]: <pre>(np.float64(-4.0), np.float64(4.0), np.float64(0.0))</pre> In\u00a0[26]: Copied! <pre># get some whole rows and columns\nx_2d[0].shape, x_2d[:,-1].shape\n</pre> # get some whole rows and columns x_2d[0].shape, x_2d[:,-1].shape Out[26]: <pre>((9,), (11,))</pre> In\u00a0[27]: Copied! <pre># get some ranges\nx_2d[3:10,3:5].shape\n</pre> # get some ranges x_2d[3:10,3:5].shape Out[27]: <pre>(7, 2)</pre> <p>There are many advanced ways to index arrays. You can read about them in the manual. Here is one example.</p> In\u00a0[28]: Copied! <pre># use a boolean array as an index\nidx = x_2d&lt;0\nx_2d[idx].shape\n</pre> # use a boolean array as an index idx = x_2d&lt;0 x_2d[idx].shape Out[28]: <pre>(44,)</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[32]: Copied! <pre># two dimensional grids\nx = np.linspace(-2*np.pi, 2*np.pi, 100)\ny = np.linspace(-np.pi, np.pi, 50)\nxx, yy = np.meshgrid(x, y)\nxx.shape, yy.shape\n</pre> # two dimensional grids x = np.linspace(-2*np.pi, 2*np.pi, 100) y = np.linspace(-np.pi, np.pi, 50) xx, yy = np.meshgrid(x, y) xx.shape, yy.shape Out[32]: <pre>((50, 100), (50, 100))</pre> In\u00a0[33]: Copied! <pre>f = np.sin(xx) * np.cos(0.5*yy)\n</pre> f = np.sin(xx) * np.cos(0.5*yy) In\u00a0[34]: Copied! <pre>from matplotlib import pyplot as plt\n</pre> from matplotlib import pyplot as plt In\u00a0[35]: Copied! <pre>plt.pcolormesh(f)\n</pre> plt.pcolormesh(f) Out[35]: <pre>&lt;matplotlib.collections.QuadMesh at 0x117fdee80&gt;</pre> In\u00a0[36]: Copied! <pre># transpose\nplt.pcolormesh(f.T)\n</pre> # transpose plt.pcolormesh(f.T) Out[36]: <pre>&lt;matplotlib.collections.QuadMesh at 0x12624e400&gt;</pre> In\u00a0[37]: Copied! <pre>f.shape\n</pre> f.shape Out[37]: <pre>(50, 100)</pre> In\u00a0[38]: Copied! <pre>np.tile(f,(6,1)).shape\n</pre> np.tile(f,(6,1)).shape Out[38]: <pre>(300, 100)</pre> In\u00a0[39]: Copied! <pre># tile an array\nplt.pcolormesh(np.tile(f,(6,1)))\n</pre> # tile an array plt.pcolormesh(np.tile(f,(6,1))) Out[39]: <pre>&lt;matplotlib.collections.QuadMesh at 0x1262bbeb0&gt;</pre> In\u00a0[44]: Copied! <pre>from IPython.display import Image\nImage(url='http://scipy-lectures.github.io/_images/numpy_broadcasting.png',\n     width=720)\n</pre> from IPython.display import Image Image(url='http://scipy-lectures.github.io/_images/numpy_broadcasting.png',      width=720) Out[44]: In\u00a0[45]: Copied! <pre># multiply f by x\nprint(f.shape, x.shape)\ng = f * x\nprint(g.shape)\n</pre> # multiply f by x print(f.shape, x.shape) g = f * x print(g.shape) <pre>(50, 100) (100,)\n(50, 100)\n</pre> In\u00a0[46]: Copied! <pre># multiply f by y\nprint(f.shape, y.shape)\nh = f * y\nprint(h.shape)\n</pre> # multiply f by y print(f.shape, y.shape) h = f * y print(h.shape) <pre>(50, 100) (50,)\n</pre> <pre>\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\nCell In[46], line 3\n      1 # multiply f by y\n      2 print(f.shape, y.shape)\n----&gt; 3 h = f * y\n      4 print(h.shape)\n\nValueError: operands could not be broadcast together with shapes (50,100) (50,) </pre> In\u00a0[69]: Copied! <pre># use newaxis special syntax\ny_new = y[:,np.newaxis]\nh = f * y_new\nprint(h.shape)\n</pre> # use newaxis special syntax y_new = y[:,np.newaxis] h = f * y_new print(h.shape) <pre>(50, 100)\n</pre> In\u00a0[48]: Copied! <pre># sum\ng.sum()\n</pre> # sum g.sum() Out[48]: <pre>np.float64(-3083.038387807155)</pre> In\u00a0[49]: Copied! <pre># mean\ng.mean()\n</pre> # mean g.mean() Out[49]: <pre>np.float64(-0.616607677561431)</pre> In\u00a0[50]: Copied! <pre># std\ng.std()\n</pre> # std g.std() Out[50]: <pre>np.float64(1.6402280119141424)</pre> In\u00a0[51]: Copied! <pre># apply on just one axis\n\n# Mean of each row (calculated across columns)\ng_xmean = g.mean(axis=1)\n\n# Mean of each column (calculated across rows)\n\ng_ymean = g.mean(axis=0)\n</pre> # apply on just one axis  # Mean of each row (calculated across columns) g_xmean = g.mean(axis=1)  # Mean of each column (calculated across rows)  g_ymean = g.mean(axis=0) In\u00a0[52]: Copied! <pre>plt.plot(x, g_ymean)\n</pre> plt.plot(x, g_ymean) Out[52]: <pre>[&lt;matplotlib.lines.Line2D at 0x1265e17f0&gt;]</pre> In\u00a0[53]: Copied! <pre>plt.plot(g_xmean, y)\n</pre> plt.plot(g_xmean, y) Out[53]: <pre>[&lt;matplotlib.lines.Line2D at 0x1266d3eb0&gt;]</pre> <p>Most real-world datasets \u2013 environmental or otherwise \u2013 have data gaps. Data can be missing for any number of reasons, including observations not being recorded or data corruption. While a cell corresponding to a data gap may just be left blank in a spreadsheet, when imported into Python, there must be some way to handle \"blank\" or missing values.</p> <p>Missing data should not be replaced with zeros, as 0 can be a valid value for many datasets, (e.g. temperature, precipitation, etc.). Instead, the convention is to fill all missing data with the constant NaN. NaN stands for \"Not a Number\" and is implemented in NumPy as np.nan.</p> <p>NaNs are handled differently by different packages. In NumPy, all computations involving NaN values will return nan:</p> In\u00a0[70]: Copied! <pre>data = np.array([[2.,2.7,1.89],\n                 [1.1, 0.0, np.nan],\n                 [3.2, 0.74, 2.1]])\n</pre> data = np.array([[2.,2.7,1.89],                  [1.1, 0.0, np.nan],                  [3.2, 0.74, 2.1]]) In\u00a0[71]: Copied! <pre>np.mean(data)\n</pre> np.mean(data) Out[71]: <pre>np.float64(nan)</pre> In\u00a0[72]: Copied! <pre>np.nanmean(data)\n</pre> np.nanmean(data) Out[72]: <pre>np.float64(1.71625)</pre> <p>First import numpy and matplotlib</p> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"Week_4_Numpy/#week-4-scientific-computing-in-python","title":"Week 4: Scientific Computing in Python\u00b6","text":"<p>This week, you will learn how to do scientific computing in Python. As we learned from first lecture, Numpy is a fundamental package for scientific computing.</p> <p>The goal of this assignment is to gain comfort creating, visualizating, and computing with numpy array. By the end of the assignment, you should feel comfortable:</p> <ul> <li>Creating new Numpy arrays using <code>linspace</code> and <code>arange</code></li> <li>Computing basic formulas with Numpy arrays</li> <li>Performing reductions (e.g. <code>mean</code>, <code>std</code> on numpy arrays)</li> <li>Making 1D line plots</li> </ul>"},{"location":"Week_4_Numpy/#1-importing-and-examining-a-new-package","title":"1. Importing and Examining a New Package\u00b6","text":"<p>This will be our first experience with importing a package which is not part of the Python standard library.</p>"},{"location":"Week_4_Numpy/#2-ndarrays","title":"2. NDArrays\u00b6","text":"<p>The core class is the numpy ndarray (n-dimensional array). The n-dimensional array object in NumPy is referred to as an ndarray, a multidimensional container of homogeneous items \u2013 i.e. all values in the array are the same type and size. These arrays can be one-dimensional (one row or column vector), two-dimensional (m rows x n columns), or three-dimensional (arrays within arrays).</p> <p>The main difference between a numpy array an a more general data container such as <code>list</code> are the following:</p> <ul> <li>Numpy arrays can have multiple dimensions (while lists, tuples, etc. only have 1)</li> <li>Numpy arrays hold values of the same datatype (e.g. <code>int</code>, <code>float</code>), while <code>lists</code> can contain anything.</li> <li>Numpy optimizes numerical operations on arrays. Numpy is fast!</li> </ul>"},{"location":"Week_4_Numpy/#21-create-array-from-a-list","title":"2.1 Create array from a list\u00b6","text":""},{"location":"Week_4_Numpy/#22-create-arrays-using-functions","title":"2.2 Create arrays using functions\u00b6","text":""},{"location":"Week_4_Numpy/#exercise-1-create-a-1d-array-ranging-from-0-to-100-including-100-with-an-interval-of-5","title":"Exercise 1: Create a 1D array ranging from 0 to 100 (including 100) with an interval of 5.\u00b6","text":""},{"location":"Week_4_Numpy/#23-create-two-dimensional-grids","title":"2.3 Create two-dimensional grids\u00b6","text":""},{"location":"Week_4_Numpy/#exercise-3-explain-what-the-meshgrid-function-does-what-is-the-difference-between-x_2d-and-y_2d","title":"Exercise 3: Explain what the meshgrid function does. What is the difference between <code>x_2d</code> and <code>y_2d</code>?\u00b6","text":""},{"location":"Week_4_Numpy/#3-indexing-in-numpy","title":"3. Indexing in Numpy\u00b6","text":"<p>Indexing in NumPy allows you to access and modify elements, rows, columns, or subarrays of an array. Basic indexing is similar to lists.</p>"},{"location":"Week_4_Numpy/#exercise-4-get-the-last-two-columns-of-y_2d-array","title":"Exercise 4: Get the last two columns of <code>y_2d</code> array.\u00b6","text":""},{"location":"Week_4_Numpy/#4-array-operations","title":"4. Array Operations\u00b6","text":"<p>There are a huge number of operations available on arrays. All the familiar arithemtic operators are applied on an element-by-element basis.</p>"},{"location":"Week_4_Numpy/#41-basic-math","title":"4.1 Basic Math\u00b6","text":""},{"location":"Week_4_Numpy/#visualizing-arrays-with-matplotlib","title":"Visualizing Arrays with Matplotlib\u00b6","text":"<p>It can be hard to work with big arrays without actually seeing anything with our eyes! We will now bring in Matplotib to start visualizating these arrays. For now we will just skim the surface of Matplotlib. Much more depth will be provided in the next chapter.</p>"},{"location":"Week_4_Numpy/#42-manipulating-array-dimensions","title":"4.2 Manipulating array dimensions\u00b6","text":""},{"location":"Week_4_Numpy/#43-broadcasting","title":"4.3 Broadcasting\u00b6","text":"<p>Broadcasting is an efficient way to multiply arrays of different sizes</p>"},{"location":"Week_4_Numpy/#exercise-5-what-is-the-difference-between-y-and-y_new-why-f-y-gives-an-error-but-f-y_new-doesnt","title":"Exercise 5: What is the difference between y and y_new? Why <code>f * y</code> gives an error, but <code>f * y_new</code> doesn't?\u00b6","text":""},{"location":"Week_4_Numpy/#44-reduction-operations","title":"4.4 Reduction Operations\u00b6","text":""},{"location":"Week_4_Numpy/#5-missing-data","title":"5. Missing data\u00b6","text":""},{"location":"Week_4_Numpy/#6-assignment","title":"6. Assignment\u00b6","text":""},{"location":"Week_4_Numpy/#61-create-two-2d-arrays-representing-coordinates-x-y","title":"6.1. Create two 2D arrays representing coordinates x, y\u00b6","text":"<p>Both should cover the range (-2, 2) and have 100 points in each direction</p>"},{"location":"Week_4_Numpy/#62-visualize-each-2d-array-using-pcolormesh","title":"6.2. Visualize each 2D array using <code>pcolormesh</code>\u00b6","text":"<p>Use the correct coordiantes for the x and y axes.</p>"},{"location":"Week_4_Numpy/#63-from-your-cartesian-coordinates-create-polar-coordinates-r-and-varphi","title":"6.3 From your cartesian coordinates, create polar coordinates $r$ and $\\varphi$:\u00b6","text":"<p>$r = \\sqrt{x^2 + y^2}$</p> <p>$\\varphi = atan2(y,x)$</p> <p>You will need to use numpy's <code>arctan2</code> function. Read its documentation.</p>"},{"location":"Week_4_Numpy/#64-visualize-r-and-varphi-on-the-2d-x-y-plane-using-pcolormesh","title":"6.4. Visualize $r$ and $\\varphi$ on the 2D  $x$ / $y$ plane using <code>pcolormesh</code>\u00b6","text":""},{"location":"Week_4_Numpy/#65-caclulate-the-quanity-f-cos24r-sin24varphi","title":"6.5 Caclulate the quanity $f = \\cos^2(4r) + \\sin^2(4\\varphi)$\u00b6","text":"<p>And plot it on the $x$ / $y$ plane</p>"},{"location":"Week_4_Numpy/#66-plot-the-mean-of-f-with-respect-to-the-x-axis","title":"6.6 Plot the mean of f with respect to the x axis\u00b6","text":"<p>as a function of y</p>"},{"location":"Week_4_Numpy/#67-plot-the-mean-of-f-with-respect-to-the-y-axis","title":"6.7 Plot the mean of f with respect to the y axis\u00b6","text":"<p>as a function of x</p>"},{"location":"Week_5_Pandas_Basics/","title":"Week 5: Working with Tabular Data in Python with Pandas","text":"<p>This week, you will learn how to work with tabular data in Python.</p> <p>Pandas is a an open source library providing high-performance, easy-to-use data structures and data analysis tools. Pandas is particularly suited to the analysis of tabular data, i.e. data that can can go into a table. In other words, if you can imagine the data in an Excel spreadsheet, then Pandas is the tool for the job.</p> <p>A recent analysis of questions from Stack Overflow showed that python is the fastest growing and most widely used programming language in the world (in developed countries).</p> <p>A follow-up analysis showed that this growth is driven by the data science packages such as numpy, matplotlib, and especially pandas.</p> <p>The exponential growth of pandas is due to the fact that it just works. It saves you time and helps you do science more efficiently and effictively.</p> <p>Let's start by importing pandas library.</p> In\u00a0[1]: Copied! <pre>import pandas as pd\nimport numpy as np\n</pre> import pandas as pd import numpy as np In\u00a0[4]: Copied! <pre>from IPython.display import Image\nImage(url='https://storage.googleapis.com/lds-media/images/series-and-dataframe.width-1200.png')\n</pre> from IPython.display import Image Image(url='https://storage.googleapis.com/lds-media/images/series-and-dataframe.width-1200.png') Out[4]: In\u00a0[5]: Copied! <pre>s = pd.Series([1, 3, 5, np.nan, 6, 8])\n</pre> s = pd.Series([1, 3, 5, np.nan, 6, 8]) In\u00a0[7]: Copied! <pre>s\n</pre> s Out[7]: <pre>0    1.0\n1    3.0\n2    5.0\n3    NaN\n4    6.0\n5    8.0\ndtype: float64</pre> <p>By default, Pandas creates a default RangeIndex starting from 0.</p> <p>Creating a Series by passing values and indices.</p> In\u00a0[9]: Copied! <pre>s = pd.Series([1, 3, 5, np.nan, 6, 8], index = ['A','B','C','D','E','F'])\ns\n</pre> s = pd.Series([1, 3, 5, np.nan, 6, 8], index = ['A','B','C','D','E','F']) s Out[9]: <pre>A    1.0\nB    3.0\nC    5.0\nD    NaN\nE    6.0\nF    8.0\ndtype: float64</pre> <p>Pandas has plotting functions that can easily visualize the data.</p> In\u00a0[11]: Copied! <pre>s.plot(kind = 'bar')\n</pre> s.plot(kind = 'bar') Out[11]: <pre>&lt;Axes: &gt;</pre> <p>Arithmetic operations and most numpy function can be applied to Series.</p> <p>An important point is that the Series keep their index during such operations.</p> In\u00a0[12]: Copied! <pre>np.sqrt(s)\n</pre> np.sqrt(s) Out[12]: <pre>A    1.000000\nB    1.732051\nC    2.236068\nD         NaN\nE    2.449490\nF    2.828427\ndtype: float64</pre> <p>We can also access the underlying index object if we need to:</p> In\u00a0[13]: Copied! <pre>s.index\n</pre> s.index Out[13]: <pre>Index(['A', 'B', 'C', 'D', 'E', 'F'], dtype='object')</pre> <p>We can get values back out using the index via the .loc attribute</p> In\u00a0[14]: Copied! <pre>s.loc['A']\n</pre> s.loc['A'] Out[14]: <pre>1.0</pre> <p>Or by raw position using .iloc:</p> In\u00a0[15]: Copied! <pre>s.iloc[0]\n</pre> s.iloc[0] Out[15]: <pre>1.0</pre> <p>We can pass a list or array to loc to get multiple rows back:</p> In\u00a0[21]: Copied! <pre>s.loc[['A','C']]\n</pre> s.loc[['A','C']] Out[21]: <pre>A    1.0\nC    5.0\ndtype: float64</pre> <p>We can also use the slice notation:</p> In\u00a0[20]: Copied! <pre>s.loc['A':'C']\n</pre> s.loc['A':'C']  Out[20]: <pre>A    1.0\nC    5.0\ndtype: float64</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[61]: Copied! <pre># Data: AQI levels and temperature in different cities\ndata = {\n    \"AQI\": [55, 75, 60, 80, np.NaN],\n    \"Temperature\": [68, 75, 64, 80, 85]\n}\n\n# Creating the DataFrame\ndf = pd.DataFrame(data, index = [\"New York\", \"Los Angeles\", \"Chicago\", \"Houston\", \"Phoenix\"])\n</pre> # Data: AQI levels and temperature in different cities data = {     \"AQI\": [55, 75, 60, 80, np.NaN],     \"Temperature\": [68, 75, 64, 80, 85] }  # Creating the DataFrame df = pd.DataFrame(data, index = [\"New York\", \"Los Angeles\", \"Chicago\", \"Houston\", \"Phoenix\"])  In\u00a0[62]: Copied! <pre>df\n</pre> df Out[62]: AQI Temperature New York 55.0 68 Los Angeles 75.0 75 Chicago 60.0 64 Houston 80.0 80 Phoenix NaN 85 In\u00a0[63]: Copied! <pre># You can set the style of the table\ndf.style.highlight_max()\n</pre> # You can set the style of the table df.style.highlight_max() Out[63]: AQI Temperature New York 55.000000 68 Los Angeles 75.000000 75 Chicago 60.000000 64 Houston 80.000000 80 Phoenix nan 85 <p>You may notice that Pandas handles missing data very elegantly, keeping track of it through all calculations.</p> <p>We can get a single column as a Series using python's getitem syntax on the DataFrame object.</p> In\u00a0[64]: Copied! <pre>df['AQI']\n</pre> df['AQI'] Out[64]: <pre>New York       55.0\nLos Angeles    75.0\nChicago        60.0\nHouston        80.0\nPhoenix         NaN\nName: AQI, dtype: float64</pre> <p>...or using attribute syntax.</p> In\u00a0[65]: Copied! <pre>df.AQI\n</pre> df.AQI Out[65]: <pre>New York       55.0\nLos Angeles    75.0\nChicago        60.0\nHouston        80.0\nPhoenix         NaN\nName: AQI, dtype: float64</pre> <p>If you want to get a specific row, use .loc</p> In\u00a0[66]: Copied! <pre>df.loc['New York']\n</pre> df.loc['New York'] Out[66]: <pre>AQI            55.0\nTemperature    68.0\nName: New York, dtype: float64</pre> In\u00a0[67]: Copied! <pre>df.iloc[2]\n</pre> df.iloc[2] Out[67]: <pre>AQI            60.0\nTemperature    64.0\nName: Chicago, dtype: float64</pre> <p>But we can also specify the column and row we want to access:</p> In\u00a0[68]: Copied! <pre>df.loc['New York','AQI']\n</pre> df.loc['New York','AQI'] Out[68]: <pre>55.0</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[28]: Copied! <pre>df.min()\n</pre> df.min() Out[28]: <pre>AQI            55.0\nTemperature    64.0\ndtype: float64</pre> In\u00a0[30]: Copied! <pre>df.idxmax()\n</pre> df.idxmax() Out[30]: <pre>AQI            Houston\nTemperature    Phoenix\ndtype: object</pre> In\u00a0[31]: Copied! <pre>df.mean()\n</pre> df.mean() Out[31]: <pre>AQI            67.5\nTemperature    74.4\ndtype: float64</pre> In\u00a0[32]: Copied! <pre>df.count()\n</pre> df.count() Out[32]: <pre>AQI            4\nTemperature    5\ndtype: int64</pre> In\u00a0[33]: Copied! <pre>df.std()\n</pre> df.std()  Out[33]: <pre>AQI            11.902381\nTemperature     8.561542\ndtype: float64</pre> In\u00a0[34]: Copied! <pre># describe function can print out the descriptive statistics easily!\ndf.describe()\n</pre> # describe function can print out the descriptive statistics easily! df.describe() Out[34]: AQI Temperature count 4.000000 5.000000 mean 67.500000 74.400000 std 11.902381 8.561542 min 55.000000 64.000000 25% 58.750000 68.000000 50% 67.500000 75.000000 75% 76.250000 80.000000 max 80.000000 85.000000 In\u00a0[\u00a0]: Copied! <pre>\n</pre> <p>Add new row:</p> In\u00a0[69]: Copied! <pre>df.loc['New Brunswick'] = [64, 75]\n</pre> df.loc['New Brunswick'] = [64, 75] In\u00a0[70]: Copied! <pre>df\n</pre> df Out[70]: AQI Temperature New York 55.0 68 Los Angeles 75.0 75 Chicago 60.0 64 Houston 80.0 80 Phoenix NaN 85 New Brunswick 64.0 75 <p>Add new column:</p> In\u00a0[71]: Copied! <pre>df['Cloudy'] = [True, False, True, False, False, True]\n</pre> df['Cloudy'] = [True, False, True, False, False, True] In\u00a0[72]: Copied! <pre>df\n</pre> df Out[72]: AQI Temperature Cloudy New York 55.0 68 True Los Angeles 75.0 75 False Chicago 60.0 64 True Houston 80.0 80 False Phoenix NaN 85 False New Brunswick 64.0 75 True In\u00a0[73]: Copied! <pre>data = {\n    \"Latitude\": [40.7128, 34.0522, 41.8781, 29.7604, 33.4484],\n    \"Longitude\": [-74.0060, -118.2437, -87.6298, -95.3698, -112.0740]\n}\n\ndf_loc = pd.DataFrame(data, index = [\"New York\", \"Los Angeles\", \"Chicago\", \"Houston\", \"Phoenix\"])\n</pre> data = {     \"Latitude\": [40.7128, 34.0522, 41.8781, 29.7604, 33.4484],     \"Longitude\": [-74.0060, -118.2437, -87.6298, -95.3698, -112.0740] }  df_loc = pd.DataFrame(data, index = [\"New York\", \"Los Angeles\", \"Chicago\", \"Houston\", \"Phoenix\"])  In\u00a0[74]: Copied! <pre>df_loc\n</pre> df_loc Out[74]: Latitude Longitude New York 40.7128 -74.0060 Los Angeles 34.0522 -118.2437 Chicago 41.8781 -87.6298 Houston 29.7604 -95.3698 Phoenix 33.4484 -112.0740 <p>Combine df and df_loc:</p> In\u00a0[75]: Copied! <pre>df_join = df.join(df_loc)\n</pre> df_join = df.join(df_loc) In\u00a0[77]: Copied! <pre>df_join\n</pre> df_join Out[77]: AQI Temperature Cloudy Latitude Longitude New York 55.0 68 True 40.7128 -74.0060 Los Angeles 75.0 75 False 34.0522 -118.2437 Chicago 60.0 64 True 41.8781 -87.6298 Houston 80.0 80 False 29.7604 -95.3698 Phoenix NaN 85 False 33.4484 -112.0740 New Brunswick 64.0 75 True NaN NaN In\u00a0[79]: Copied! <pre>df_join = df.join(df_loc, how = 'right')\ndf_join\n</pre> df_join = df.join(df_loc, how = 'right') df_join Out[79]: AQI Temperature Cloudy Latitude Longitude New York 55.0 68 True 40.7128 -74.0060 Los Angeles 75.0 75 False 34.0522 -118.2437 Chicago 60.0 64 True 41.8781 -87.6298 Houston 80.0 80 False 29.7604 -95.3698 Phoenix NaN 85 False 33.4484 -112.0740 <p>Using concat to append new rows:</p> In\u00a0[80]: Copied! <pre>df_append = pd.concat([df,df_loc])\n</pre> df_append = pd.concat([df,df_loc]) In\u00a0[81]: Copied! <pre>df_append\n</pre> df_append Out[81]: AQI Temperature Cloudy Latitude Longitude New York 55.0 68.0 True NaN NaN Los Angeles 75.0 75.0 False NaN NaN Chicago 60.0 64.0 True NaN NaN Houston 80.0 80.0 False NaN NaN Phoenix NaN 85.0 False NaN NaN New Brunswick 64.0 75.0 True NaN NaN New York NaN NaN NaN 40.7128 -74.0060 Los Angeles NaN NaN NaN 34.0522 -118.2437 Chicago NaN NaN NaN 41.8781 -87.6298 Houston NaN NaN NaN 29.7604 -95.3698 Phoenix NaN NaN NaN 33.4484 -112.0740 <p>As you can see, pd.read_csv() has quite a few parameters. Don't be overwhelmed \u2013 most of these are optional arguments that allow you to specify exactly how your data file is structured and which part(s) you want to import. In particular, the sep parameter allows the user to specify the type of delimiter used in the file. The default is a comma, but you can actually pass other common delimiters (such as sep='\\t', which is a tab) to import other delimited files. The only required argument is a string specifying the filepath of your file.</p> In\u00a0[\u00a0]: Copied! <pre>pd.read_csv?\n</pre> pd.read_csv? <p>Download wildfire data <code>Spatial_Database_Big_Wildfires_US_all.csv</code> from Canvas, and upload the data to your current working directory.</p> In\u00a0[84]: Copied! <pre>df = pd.read_csv('Spatial_Database_Big_Wildfires_US_all.csv')\ndf.head()\n</pre> df = pd.read_csv('Spatial_Database_Big_Wildfires_US_all.csv') df.head() Out[84]: FOD_ID FPA_ID SOURCE_SYSTEM_TYPE SOURCE_SYSTEM NWCG_REPORTING_UNIT_ID NWCG_REPORTING_UNIT_NAME FIRE_CODE FIRE_NAME MTBS_FIRE_NAME COMPLEX_NAME ... CONT_DOY FIRE_SIZE FIRE_SIZE_CLASS LATITUDE LONGITUDE OWNER_DESCR STATE COUNTY FIPS_CODE FIPS_NAME 0 17 FS-1418878 FED FS-FIRESTAT USCAENF Eldorado National Forest NaN POWER POWER NaN ... 295.0 16823.0 G 38.523333 -120.211667 USFS CA 5 6005.0 Amador County 1 18 FS-1418881 FED FS-FIRESTAT USCAENF Eldorado National Forest BHA3 FREDS FREDS NaN ... 291.0 7700.0 G 38.780000 -120.260000 USFS CA 17 6017.0 El Dorado County 2 40 FS-1418920 FED FS-FIRESTAT USNCNCF National Forests in North Carolina BKC8 AUSTIN CREEK NaN NaN ... 44.0 125.0 D 36.001667 -81.590000 MISSING/NOT SPECIFIED NC 27 37027.0 Caldwell County 3 119 FS-1419153 FED FS-FIRESTAT USNENBF Nebraska National Forest BEW8 THOMPSON BUTTE NaN NaN ... 198.0 119.0 D 43.899167 -102.954722 USFS SD 103 46103.0 Pennington County 4 120 FS-1419156 FED FS-FIRESTAT USNENBF Nebraska National Forest BEW8 CHARLES DRAW NaN NaN ... 197.0 119.0 D 43.892778 -102.948056 USFS SD 103 46103.0 Pennington County <p>5 rows \u00d7 28 columns</p> In\u00a0[85]: Copied! <pre>df.columns\n</pre> df.columns Out[85]: <pre>Index(['FOD_ID', 'FPA_ID', 'SOURCE_SYSTEM_TYPE', 'SOURCE_SYSTEM',\n       'NWCG_REPORTING_UNIT_ID', 'NWCG_REPORTING_UNIT_NAME', 'FIRE_CODE',\n       'FIRE_NAME', 'MTBS_FIRE_NAME', 'COMPLEX_NAME', 'FIRE_YEAR',\n       'DISCOVERY_DATE', 'DISCOVERY_DOY', 'DISCOVERY_TIME',\n       'NWCG_CAUSE_CLASSIFICATION', 'NWCG_GENERAL_CAUSE',\n       'NWCG_CAUSE_AGE_CATEGORY', 'CONT_DATE', 'CONT_DOY', 'FIRE_SIZE',\n       'FIRE_SIZE_CLASS', 'LATITUDE', 'LONGITUDE', 'OWNER_DESCR', 'STATE',\n       'COUNTY', 'FIPS_CODE', 'FIPS_NAME'],\n      dtype='object')</pre> In\u00a0[86]: Copied! <pre>df = df.set_index('FOD_ID') #Set index\n</pre> df = df.set_index('FOD_ID') #Set index In\u00a0[87]: Copied! <pre>df[['DISCOVERY_DATE','DISCOVERY_DOY','DISCOVERY_TIME' ]]\n</pre> df[['DISCOVERY_DATE','DISCOVERY_DOY','DISCOVERY_TIME' ]] Out[87]: DISCOVERY_DATE DISCOVERY_DOY DISCOVERY_TIME FOD_ID 17 10/6/2004 280 1415.0 18 10/13/2004 287 1618.0 40 2/12/2005 43 1520.0 119 7/16/2005 197 1715.0 120 7/16/2005 197 1730.0 ... ... ... ... 400732975 8/9/2019 221 2134.0 400732976 3/1/2020 61 1330.0 400732977 5/13/2020 134 1300.0 400732982 8/17/2020 230 755.0 400732984 11/20/2020 325 1110.0 <p>60713 rows \u00d7 3 columns</p> In\u00a0[88]: Copied! <pre>df.groupby('STATE').FPA_ID.count().nlargest(10).plot(kind='bar', figsize=(12,6))\n</pre> df.groupby('STATE').FPA_ID.count().nlargest(10).plot(kind='bar', figsize=(12,6)) Out[88]: <pre>&lt;Axes: xlabel='STATE'&gt;</pre> In\u00a0[89]: Copied! <pre>df.groupby(df.STATE)\n</pre> df.groupby(df.STATE) Out[89]: <pre>&lt;pandas.core.groupby.generic.DataFrameGroupBy object at 0x30f804280&gt;</pre> <p>There is a shortcut for doing this with dataframes: you just pass the column name:</p> In\u00a0[90]: Copied! <pre>df.groupby('STATE')\n</pre> df.groupby('STATE') Out[90]: <pre>&lt;pandas.core.groupby.generic.DataFrameGroupBy object at 0x30d529a30&gt;</pre> In\u00a0[91]: Copied! <pre>gb = df.groupby('STATE')\ngb\n</pre> gb = df.groupby('STATE') gb Out[91]: <pre>&lt;pandas.core.groupby.generic.DataFrameGroupBy object at 0x30d0d0b80&gt;</pre> <p>The length tells us how many groups were found:</p> In\u00a0[92]: Copied! <pre>len(gb)\n</pre> len(gb) Out[92]: <pre>50</pre> <p>All of the groups are available as a dictionary via the <code>.groups</code> attribute:</p> In\u00a0[93]: Copied! <pre>groups = gb.groups\nlen(groups)\n</pre> groups = gb.groups len(groups) Out[93]: <pre>50</pre> In\u00a0[94]: Copied! <pre>groups['NJ']\n</pre> groups['NJ'] Out[94]: <pre>Index([   247140,    384407,    578890,    579164,    579296,    580135,\n          580956,    581165,    582330,    582680,\n       ...\n       400271442, 400389794, 400482043, 400528139, 400531379, 400587134,\n       400594776, 400602511, 400613352, 400632920],\n      dtype='int64', name='FOD_ID', length=111)</pre> In\u00a0[95]: Copied! <pre>for key, group in gb:\n    display(group.head())\n    print(f'The key is \"{key}\"')\n    break\n</pre> for key, group in gb:     display(group.head())     print(f'The key is \"{key}\"')     break FPA_ID SOURCE_SYSTEM_TYPE SOURCE_SYSTEM NWCG_REPORTING_UNIT_ID NWCG_REPORTING_UNIT_NAME FIRE_CODE FIRE_NAME MTBS_FIRE_NAME COMPLEX_NAME FIRE_YEAR ... CONT_DOY FIRE_SIZE FIRE_SIZE_CLASS LATITUDE LONGITUDE OWNER_DESCR STATE COUNTY FIPS_CODE FIPS_NAME FOD_ID 6689 FS-1431539 FED FS-FIRESTAT USAKTNF Tongass National Forest BRD1 MUSKEG NaN NaN 2005 ... 126.0 305.0 E 59.087222 -135.441389 STATE OR PRIVATE AK 220 2220.0 Sitka City and Borough 109456 FS-334441 FED FS-FIRESTAT USAKTNF Tongass National Forest NaN MILL NaN NaN 1998 ... 189.0 118.0 D 55.681667 -132.615000 STATE OR PRIVATE AK NaN NaN NaN 147361 FS-374211 FED FS-FIRESTAT USAKCGF Chugach National Forest NaN KENAI LAKE KENAI LAKE NaN 2001 ... 188.0 3260.0 F 60.410278 -149.473611 USFS AK NaN NaN NaN 174677 W-374459 FED DOI-WFMI USAKAKA Alaska Regional Office B391 B391 532391 NaN 1995 ... 226.0 2850.0 F 66.832700 -160.736100 TRIBAL AK NaN NaN NaN 213301 W-36457 FED DOI-WFMI USAKAKD Alaska Fire Service A029 203029 NaN NaN 1992 ... 126.0 170.0 D 57.065900 -154.085700 BIA AK NaN NaN NaN <p>5 rows \u00d7 27 columns</p> <pre>The key is \"AK\"\n</pre> <p>And you can get a specific group by key.</p> In\u00a0[96]: Copied! <pre>gb.get_group('NJ')\n</pre> gb.get_group('NJ') Out[96]: FPA_ID SOURCE_SYSTEM_TYPE SOURCE_SYSTEM NWCG_REPORTING_UNIT_ID NWCG_REPORTING_UNIT_NAME FIRE_CODE FIRE_NAME MTBS_FIRE_NAME COMPLEX_NAME FIRE_YEAR ... CONT_DOY FIRE_SIZE FIRE_SIZE_CLASS LATITUDE LONGITUDE OWNER_DESCR STATE COUNTY FIPS_CODE FIPS_NAME FOD_ID 247140 W-234848 FED DOI-WFMI USPADWP Delaware Water Gap National Recreation Area NaN WORTHINGTO WORTHINGTO NaN 1999 ... 102.0 623.0 E 40.995895 -75.120000 NPS NJ NaN NaN NaN 384407 FWS-2007NJERRDFR2 FED FWS-FMIS USNJERR Edwin B. Forsythe National Wildlife Refuge DFR2 NJ NJFFS WF ASSIST WARREN GROVE WARREN GROVE NaN 2007 ... 141.0 17050.0 G 39.707500 -74.309722 STATE NJ NaN NaN NaN 578890 SFO-2006NJDEPA032704 NONFED ST-NASF USNJNJS New Jersey Forest Fire Service NaN NaN NaN NaN 2006 ... NaN 104.0 D 40.304400 -74.201100 PRIVATE NJ Middlesex 34023.0 Middlesex County 579164 SFO-2006NJDEPB012703 NONFED ST-NASF USNJNJS New Jersey Forest Fire Service NaN RARITAN CENTER NaN NaN 2006 ... NaN 450.0 E 40.296100 -74.214000 PRIVATE NJ Middlesex 34023.0 Middlesex County 579296 SFO-2006NJDEPB032108 NONFED ST-NASF USNJNJS New Jersey Forest Fire Service NaN SUNRISE LAKE NaN NaN 2006 ... NaN 136.0 D 39.482800 -74.510900 STATE NJ Burlington 34005.0 Burlington County ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 400587134 SFO-2020NJDEPA03-200223155509 NONFED ST-NASF USNJNJS New Jersey Forest Fire Service NaN NaN NaN NaN 2020 ... NaN 103.0 D 40.970480 -75.117710 MISSING/NOT SPECIFIED NJ Warren 34041.0 Warren County 400594776 SFO-2020NJDEPC03-200409234633 NONFED ST-NASF USNJNJS New Jersey Forest Fire Service NaN NaN SPLIT DITCH NaN 2020 ... NaN 1518.0 F 39.312640 -75.090240 MISSING/NOT SPECIFIED NJ Cumberland 34011.0 Cumberland County 400602511 SFO-2020NJDEPC06-200519235337 NONFED ST-NASF USNJNJS New Jersey Forest Fire Service NaN NaN BIG TIMBER NaN 2020 ... NaN 2107.0 F 39.651250 -74.892050 MISSING/NOT SPECIFIED NJ Camden 34007.0 Camden County 400613352 SFO-2020NJDEPB09-200709201959 NONFED ST-NASF USNJNJS New Jersey Forest Fire Service NaN NaN NaN NaN 2020 ... NaN 204.0 D 40.111570 -74.412330 MISSING/NOT SPECIFIED NJ Ocean 34029.0 Ocean County 400632920 ICS209_2019_10720324 INTERAGCY IA-ICS209 USNJNJS New Jersey Forest Fire Service NaN SPRING HILL FIRE SPRING HILL FIRE NaN 2019 ... NaN 11638.0 G 39.770000 -74.450000 MISSING/NOT SPECIFIED NJ Burlington 34005.0 Burlington County <p>111 rows \u00d7 27 columns</p> <p>By default, the operation is applied to every column. That's usually not what we want. We can use both <code>.</code> or <code>[]</code> syntax to select a specific column to operate on. Then we get back a series.</p> In\u00a0[121]: Copied! <pre># Find out the 10 states with biggest fire size. \n\ngb.FIRE_SIZE.max().nlargest(10)\n</pre> # Find out the 10 states with biggest fire size.   gb.FIRE_SIZE.max().nlargest(10) Out[121]: <pre>STATE  FIRE_YEAR\nOK     2017         662700.0\nAK     1997         606945.0\nCA     2020         589368.0\nOR     2012         558198.3\nAZ     2011         538049.0\nAK     2004         537627.0\n       2009         517078.0\nOR     2002         499945.0\nTX     2006         479549.0\nNV     2018         416821.2\nName: FIRE_SIZE, dtype: float64</pre> <p>There are shortcuts for common aggregation functions:</p> In\u00a0[99]: Copied! <pre>gb.FIRE_SIZE.max().nlargest(10)\n</pre> gb.FIRE_SIZE.max().nlargest(10) Out[99]: <pre>STATE\nOK    662700.0\nAK    606945.0\nCA    589368.0\nOR    558198.3\nAZ    538049.0\nTX    479549.0\nNV    416821.2\nID    367785.0\nUT    357185.0\nGA    309200.0\nName: FIRE_SIZE, dtype: float64</pre> In\u00a0[100]: Copied! <pre>gb.FIRE_SIZE.mean().nlargest(10)\n</pre> gb.FIRE_SIZE.mean().nlargest(10) Out[100]: <pre>STATE\nAK    16440.375603\nNV     6138.109191\nOR     5595.310524\nWA     5071.806130\nID     4657.836385\nCA     4086.919845\nMT     3571.759463\nAZ     3084.376006\nUT     2874.009960\nCO     2809.130881\nName: FIRE_SIZE, dtype: float64</pre> In\u00a0[103]: Copied! <pre>gb.FIRE_SIZE.sum().nlargest(10).plot(kind='bar')\n</pre> gb.FIRE_SIZE.sum().nlargest(10).plot(kind='bar') Out[103]: <pre>&lt;Axes: xlabel='STATE'&gt;</pre> In\u00a0[104]: Copied! <pre># Find out unique values of fire cause classification. \n\ndf['NWCG_CAUSE_CLASSIFICATION'].unique()\n</pre> # Find out unique values of fire cause classification.   df['NWCG_CAUSE_CLASSIFICATION'].unique() Out[104]: <pre>array(['Human', 'Natural', 'Missing data/not specified/undetermined'],\n      dtype=object)</pre> In\u00a0[105]: Copied! <pre># Find out unique values of fire general cause. \n\ndf['NWCG_GENERAL_CAUSE'].unique()\n</pre> # Find out unique values of fire general cause.   df['NWCG_GENERAL_CAUSE'].unique() Out[105]: <pre>array(['Equipment and vehicle use',\n       'Power generation/transmission/distribution',\n       'Debris and open burning', 'Natural',\n       'Missing data/not specified/undetermined',\n       'Recreation and ceremony', 'Smoking',\n       'Railroad operations and maintenance', 'Arson/incendiarism',\n       'Fireworks', 'Other causes', 'Misuse of fire by a minor',\n       'Firearms and explosives use'], dtype=object)</pre> In\u00a0[106]: Copied! <pre># Find out the 10 leading causes of fires. \n\ndf.groupby('NWCG_GENERAL_CAUSE').count()['FPA_ID'].nlargest(10).plot(kind = 'bar')\n</pre> # Find out the 10 leading causes of fires.   df.groupby('NWCG_GENERAL_CAUSE').count()['FPA_ID'].nlargest(10).plot(kind = 'bar') Out[106]: <pre>&lt;Axes: xlabel='NWCG_GENERAL_CAUSE'&gt;</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[108]: Copied! <pre>gb = df.groupby(['STATE','FIRE_YEAR'])\nlen(gb)\n</pre> gb = df.groupby(['STATE','FIRE_YEAR']) len(gb) Out[108]: <pre>1231</pre> In\u00a0[109]: Copied! <pre>list(gb.groups.keys())[:100:10]\n</pre> list(gb.groups.keys())[:100:10] Out[109]: <pre>[('AK', 1992),\n ('AK', 2002),\n ('AK', 2012),\n ('AL', 1993),\n ('AL', 2003),\n ('AL', 2013),\n ('AR', 1994),\n ('AR', 2004),\n ('AR', 2014),\n ('AZ', 1995)]</pre> In\u00a0[110]: Copied! <pre>gb.FIRE_SIZE.sum()\n</pre> gb.FIRE_SIZE.sum() Out[110]: <pre>STATE  FIRE_YEAR\nAK     1992         141007.000\n       1993         684669.800\n       1994         259901.600\n       1995          42526.000\n       1996         596706.400\n                       ...    \nWY     2016         254804.700\n       2017         118803.020\n       2018         220718.000\n       2019          41022.200\n       2020         285791.255\nName: FIRE_SIZE, Length: 1231, dtype: float64</pre> In\u00a0[111]: Copied! <pre>### Select group with multiple index must use tuple!\ngb.get_group(('CA', 2003))\n</pre> ### Select group with multiple index must use tuple! gb.get_group(('CA', 2003)) Out[111]: FPA_ID SOURCE_SYSTEM_TYPE SOURCE_SYSTEM NWCG_REPORTING_UNIT_ID NWCG_REPORTING_UNIT_NAME FIRE_CODE FIRE_NAME MTBS_FIRE_NAME COMPLEX_NAME FIRE_YEAR ... CONT_DOY FIRE_SIZE FIRE_SIZE_CLASS LATITUDE LONGITUDE OWNER_DESCR STATE COUNTY FIPS_CODE FIPS_NAME FOD_ID 157551 FS-385211 FED FS-FIRESTAT USCAINF Inyo National Forest NaN DEXTER DEXTER WFU NaN 2003 ... 286.0 2515.0 F 37.831389 -118.795000 USFS CA NaN NaN NaN 158728 FS-386431 FED FS-FIRESTAT USCAPNF Plumas National Forest 4300 ROWLAND NaN NaN 2003 ... 163.0 114.0 D 39.951389 -120.068889 USFS CA NaN NaN NaN 159533 FS-387254 FED FS-FIRESTAT USCASTF Stanislaus National Forest 7648 MUDD MUD WFU MUD COMPLEX 2003 ... 300.0 4102.0 F 38.424722 -119.961111 USFS CA NaN NaN NaN 159534 FS-387255 FED FS-FIRESTAT USCASTF Stanislaus National Forest 5555 WHITT WHITT MUD COMPLEX 2003 ... 300.0 1014.0 F 38.378056 -119.999722 USFS CA NaN NaN NaN 160202 FS-388122 FED FS-FIRESTAT USCALPF Los Padres National Forest 2996 DEL VENTURI NaN NaN 2003 ... 225.0 861.0 E 36.071111 -121.390000 MISSING/NOT SPECIFIED CA NaN NaN NaN ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 15000827 ICS209_2003_CA-KRN-37559 INTERAGCY IA-ICS209 USCAKRN Kern County Fire Department NaN HILLSIDE UNNAMED NaN 2003 ... 198.0 835.0 E 35.168056 -118.468056 MISSING/NOT SPECIFIED CA KERN 6029.0 Kern County 15000828 ICS209_2003_CA-KRN-38766 INTERAGCY IA-ICS209 USCAKRN Kern County Fire Department NaN MERCURY UNNAMED NaN 2003 ... 203.0 340.0 E 35.200556 -118.518611 MISSING/NOT SPECIFIED CA KERN 6029.0 Kern County 15000829 ICS209_2003_CA-LAC-03004054 INTERAGCY IA-ICS209 USCALAC Los Angeles County Fire Department NaN AIRPORT NaN NaN 2003 ... 8.0 245.0 D 33.407778 -118.402500 MISSING/NOT SPECIFIED CA LOS ANGELES 6037.0 Los Angeles County 201940026 ICS209_2003-CA-KRN-0333259 INTERAGCY IA-ICS209 USCAKRN Kern County Fire Department NaN TEJON TEJON NaN 2003 ... 183.0 1155.0 F 34.871389 -118.882778 MISSING/NOT SPECIFIED CA Kern 6029.0 Kern County 400280041 ICS209_2003_CA-KRN-33853 INTERAGCY IA-ICS209 USCAKRN Kern County Fire Department NaN GRAPEVINE GRAPEVINE NaN 2003 ... NaN 1830.0 F 34.916944 -118.918333 MISSING/NOT SPECIFIED CA Kern 6029.0 Kern County <p>210 rows \u00d7 27 columns</p> In\u00a0[112]: Copied! <pre>### Find out the largest fire in CA, 2020\ndf.loc[gb['FIRE_SIZE'].idxmax().loc['CA',2020]]\n</pre> ### Find out the largest fire in CA, 2020 df.loc[gb['FIRE_SIZE'].idxmax().loc['CA',2020]] Out[112]: <pre>FPA_ID                           IRW-2020-CAMNF-000730\nSOURCE_SYSTEM_TYPE                           INTERAGCY\nSOURCE_SYSTEM                                 IA-IRWIN\nNWCG_REPORTING_UNIT_ID                         USCAMNF\nNWCG_REPORTING_UNIT_NAME     Mendocino National Forest\nFIRE_CODE                                         NFP4\nFIRE_NAME                                          DOE\nMTBS_FIRE_NAME                          AUGUST COMPLEX\nCOMPLEX_NAME                            AUGUST COMPLEX\nFIRE_YEAR                                         2020\nDISCOVERY_DATE                               8/16/2020\nDISCOVERY_DOY                                      229\nDISCOVERY_TIME                                     NaN\nNWCG_CAUSE_CLASSIFICATION                      Natural\nNWCG_GENERAL_CAUSE                             Natural\nNWCG_CAUSE_AGE_CATEGORY                            NaN\nCONT_DATE                                   11/11/2020\nCONT_DOY                                         316.0\nFIRE_SIZE                                     589368.0\nFIRE_SIZE_CLASS                                      G\nLATITUDE                                     39.765255\nLONGITUDE                                  -122.672914\nOWNER_DESCR                                       USFS\nSTATE                                               CA\nCOUNTY                                           Glenn\nFIPS_CODE                                       6021.0\nFIPS_NAME                                 Glenn County\nName: 400629554, dtype: object</pre> In\u00a0[113]: Copied! <pre># Plot the number of wildfires every year and associated causes.\n\ndf.groupby(['FIRE_YEAR','NWCG_CAUSE_CLASSIFICATION']).FPA_ID.count().unstack('NWCG_CAUSE_CLASSIFICATION').plot(kind = 'bar', stacked = True)\n</pre> # Plot the number of wildfires every year and associated causes.  df.groupby(['FIRE_YEAR','NWCG_CAUSE_CLASSIFICATION']).FPA_ID.count().unstack('NWCG_CAUSE_CLASSIFICATION').plot(kind = 'bar', stacked = True) Out[113]: <pre>&lt;Axes: xlabel='FIRE_YEAR'&gt;</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"Week_5_Pandas_Basics/#week-5-working-with-tabular-data-in-python-with-pandas","title":"Week 5: Working with Tabular Data in Python with Pandas\u00b6","text":""},{"location":"Week_5_Pandas_Basics/#pandas-capabilities-from-the-pandas-website","title":"Pandas capabilities (from the Pandas website):\u00b6","text":"<ul> <li>A fast and efficient DataFrame object for data manipulation with integrated indexing;</li> <li>Tools for reading and writing data between in-memory data structures and different formats: CSV and text files, Microsoft Excel, SQL databases, and the fast HDF5 format;</li> <li>Intelligent data alignment and integrated handling of missing data: gain automatic label-based alignment in computations and easily manipulate messy data into an orderly form;</li> <li>Flexible reshaping and pivoting of data sets;</li> <li>Intelligent label-based slicing, fancy indexing, and subsetting of large data sets;</li> <li>Columns can be inserted and deleted from data structures for size mutability;</li> <li>Aggregating or transforming data with a powerful group by engine allowing split-apply-combine operations on data sets;</li> <li>High performance merging and joining of data sets;</li> <li>Hierarchical axis indexing provides an intuitive way of working with high-dimensional data in a lower-dimensional data structure;</li> <li>Time series-functionality: date range generation and frequency conversion, moving window statistics, moving window linear regressions, date shifting and lagging. Even create domain-specific time offsets and join time series without losing data;</li> <li>Highly optimized for performance, with critical code paths written in Cython or C.</li> <li>Python with pandas is in use in a wide variety of academic and commercial domains, including Finance, Neuroscience, Economics, Statistics, Advertising, Web Analytics, and more.</li> </ul>"},{"location":"Week_5_Pandas_Basics/#1-basic-pandas","title":"1. Basic Pandas\u00b6","text":""},{"location":"Week_5_Pandas_Basics/#11-basic-data-structures-in-pandas","title":"1.1 Basic data structures in Pandas:\u00b6","text":"<p>Pandas provides two types of classes for handling data:</p> <ol> <li>Series: a one-dimensional labeled array holding data of any type.</li> <li>DataFrame: a two-dimensional data structure that holds data like a two-dimension array or a table with rows and columns.</li> </ol> <p>You can think of Pandas Dataframe as an Excel spreadsheet, and Series as one column of the the spreadsheet. Multiple series can be combined as a DataFrame.</p>"},{"location":"Week_5_Pandas_Basics/#12-pandas-series","title":"1.2 Pandas Series\u00b6","text":"<p>Creating a Series by passing a list of values.</p>"},{"location":"Week_5_Pandas_Basics/#exercise-1-create-a-pandas-series-with-values-ranging-from-0-to-6-and-label-the-index-as-the-day-of-week-starting-from-sunday-to-saturday","title":"Exercise 1: Create a Pandas series with values ranging from 0 to 6, and label the index as the day of week, starting from 'Sunday' to 'Saturday'.\u00b6","text":""},{"location":"Week_5_Pandas_Basics/#13-indexing","title":"1.3 Indexing\u00b6","text":""},{"location":"Week_5_Pandas_Basics/#exercise-2-print-out-the-last-two-elements-of-series-s-hint-using-slice-notation-and-iloc","title":"Exercise 2: Print out the last two elements of Series s (hint: using slice notation and iloc).\u00b6","text":""},{"location":"Week_5_Pandas_Basics/#14-pandas-data-structure-dataframe","title":"1.4 Pandas data structure: DataFrame\u00b6","text":"<p>A more useful Pandas data structure is the DataFrame. A DataFrame is basically a bunch of series that share the same index. It's a lot like a table in a spreadsheet.</p> <p>Below we create a DataFrame.</p>"},{"location":"Week_5_Pandas_Basics/#15-index-with-pandas-dataframe","title":"1.5 Index with Pandas DataFrame:\u00b6","text":""},{"location":"Week_5_Pandas_Basics/#exercise-3-print-out-the-temperature-of-chicago-and-los-angeles","title":"Exercise 3: Print out the temperature of Chicago and Los Angeles.\u00b6","text":""},{"location":"Week_5_Pandas_Basics/#16-basic-statistics-with-pandas","title":"1.6 Basic statistics with Pandas:\u00b6","text":""},{"location":"Week_5_Pandas_Basics/#exercise-4-print-out-the-city-with-minimum-temperature","title":"Exercise 4: Print out the city with minimum temperature.\u00b6","text":""},{"location":"Week_5_Pandas_Basics/#17-modifying-pandas-dataframe","title":"1.7 Modifying Pandas DataFrame\u00b6","text":""},{"location":"Week_5_Pandas_Basics/#2-advanced-pandas","title":"2. Advanced Pandas\u00b6","text":""},{"location":"Week_5_Pandas_Basics/#21-importing-tabular-data-in-pandas","title":"2.1 Importing tabular data in pandas\u00b6","text":"<p>In Pandas, the most commonly used function to import tabular data is <code>read_csv</code> function</p>"},{"location":"Week_5_Pandas_Basics/#22-groupby-methods","title":"2.2 Groupby methods\u00b6","text":"<p><code>groupby</code> is an amazingly powerful function in pandas, but it is also complicated to use and understand. The point of this section is to make you feel confident in using <code>groupby</code>.</p>"},{"location":"Week_5_Pandas_Basics/#an-example","title":"An Example:\u00b6","text":"<p>Question: Find out the top 10 states with largest number of wildfires.</p> <p>This is an example of a \"one-liner\" that you can accomplish with groupby.</p>"},{"location":"Week_5_Pandas_Basics/#what-happened","title":"What Happened?\u00b6","text":"<p>Let's break apart this operation a bit. The workflow with <code>groubpy</code> can be divided into three general steps:</p> <ol> <li><p>Split: Partition the data into different groups based on some criterion.</p> </li> <li><p>Apply: Do some caclulation within each group. Different types of \"apply\" steps might be</p> <ul> <li> Aggregation: Get the mean or max within the group. </li> <li> Transformation: Normalize all the values within a group. </li> <li> Filtration: Eliminate some groups based on a criterion. </li> </ul> </li> <li><p>Combine: Put the results back together into a single object.</p> </li> </ol>"},{"location":"Week_5_Pandas_Basics/#the-groupby-method","title":"The <code>groupby</code> method\u00b6","text":"<p>Both <code>Series</code> and <code>DataFrame</code> objects have a groupby method. It accepts a variety of arguments, but the simplest way to think about it is that you pass another series, whose unique values are used to split the original object into different groups.</p>"},{"location":"Week_5_Pandas_Basics/#the-groubby-object","title":"The <code>GroubBy</code> object\u00b6","text":"<p>When we call, <code>groupby</code> we get back a <code>GroupBy</code> object:</p>"},{"location":"Week_5_Pandas_Basics/#23-iterating-and-selecting-groups","title":"2.3 Iterating and selecting groups\u00b6","text":"<p>You can loop through the groups if you want.</p>"},{"location":"Week_5_Pandas_Basics/#24-aggregation","title":"2.4 Aggregation\u00b6","text":"<p>Now that we know how to create a <code>GroupBy</code> object, let's learn how to do aggregation on it.</p> <p>One way us to use the <code>.aggregate</code> method, which accepts another function as its argument. The result is automatically combined into a new dataframe with the group key as the index.</p>"},{"location":"Week_5_Pandas_Basics/#exercise-5-plot-the-number-of-wildfires-every-year","title":"Exercise 5: Plot the number of wildfires every year.\u00b6","text":""},{"location":"Week_5_Pandas_Basics/#exercise-6-plot-the-number-of-wildfires-in-ca-every-year","title":"Exercise 6: Plot the number of wildfires in CA every year.\u00b6","text":""},{"location":"Week_5_Pandas_Basics/#25-groupby-multiple-index","title":"2.5 Groupby multiple index\u00b6","text":""},{"location":"Week_5_Pandas_Basics/#exercise-7-plot-the-number-of-wildfires-in-nj-every-year-and-associated-causes","title":"Exercise 7: Plot the number of wildfires in NJ every year and associated causes.\u00b6","text":""},{"location":"Week_6_Correlation_Regression_Analysis/","title":"Week 6: Correlation and Regressions in Python","text":"<p>This week, you will learn how to conduct correlation and linear regression analysis in Python</p> <p>In Environmental Sciences, we often come up with the ideas of exploring the relationship between two sets of measurements (e.g., How is air quality correlated with temperature?). The first step of the exploratory correlation analysis is to link the two datasets by matching the measurements taken at the same time and same place. Matching datasets has been a pain in Excel, but with the indexing functionality in Pandas, it is convenient to link datasets.</p> In\u00a0[1]: Copied! <pre>#Getting all the packages we need: \nimport pandas as pd \nimport numpy as np\n</pre> #Getting all the packages we need:  import pandas as pd  import numpy as np In\u00a0[\u00a0]: Copied! <pre>\n</pre> <p>Here we use an example to explore the correlation between ozone air quality and temperature at Millbrook Site in New York. We have two datasets: (1) Daily ozone measurements at this site (https://www.epa.gov/outdoor-air-quality-data/download-daily-data); (2) NOAA weather station data at this site (https://www.ncdc.noaa.gov/data-access/land-based-station-data).</p> <p>First, let's read in these two datasets using Pandas <code>read_csv</code> fuction:</p> In\u00a0[9]: Copied! <pre>df_AQS = pd.read_csv('Millbrook_NY_daily_ozone_2022.csv', parse_dates = ['Date'])\n</pre> df_AQS = pd.read_csv('Millbrook_NY_daily_ozone_2022.csv', parse_dates = ['Date']) In\u00a0[10]: Copied! <pre>df_AQS.head()\n</pre> df_AQS.head() Out[10]: Date Source Site ID POC Daily Max 8-hour Ozone Concentration Units Daily AQI Value Local Site Name Daily Obs Count Percent Complete ... AQS Parameter Description Method Code CBSA Code CBSA Name State FIPS Code State County FIPS Code County Site Latitude Site Longitude 0 2022-01-15 AQS 360270007 1 0.034 ppm 31 MILLBROOK 17 100.0 ... Ozone 87 35620 New York-Newark-Jersey City, NY-NJ-PA 36 New York 27 Dutchess 41.78555 -73.74136 1 2022-01-16 AQS 360270007 1 0.037 ppm 34 MILLBROOK 17 100.0 ... Ozone 87 35620 New York-Newark-Jersey City, NY-NJ-PA 36 New York 27 Dutchess 41.78555 -73.74136 2 2022-01-17 AQS 360270007 1 0.038 ppm 35 MILLBROOK 17 100.0 ... Ozone 87 35620 New York-Newark-Jersey City, NY-NJ-PA 36 New York 27 Dutchess 41.78555 -73.74136 3 2022-01-18 AQS 360270007 1 0.042 ppm 39 MILLBROOK 17 100.0 ... Ozone 87 35620 New York-Newark-Jersey City, NY-NJ-PA 36 New York 27 Dutchess 41.78555 -73.74136 4 2022-01-19 AQS 360270007 1 0.029 ppm 27 MILLBROOK 17 100.0 ... Ozone 87 35620 New York-Newark-Jersey City, NY-NJ-PA 36 New York 27 Dutchess 41.78555 -73.74136 <p>5 rows \u00d7 21 columns</p> In\u00a0[11]: Copied! <pre>df_weather = pd.read_csv('Millbrook_NY_daily_weather.csv', parse_dates = ['LST_DATE'])\n</pre> df_weather = pd.read_csv('Millbrook_NY_daily_weather.csv', parse_dates = ['LST_DATE']) In\u00a0[12]: Copied! <pre>df_weather.head()\n</pre> df_weather.head() Out[12]: LST_DATE WBANNO CRX_VN LONGITUDE LATITUDE T_DAILY_MAX T_DAILY_MIN T_DAILY_MEAN T_DAILY_AVG P_DAILY_CALC ... SOIL_MOISTURE_10_DAILY SOIL_MOISTURE_20_DAILY SOIL_MOISTURE_50_DAILY SOIL_MOISTURE_100_DAILY SOIL_TEMP_5_DAILY SOIL_TEMP_10_DAILY SOIL_TEMP_20_DAILY SOIL_TEMP_50_DAILY SOIL_TEMP_100_DAILY Unnamed: 28 0 2016-01-01 64756 2.422 -73.74 41.79 3.4 -0.5 1.5 1.3 0.0 ... 0.233 0.204 0.155 0.147 4.2 4.4 5.1 6.0 7.6 NaN 1 2016-01-02 64756 2.422 -73.74 41.79 2.9 -3.6 -0.4 -0.3 0.0 ... 0.227 0.199 0.152 0.144 2.8 3.1 4.2 5.7 7.4 NaN 2 2016-01-03 64756 2.422 -73.74 41.79 5.1 -1.8 1.6 1.1 0.0 ... 0.223 0.196 0.151 0.141 2.6 2.8 3.8 5.2 7.2 NaN 3 2016-01-04 64756 2.422 -73.74 41.79 0.5 -14.4 -6.9 -7.5 0.0 ... 0.220 0.194 0.148 0.139 1.7 2.1 3.4 4.9 6.9 NaN 4 2016-01-05 64756 2.422 -73.74 41.79 -5.2 -15.5 -10.3 -11.7 0.0 ... 0.213 0.191 0.148 0.138 0.4 0.9 2.4 4.3 6.6 NaN <p>5 rows \u00d7 29 columns</p> In\u00a0[13]: Copied! <pre>df_weather.columns\n</pre> df_weather.columns Out[13]: <pre>Index(['LST_DATE', 'WBANNO', 'CRX_VN', 'LONGITUDE', 'LATITUDE', 'T_DAILY_MAX',\n       'T_DAILY_MIN', 'T_DAILY_MEAN', 'T_DAILY_AVG', 'P_DAILY_CALC',\n       'SOLARAD_DAILY', 'SUR_TEMP_DAILY_TYPE', 'SUR_TEMP_DAILY_MAX',\n       'SUR_TEMP_DAILY_MIN', 'SUR_TEMP_DAILY_AVG', 'RH_DAILY_MAX',\n       'RH_DAILY_MIN', 'RH_DAILY_AVG', 'SOIL_MOISTURE_5_DAILY',\n       'SOIL_MOISTURE_10_DAILY', 'SOIL_MOISTURE_20_DAILY',\n       'SOIL_MOISTURE_50_DAILY', 'SOIL_MOISTURE_100_DAILY',\n       'SOIL_TEMP_5_DAILY', 'SOIL_TEMP_10_DAILY', 'SOIL_TEMP_20_DAILY',\n       'SOIL_TEMP_50_DAILY', 'SOIL_TEMP_100_DAILY', 'Unnamed: 28'],\n      dtype='object')</pre> <p>Next, we need to merge the two dataframes by matching the date and location. In this dataset, as there is only one site, we don't need to match the location, so we just need to match the date. Set the <code>Date</code> column as index.</p> In\u00a0[14]: Copied! <pre>df_AQS = df_AQS.set_index('Date')\ndf_weather = df_weather.set_index('LST_DATE')\n</pre> df_AQS = df_AQS.set_index('Date') df_weather = df_weather.set_index('LST_DATE') <p>If we only need to add selected columns in <code>df_weather</code> to  <code>df_AQS</code>, we just assign the new columns to <code>df_AQS</code>. For single column:</p> In\u00a0[15]: Copied! <pre>df_AQS['T_DAILY_MEAN'] = df_weather['T_DAILY_MEAN']\n</pre> df_AQS['T_DAILY_MEAN'] = df_weather['T_DAILY_MEAN'] <p>For multiple columns:</p> In\u00a0[16]: Copied! <pre>df_AQS[['T_DAILY_MAX','T_DAILY_MIN','RH_DAILY_MAX']] = df_weather[['T_DAILY_MAX','T_DAILY_MIN','RH_DAILY_MAX']]\n</pre> df_AQS[['T_DAILY_MAX','T_DAILY_MIN','RH_DAILY_MAX']] = df_weather[['T_DAILY_MAX','T_DAILY_MIN','RH_DAILY_MAX']] <p>Now you should see <code>df_AQS</code> has three new columns with temperature. We've merged these two datasets!</p> In\u00a0[17]: Copied! <pre>df_AQS\n</pre> df_AQS Out[17]: Source Site ID POC Daily Max 8-hour Ozone Concentration Units Daily AQI Value Local Site Name Daily Obs Count Percent Complete AQS Parameter Code ... State FIPS Code State County FIPS Code County Site Latitude Site Longitude T_DAILY_MEAN T_DAILY_MAX T_DAILY_MIN RH_DAILY_MAX Date 2022-01-15 AQS 360270007 1 0.034 ppm 31 MILLBROOK 17 100.0 44201 ... 36 New York 27 Dutchess 41.78555 -73.74136 -14.7 -11.6 -17.9 60.0 2022-01-16 AQS 360270007 1 0.037 ppm 34 MILLBROOK 17 100.0 44201 ... 36 New York 27 Dutchess 41.78555 -73.74136 -10.4 -1.1 -19.7 87.1 2022-01-17 AQS 360270007 1 0.038 ppm 35 MILLBROOK 17 100.0 44201 ... 36 New York 27 Dutchess 41.78555 -73.74136 2.0 5.2 -1.1 87.1 2022-01-18 AQS 360270007 1 0.042 ppm 39 MILLBROOK 17 100.0 44201 ... 36 New York 27 Dutchess 41.78555 -73.74136 -4.8 0.3 -9.9 66.3 2022-01-19 AQS 360270007 1 0.029 ppm 27 MILLBROOK 17 100.0 44201 ... 36 New York 27 Dutchess 41.78555 -73.74136 -2.4 5.8 -10.6 76.8 ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 2022-12-26 AQS 360270007 1 0.033 ppm 31 MILLBROOK 17 100.0 44201 ... 36 New York 27 Dutchess 41.78555 -73.74136 -6.8 -2.4 -11.1 70.9 2022-12-27 AQS 360270007 1 0.030 ppm 28 MILLBROOK 17 100.0 44201 ... 36 New York 27 Dutchess 41.78555 -73.74136 -4.4 -0.8 -8.0 81.9 2022-12-28 AQS 360270007 1 0.027 ppm 25 MILLBROOK 17 100.0 44201 ... 36 New York 27 Dutchess 41.78555 -73.74136 0.7 7.4 -6.1 80.8 2022-12-29 AQS 360270007 1 0.030 ppm 28 MILLBROOK 17 100.0 44201 ... 36 New York 27 Dutchess 41.78555 -73.74136 4.4 10.7 -1.8 74.3 2022-12-30 AQS 360270007 1 0.028 ppm 26 MILLBROOK 17 100.0 44201 ... 36 New York 27 Dutchess 41.78555 -73.74136 10.7 16.6 4.9 68.5 <p>339 rows \u00d7 24 columns</p> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> <p>Scatter plots allow you to quickly see if two variables are positively, negatively, or not correlated at all. You can directly use the plotting functions in Pandas:</p> In\u00a0[18]: Copied! <pre>df_AQS.plot.scatter('T_DAILY_MEAN','Daily Max 8-hour Ozone Concentration')\n</pre> df_AQS.plot.scatter('T_DAILY_MEAN','Daily Max 8-hour Ozone Concentration') Out[18]: <pre>&lt;Axes: xlabel='T_DAILY_MEAN', ylabel='Daily Max 8-hour Ozone Concentration'&gt;</pre> <p>The Pearson correlation coefficient r is calculated using the following formula:</p> <p>$$ r = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum_{i=1}^{n} (x_i - \\bar{x})^2 \\sum_{i=1}^{n} (y_i - \\bar{y})^2}} $$</p> <p>where $x_i$ and $y_i$ are individual data points for variables $x$ and $y$; $\\bar{x}$ and $\\bar{y}$ are the means of $x$ and $y$; $n$ is the number of data points.</p> In\u00a0[\u00a0]: Copied! <pre>\n</pre> <p>You may find it a pain to calculate R value by hand. You just need to do it once! In Pandas, you can directly calculate Pearson Correlation Coefficient using the <code>corr</code> function.</p> In\u00a0[19]: Copied! <pre>pearson_corr = df_AQS['T_DAILY_MEAN'].corr(df_AQS['Daily Max 8-hour Ozone Concentration'], method='pearson')\n</pre> pearson_corr = df_AQS['T_DAILY_MEAN'].corr(df_AQS['Daily Max 8-hour Ozone Concentration'], method='pearson') In\u00a0[20]: Copied! <pre>pearson_corr\n</pre> pearson_corr Out[20]: <pre>np.float64(0.3047365963742261)</pre> <p>Check if the value is the same as the r value you calculated in Exercise 2.</p> <p>In Week 2, we learned that rank-based statistics are more appropriate for censored datasets with non-detects.</p> <p>The Spearman rank correlation coefficient (denoted as \u03c1) is a non-parametric measure of the strength and direction of the monotonic relationship between two ranked variables. Spearman correlation works on the ranks of the data, not the actual values. Each data point is assigned a rank, and the correlation is calculated based on these ranks. Like Pearson correlation, the Spearman correlation coefficient ranges from -1 to 1:</p> <ul> <li>\u03c1=1: Perfect positive monotonic relationship. As one variable increases, the other increases as well.</li> <li>\u03c1=\u22121: Perfect negative monotonic relationship. As one variable increases, the other decreases.</li> <li>\u03c1=0: No monotonic relationship between the variables.</li> </ul> <p>Spearman rank correlation coefficient does not assume normality or linearity. It can be applied to ordinal, interval, or ratio data. Since Spearman uses ranks, it is more robust to outliers and non-detects compared to Pearson correlation.</p> <p>To calculate the Spearman rank correlation coefficient in Pandas, we just simply need to change the method argument to 'spearman':</p> In\u00a0[21]: Copied! <pre>spearman_corr = df_AQS['T_DAILY_MEAN'].corr(df_AQS['Daily Max 8-hour Ozone Concentration'], method='spearman')\n</pre> spearman_corr = df_AQS['T_DAILY_MEAN'].corr(df_AQS['Daily Max 8-hour Ozone Concentration'], method='spearman') In\u00a0[22]: Copied! <pre>spearman_corr\n</pre> spearman_corr Out[22]: <pre>np.float64(0.3031817198225167)</pre> In\u00a0[23]: Copied! <pre># Calculate Pearson correlation matrix for multiple numeric columns\ncorr_matrix = df_AQS[['T_DAILY_MAX','T_DAILY_MIN','T_DAILY_MEAN','Daily Max 8-hour Ozone Concentration']].corr(method='pearson', numeric_only = True)\n\n# We can visualize the correlation metrics by setting the style of the output.\ncorr_matrix.style.background_gradient(cmap='Blues')\n</pre> # Calculate Pearson correlation matrix for multiple numeric columns corr_matrix = df_AQS[['T_DAILY_MAX','T_DAILY_MIN','T_DAILY_MEAN','Daily Max 8-hour Ozone Concentration']].corr(method='pearson', numeric_only = True)  # We can visualize the correlation metrics by setting the style of the output. corr_matrix.style.background_gradient(cmap='Blues') Out[23]: T_DAILY_MAX T_DAILY_MIN T_DAILY_MEAN Daily Max 8-hour Ozone Concentration T_DAILY_MAX 1.000000 0.905145 0.978251 0.379406 T_DAILY_MIN 0.905145 1.000000 0.973623 0.206968 T_DAILY_MEAN 0.978251 0.973623 1.000000 0.304737 Daily Max 8-hour Ozone Concentration 0.379406 0.206968 0.304737 1.000000 In\u00a0[24]: Copied! <pre>import statsmodels.api as sm\n</pre> import statsmodels.api as sm In\u00a0[25]: Copied! <pre># Define the independent (X) and dependent (y) variables\nX = df_AQS['T_DAILY_MAX']  # Independent variable\ny = df_AQS['Daily Max 8-hour Ozone Concentration']*1000.  # Dependent variable\n</pre> # Define the independent (X) and dependent (y) variables X = df_AQS['T_DAILY_MAX']  # Independent variable y = df_AQS['Daily Max 8-hour Ozone Concentration']*1000.  # Dependent variable  In\u00a0[26]: Copied! <pre># Add a constant (intercept) to X\nX_with_const = sm.add_constant(X)\n\nmodel = sm.OLS(y, X_with_const).fit()\n</pre> # Add a constant (intercept) to X X_with_const = sm.add_constant(X)  model = sm.OLS(y, X_with_const).fit()  In\u00a0[27]: Copied! <pre>model.summary()\n</pre> model.summary() Out[27]: OLS Regression Results Dep. Variable: Daily Max 8-hour Ozone Concentration   R-squared:             0.144 Model: OLS   Adj. R-squared:        0.141 Method: Least Squares   F-statistic:           56.67 Date: Sun, 29 Sep 2024   Prob (F-statistic): 4.76e-13 Time: 15:19:23   Log-Likelihood:      -1226.9 No. Observations:    339   AIC:                   2458. Df Residuals:    337   BIC:                   2465. Df Model:      1 Covariance Type: nonrobust coef std err t P&gt;|t| [0.025 0.975] const    32.7306     0.903    36.251  0.000    30.955    34.507 T_DAILY_MAX     0.3396     0.045     7.528  0.000     0.251     0.428 Omnibus:  2.910   Durbin-Watson:         0.972 Prob(Omnibus):  0.233   Jarque-Bera (JB):      2.221 Skew:  0.007   Prob(JB):              0.329 Kurtosis:  2.604   Cond. No.               36.8 Notes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.  In\u00a0[28]: Copied! <pre># Extract the intercept and slope\nintercept, slope = model.params\n\n# Print the slope and intercept\nprint(f\"Intercept: {intercept}\")\nprint(f\"Slope (Coefficient): {slope}\")\n</pre> # Extract the intercept and slope intercept, slope = model.params  # Print the slope and intercept print(f\"Intercept: {intercept}\") print(f\"Slope (Coefficient): {slope}\")  <pre>Intercept: 32.73055575275309\nSlope (Coefficient): 0.33960906163846516\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> <p>If you have multiple independent variables, the process is similar. You just need to include more columns in your X.</p> In\u00a0[29]: Copied! <pre># Define the independent (X) and dependent (y) variables\nX = df_AQS[['T_DAILY_MAX','RH_DAILY_MAX']]  # Independent variables\ny = df_AQS['Daily Max 8-hour Ozone Concentration']*1000.  # Dependent variable\n</pre> # Define the independent (X) and dependent (y) variables X = df_AQS[['T_DAILY_MAX','RH_DAILY_MAX']]  # Independent variables y = df_AQS['Daily Max 8-hour Ozone Concentration']*1000.  # Dependent variable  In\u00a0[30]: Copied! <pre># Add a constant (intercept) to X\nX_with_const = sm.add_constant(X)\n\n# Fit the linear regression model\nmodel = sm.OLS(y, X_with_const).fit()\n\n# Get the regression results summary\nmodel.summary()\n</pre> # Add a constant (intercept) to X X_with_const = sm.add_constant(X)  # Fit the linear regression model model = sm.OLS(y, X_with_const).fit()  # Get the regression results summary model.summary() Out[30]: OLS Regression Results Dep. Variable: Daily Max 8-hour Ozone Concentration   R-squared:             0.205 Model: OLS   Adj. R-squared:        0.200 Method: Least Squares   F-statistic:           43.34 Date: Sun, 29 Sep 2024   Prob (F-statistic): 1.80e-17 Time: 15:19:53   Log-Likelihood:      -1214.4 No. Observations:    339   AIC:                   2435. Df Residuals:    336   BIC:                   2446. Df Model:      2 Covariance Type: nonrobust coef std err t P&gt;|t| [0.025 0.975] const    59.2369     5.287    11.203  0.000    48.836    69.638 T_DAILY_MAX     0.4494     0.049     9.246  0.000     0.354     0.545 RH_DAILY_MAX    -0.3274     0.064    -5.083  0.000    -0.454    -0.201 Omnibus:  3.131   Durbin-Watson:         1.031 Prob(Omnibus):  0.209   Jarque-Bera (JB):      2.347 Skew:  0.017   Prob(JB):              0.309 Kurtosis:  2.594   Cond. No.               988. Notes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.  In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"Week_6_Correlation_Regression_Analysis/#week-6-correlation-and-regressions-in-python","title":"Week 6: Correlation and Regressions in Python\u00b6","text":""},{"location":"Week_6_Correlation_Regression_Analysis/#1-linking-datasets-in-python","title":"1. Linking Datasets in Python\u00b6","text":""},{"location":"Week_6_Correlation_Regression_Analysis/#exercise-11-combine-the-two-dataframes-by-adding-daily-max-8-hour-ozone-concentration-from-df_aqs-to-df_weather","title":"Exercise 1.1: Combine the two dataframes by adding 'Daily Max 8-hour Ozone Concentration' from <code>df_AQS</code> to <code>df_weather</code>.\u00b6","text":""},{"location":"Week_6_Correlation_Regression_Analysis/#exercise-12-use-describe-to-get-the-basic-statistics-of-the-combined-dataset-df_aqs-and-df_weather-can-you-tell-whats-the-difference-between-these-two-dataframes","title":"Exercise 1.2: Use <code>describe</code> to get the basic statistics of the combined dataset df_AQS and df_weather. Can you tell what's the difference between these two dataframes?\u00b6","text":""},{"location":"Week_6_Correlation_Regression_Analysis/#2-correlation-analysis","title":"2. Correlation Analysis\u00b6","text":""},{"location":"Week_6_Correlation_Regression_Analysis/#21-scatter-plots","title":"2.1 Scatter Plots\u00b6","text":""},{"location":"Week_6_Correlation_Regression_Analysis/#22-pearson-correlation-coefficient","title":"2.2 Pearson Correlation Coefficient\u00b6","text":"<p>The Pearson correlation coefficient (often denoted as r) is a statistical measure that quantifies the strength and direction of the linear relationship between two continuous variables.</p>"},{"location":"Week_6_Correlation_Regression_Analysis/#exercise-2-using-the-above-formula-to-calculate-the-pearson-correlation-coefficient-r-between-daily-max-8-hour-ozone-concentration-and-t_daily_mean-in-df_aqs","title":"Exercise 2: Using the above formula to calculate the Pearson Correlation Coefficient r between 'Daily Max 8-hour Ozone Concentration' and 'T_DAILY_MEAN' in <code>df_AQS</code>\u00b6","text":""},{"location":"Week_6_Correlation_Regression_Analysis/#23-spearman-rank-correlation-coefficient","title":"2.3 Spearman Rank Correlation Coefficient\u00b6","text":""},{"location":"Week_6_Correlation_Regression_Analysis/#24-correlation-matrix","title":"2.4 Correlation Matrix\u00b6","text":"<p>Correlation matrix is a numerical representation (a matrix of the correlation coefficient (r)) showing the strength of the relationship among all the variables in your dataset.</p>"},{"location":"Week_6_Correlation_Regression_Analysis/#3-linear-regression","title":"3. Linear Regression\u00b6","text":"<p>There are multiple ways to conduct linear regression in Python. Here we use <code>statsmodels</code> library in Python, which provides classes and functions for the estimation of many different statistical models, as well as for conducting statistical tests, and statistical data exploration.</p>"},{"location":"Week_6_Correlation_Regression_Analysis/#exercise-3-based-on-what-you-learned-from-the-video-explain-the-linear-regression-results-summary","title":"Exercise 3: Based on what you learned from the video, explain the linear regression results summary:\u00b6","text":"<p>A. What do the slope and intercept mean here? What are the their units?</p> <p>B. What does R-squared mean here?</p> <p>C. Using the linear relationship, predict the level of ozone at 30 \u02daC.</p> <p>D. What is degree of freedom of this linear model?</p>"},{"location":"Week_6_Correlation_Regression_Analysis/#4-multiple-linear-regression","title":"4. Multiple Linear Regression\u00b6","text":""},{"location":"Week_6_Correlation_Regression_Analysis/#exercise-4-based-on-what-you-learned-from-the-video-explain-the-multiple-linear-regression-results-summary","title":"Exercise 4: Based on what you learned from the video, explain the multiple linear regression results summary:\u00b6","text":"<p>A. What do the coefficients mean here? What are the their units?</p> <p>B. What is degree of freedom of this model?</p> <p>C. What is the difference between R-squared and Adj. R-squared?</p>"},{"location":"Week_6_Correlation_Regression_Analysis/#5-assignment-apply-correlation-and-regression-analysis-to-the-datasets-you-found-in-week-2-or-any-other-datasets-that-you-use","title":"5. Assignment: Apply correlation and regression analysis to the datasets you found in Week 2 (or any other datasets that you use).\u00b6","text":"<p>Note: If you are both careful and lucky (i.e. you are lucky enough to choose the right data set), you should be able to meld this weekly assignment into your final paper.</p>"},{"location":"Week_6_Correlation_Regression_Analysis/#51-in-one-sentence-explain-the-purpose-of-the-analysis-you-will-do","title":"5.1 In one sentence, explain the purpose of the analysis you will do.\u00b6","text":""},{"location":"Week_6_Correlation_Regression_Analysis/#52-correlation-analysis","title":"5.2 Correlation analysis\u00b6","text":""},{"location":"Week_6_Correlation_Regression_Analysis/#53-linear-regression-analysis","title":"5.3 Linear regression analysis\u00b6","text":""},{"location":"Week_7_Time_Series_Analysis/","title":"Week 7: Time series analysis","text":"<p>First, import python packages.</p> In\u00a0[1]: Copied! <pre>import pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\n</pre> import pandas as pd import numpy as np from matplotlib import pyplot as plt <p>Like the data we are working with in this exercise, many environmental datasets include timed records. The standard datetime library is the primary way of manipulating dates and times in Python, but there are additional third-party packages that provide additional support.</p> <p>A few worth exploring are dateutil, an extension of the datetime library useful for parsing timestamps, and pytz, which provides a smooth way of tackling time zones.</p> <p>Though we will not review datetime objects in depth here, it is useful to understand the basics of how to deal with datetime objects in Python as this is a main component of time series data.</p> <p>Here we will introduce a few pandas functions built on the datetime library to handle datetime objects.</p> In\u00a0[3]: Copied! <pre># Define a range of dates. By default, the frequency is daily. \npd.date_range('4/1/2017','4/30/2017')\n</pre> # Define a range of dates. By default, the frequency is daily.  pd.date_range('4/1/2017','4/30/2017') Out[3]: <pre>DatetimeIndex(['2017-04-01', '2017-04-02', '2017-04-03', '2017-04-04',\n               '2017-04-05', '2017-04-06', '2017-04-07', '2017-04-08',\n               '2017-04-09', '2017-04-10', '2017-04-11', '2017-04-12',\n               '2017-04-13', '2017-04-14', '2017-04-15', '2017-04-16',\n               '2017-04-17', '2017-04-18', '2017-04-19', '2017-04-20',\n               '2017-04-21', '2017-04-22', '2017-04-23', '2017-04-24',\n               '2017-04-25', '2017-04-26', '2017-04-27', '2017-04-28',\n               '2017-04-29', '2017-04-30'],\n              dtype='datetime64[ns]', freq='D')</pre> In\u00a0[4]: Copied! <pre># Specify start and end, monthly frequency\n\npd.date_range('4/1/2017','4/30/2018', freq = 'ME')\n</pre> # Specify start and end, monthly frequency  pd.date_range('4/1/2017','4/30/2018', freq = 'ME') Out[4]: <pre>DatetimeIndex(['2017-04-30', '2017-05-31', '2017-06-30', '2017-07-31',\n               '2017-08-31', '2017-09-30', '2017-10-31', '2017-11-30',\n               '2017-12-31', '2018-01-31', '2018-02-28', '2018-03-31',\n               '2018-04-30'],\n              dtype='datetime64[ns]', freq='ME')</pre> In\u00a0[5]: Copied! <pre># Specify start and end, 5min frequency\n# datetime64 is 64-bit integer, which represents an offset from 1970-01-01T00:00:00\n\npd.date_range('4/1/2017','4/30/2018', freq = '5min')\n</pre> # Specify start and end, 5min frequency # datetime64 is 64-bit integer, which represents an offset from 1970-01-01T00:00:00  pd.date_range('4/1/2017','4/30/2018', freq = '5min') Out[5]: <pre>DatetimeIndex(['2017-04-01 00:00:00', '2017-04-01 00:05:00',\n               '2017-04-01 00:10:00', '2017-04-01 00:15:00',\n               '2017-04-01 00:20:00', '2017-04-01 00:25:00',\n               '2017-04-01 00:30:00', '2017-04-01 00:35:00',\n               '2017-04-01 00:40:00', '2017-04-01 00:45:00',\n               ...\n               '2018-04-29 23:15:00', '2018-04-29 23:20:00',\n               '2018-04-29 23:25:00', '2018-04-29 23:30:00',\n               '2018-04-29 23:35:00', '2018-04-29 23:40:00',\n               '2018-04-29 23:45:00', '2018-04-29 23:50:00',\n               '2018-04-29 23:55:00', '2018-04-30 00:00:00'],\n              dtype='datetime64[ns]', length=113473, freq='5min')</pre> In\u00a0[6]: Copied! <pre>df = pd.read_csv('Millbrook_NY_daily_weather.csv')\n</pre> df = pd.read_csv('Millbrook_NY_daily_weather.csv') In\u00a0[7]: Copied! <pre>df.head()\n</pre> df.head() Out[7]: LST_DATE WBANNO CRX_VN LONGITUDE LATITUDE T_DAILY_MAX T_DAILY_MIN T_DAILY_MEAN T_DAILY_AVG P_DAILY_CALC ... SOIL_MOISTURE_10_DAILY SOIL_MOISTURE_20_DAILY SOIL_MOISTURE_50_DAILY SOIL_MOISTURE_100_DAILY SOIL_TEMP_5_DAILY SOIL_TEMP_10_DAILY SOIL_TEMP_20_DAILY SOIL_TEMP_50_DAILY SOIL_TEMP_100_DAILY Unnamed: 28 0 2016-01-01 64756 2.422 -73.74 41.79 3.4 -0.5 1.5 1.3 0.0 ... 0.233 0.204 0.155 0.147 4.2 4.4 5.1 6.0 7.6 NaN 1 2016-01-02 64756 2.422 -73.74 41.79 2.9 -3.6 -0.4 -0.3 0.0 ... 0.227 0.199 0.152 0.144 2.8 3.1 4.2 5.7 7.4 NaN 2 2016-01-03 64756 2.422 -73.74 41.79 5.1 -1.8 1.6 1.1 0.0 ... 0.223 0.196 0.151 0.141 2.6 2.8 3.8 5.2 7.2 NaN 3 2016-01-04 64756 2.422 -73.74 41.79 0.5 -14.4 -6.9 -7.5 0.0 ... 0.220 0.194 0.148 0.139 1.7 2.1 3.4 4.9 6.9 NaN 4 2016-01-05 64756 2.422 -73.74 41.79 -5.2 -15.5 -10.3 -11.7 0.0 ... 0.213 0.191 0.148 0.138 0.4 0.9 2.4 4.3 6.6 NaN <p>5 rows \u00d7 29 columns</p> In\u00a0[8]: Copied! <pre>df.columns\n</pre> df.columns Out[8]: <pre>Index(['LST_DATE', 'WBANNO', 'CRX_VN', 'LONGITUDE', 'LATITUDE', 'T_DAILY_MAX',\n       'T_DAILY_MIN', 'T_DAILY_MEAN', 'T_DAILY_AVG', 'P_DAILY_CALC',\n       'SOLARAD_DAILY', 'SUR_TEMP_DAILY_TYPE', 'SUR_TEMP_DAILY_MAX',\n       'SUR_TEMP_DAILY_MIN', 'SUR_TEMP_DAILY_AVG', 'RH_DAILY_MAX',\n       'RH_DAILY_MIN', 'RH_DAILY_AVG', 'SOIL_MOISTURE_5_DAILY',\n       'SOIL_MOISTURE_10_DAILY', 'SOIL_MOISTURE_20_DAILY',\n       'SOIL_MOISTURE_50_DAILY', 'SOIL_MOISTURE_100_DAILY',\n       'SOIL_TEMP_5_DAILY', 'SOIL_TEMP_10_DAILY', 'SOIL_TEMP_20_DAILY',\n       'SOIL_TEMP_50_DAILY', 'SOIL_TEMP_100_DAILY', 'Unnamed: 28'],\n      dtype='object')</pre> <p>Which of the columns is likely to store the date and time information?</p> In\u00a0[9]: Copied! <pre>df['LST_DATE']\n</pre> df['LST_DATE'] Out[9]: <pre>0       2016-01-01\n1       2016-01-02\n2       2016-01-03\n3       2016-01-04\n4       2016-01-05\n           ...    \n2552    2022-12-27\n2553    2022-12-28\n2554    2022-12-29\n2555    2022-12-30\n2556    2022-12-31\nName: LST_DATE, Length: 2557, dtype: object</pre> <p>While the values certainly resemble datetime objects, they are stored in pandas as \"objects,\" which basically means that pandas doesn't recognize the data type \u2013 it doesn't know how to handle them.</p> <p>Using the pd.to_datetime() function, we can convert this column to datetime objects:</p> In\u00a0[10]: Copied! <pre>pd.to_datetime(df['LST_DATE'])\n</pre> pd.to_datetime(df['LST_DATE']) Out[10]: <pre>0      2016-01-01\n1      2016-01-02\n2      2016-01-03\n3      2016-01-04\n4      2016-01-05\n          ...    \n2552   2022-12-27\n2553   2022-12-28\n2554   2022-12-29\n2555   2022-12-30\n2556   2022-12-31\nName: LST_DATE, Length: 2557, dtype: datetime64[ns]</pre> In\u00a0[11]: Copied! <pre># Set the LST_DATE as datetime object. \ndf['LST_DATE'] = pd.to_datetime(df['LST_DATE'])\n</pre> # Set the LST_DATE as datetime object.  df['LST_DATE'] = pd.to_datetime(df['LST_DATE']) In\u00a0[24]: Copied! <pre># We can also set LST_DATE as datetime object so by setting the parse_dates when read in the csv data:\n\ndf = pd.read_csv('Millbrook_NY_daily_weather.csv', parse_dates = ['LST_DATE'])\n</pre> # We can also set LST_DATE as datetime object so by setting the parse_dates when read in the csv data:  df = pd.read_csv('Millbrook_NY_daily_weather.csv', parse_dates = ['LST_DATE']) In\u00a0[25]: Copied! <pre># Set the Date column as index:\n\ndf = df.set_index('LST_DATE')\n</pre> # Set the Date column as index:  df = df.set_index('LST_DATE') In\u00a0[26]: Copied! <pre># Now it's more intuitive to interpret the data:\n\ndf['T_DAILY_MEAN']\n</pre> # Now it's more intuitive to interpret the data:  df['T_DAILY_MEAN'] Out[26]: <pre>LST_DATE\n2016-01-01     1.5\n2016-01-02    -0.4\n2016-01-03     1.6\n2016-01-04    -6.9\n2016-01-05   -10.3\n              ... \n2022-12-27    -4.4\n2022-12-28     0.7\n2022-12-29     4.4\n2022-12-30    10.7\n2022-12-31     7.9\nName: T_DAILY_MEAN, Length: 2557, dtype: float64</pre> <p>After setting the date as the index, it's very simple to make time series plots in Pandas. You don't even need to set the x-axis label. Pandas will automatically decide the date frequency that can best show the date information!</p> In\u00a0[27]: Copied! <pre>df['T_DAILY_MEAN'].plot()\n</pre> df['T_DAILY_MEAN'].plot() Out[27]: <pre>&lt;Axes: xlabel='LST_DATE'&gt;</pre> <p>Since we have multiple years of data, Pandas will automatically choose to show the year only.</p> In\u00a0[\u00a0]: Copied! <pre>\n</pre> <p>Now that we have a DatetimeIndex, we can access specific attributes of the datetime objects like the year, day, hour, etc. To do this, we add the desired time period using dot notation: df.index.attribute. For a full list of attributes, see the pd.DatetimeIndex documentation. For example:</p> In\u00a0[28]: Copied! <pre># Get the month of each record\ndf.index.month\n</pre> # Get the month of each record df.index.month Out[28]: <pre>Index([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n       ...\n       12, 12, 12, 12, 12, 12, 12, 12, 12, 12],\n      dtype='int32', name='LST_DATE', length=2557)</pre> In\u00a0[29]: Copied! <pre># Get the year of each record, and assign this to a new column\n\ndf['year'] = df.index.year\n</pre> # Get the year of each record, and assign this to a new column  df['year'] = df.index.year  In\u00a0[30]: Copied! <pre>df\n</pre> df Out[30]: WBANNO CRX_VN LONGITUDE LATITUDE T_DAILY_MAX T_DAILY_MIN T_DAILY_MEAN T_DAILY_AVG P_DAILY_CALC SOLARAD_DAILY ... SOIL_MOISTURE_20_DAILY SOIL_MOISTURE_50_DAILY SOIL_MOISTURE_100_DAILY SOIL_TEMP_5_DAILY SOIL_TEMP_10_DAILY SOIL_TEMP_20_DAILY SOIL_TEMP_50_DAILY SOIL_TEMP_100_DAILY Unnamed: 28 year LST_DATE 2016-01-01 64756 2.422 -73.74 41.79 3.4 -0.5 1.5 1.3 0.0 1.69 ... 0.204 0.155 0.147 4.2 4.4 5.1 6.0 7.6 NaN 2016 2016-01-02 64756 2.422 -73.74 41.79 2.9 -3.6 -0.4 -0.3 0.0 6.25 ... 0.199 0.152 0.144 2.8 3.1 4.2 5.7 7.4 NaN 2016 2016-01-03 64756 2.422 -73.74 41.79 5.1 -1.8 1.6 1.1 0.0 5.69 ... 0.196 0.151 0.141 2.6 2.8 3.8 5.2 7.2 NaN 2016 2016-01-04 64756 2.422 -73.74 41.79 0.5 -14.4 -6.9 -7.5 0.0 9.17 ... 0.194 0.148 0.139 1.7 2.1 3.4 4.9 6.9 NaN 2016 2016-01-05 64756 2.422 -73.74 41.79 -5.2 -15.5 -10.3 -11.7 0.0 9.34 ... 0.191 0.148 0.138 0.4 0.9 2.4 4.3 6.6 NaN 2016 ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 2022-12-27 64756 2.622 -73.74 41.79 -0.8 -8.0 -4.4 -3.8 0.0 4.00 ... NaN 0.164 0.157 -0.4 -0.2 0.5 2.2 4.0 NaN 2022 2022-12-28 64756 2.622 -73.74 41.79 7.4 -6.1 0.7 1.3 0.0 7.73 ... NaN 0.162 0.156 -0.4 -0.3 0.4 2.1 3.8 NaN 2022 2022-12-29 64756 2.622 -73.74 41.79 10.7 -1.8 4.4 5.0 0.0 6.66 ... NaN 0.159 0.155 -0.3 -0.3 0.3 1.9 3.7 NaN 2022 2022-12-30 64756 2.622 -73.74 41.79 16.6 4.9 10.7 10.3 0.0 5.39 ... NaN 0.159 0.154 -0.2 -0.2 0.3 1.8 3.6 NaN 2022 2022-12-31 64756 2.622 -73.74 41.79 13.2 2.7 7.9 10.2 5.0 1.25 ... NaN 0.160 0.153 -0.1 -0.2 0.3 1.8 3.4 NaN 2022 <p>2557 rows \u00d7 29 columns</p> In\u00a0[31]: Copied! <pre># Get the unique year values\ndf.index.year.unique()\n</pre> # Get the unique year values df.index.year.unique() Out[31]: <pre>Index([2016, 2017, 2018, 2019, 2020, 2021, 2022], dtype='int32', name='LST_DATE')</pre> In\u00a0[32]: Copied! <pre># Sometimes you may want to know the day of year:\n\ndf.index.dayofyear\n</pre> # Sometimes you may want to know the day of year:  df.index.dayofyear  Out[32]: <pre>Index([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n       ...\n       356, 357, 358, 359, 360, 361, 362, 363, 364, 365],\n      dtype='int32', name='LST_DATE', length=2557)</pre> In\u00a0[33]: Copied! <pre># You can also directly get the day of week, which is difficult to program on our own.\n\ndf.index.dayofweek\n</pre> # You can also directly get the day of week, which is difficult to program on our own.  df.index.dayofweek   Out[33]: <pre>Index([4, 5, 6, 0, 1, 2, 3, 4, 5, 6,\n       ...\n       3, 4, 5, 6, 0, 1, 2, 3, 4, 5],\n      dtype='int32', name='LST_DATE', length=2557)</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> <p>Below we resample the dataframe by taking the mean over each month.</p> In\u00a0[34]: Copied! <pre># First, we need to remove the columns that do not have numerical values.\ndf = df.drop(columns = 'SUR_TEMP_DAILY_TYPE')\n</pre> # First, we need to remove the columns that do not have numerical values. df = df.drop(columns = 'SUR_TEMP_DAILY_TYPE') In\u00a0[35]: Copied! <pre>df.resample('ME').mean().plot(y='T_DAILY_MEAN', marker='o')\n</pre> df.resample('ME').mean().plot(y='T_DAILY_MEAN', marker='o')  Out[35]: <pre>&lt;Axes: xlabel='LST_DATE'&gt;</pre> <p>Resampling can be applied to the entire dataframe.</p> In\u00a0[36]: Copied! <pre>df_mm = df.resample('ME').mean()\ndf_mm[['T_DAILY_MIN', 'T_DAILY_MEAN', 'T_DAILY_MAX']].plot()\n</pre> df_mm = df.resample('ME').mean() df_mm[['T_DAILY_MIN', 'T_DAILY_MEAN', 'T_DAILY_MAX']].plot() Out[36]: <pre>&lt;Axes: xlabel='LST_DATE'&gt;</pre> <p>Just like with groupby, we can apply any aggregation function to our resample operation.</p> In\u00a0[37]: Copied! <pre># Resample by maximum values.\ndf.resample('ME').max().plot(y='T_DAILY_MAX', marker='o')\n</pre> # Resample by maximum values. df.resample('ME').max().plot(y='T_DAILY_MAX', marker='o')  Out[37]: <pre>&lt;Axes: xlabel='LST_DATE'&gt;</pre> <p>Rolling mean (or moving average) computes the average of data points in a sliding window over the series. It's typically used to smooth out short-term fluctuations and highlight longer-term trends.</p> In\u00a0[38]: Copied! <pre># Setting the window size to be 30. Center = True means the window is centered at a given index. For example, on 10/15/2022, it will return the mean from 10/01 to 10/30.\ndf.rolling(30, center=True).T_DAILY_MEAN.mean().plot()\n</pre> # Setting the window size to be 30. Center = True means the window is centered at a given index. For example, on 10/15/2022, it will return the mean from 10/01 to 10/30. df.rolling(30, center=True).T_DAILY_MEAN.mean().plot() Out[38]: <pre>&lt;Axes: xlabel='LST_DATE'&gt;</pre> <p>You may notice that there are some breaks in the time series. If there is missing value in the rolling window, pandas will return NaN for the rolling mean.</p> In\u00a0[39]: Copied! <pre># We find 12 observations with missing values for T_DAILY_MEAN. \ndf.loc[(df.T_DAILY_MEAN.isnull())]\n</pre> # We find 12 observations with missing values for T_DAILY_MEAN.  df.loc[(df.T_DAILY_MEAN.isnull())] Out[39]: WBANNO CRX_VN LONGITUDE LATITUDE T_DAILY_MAX T_DAILY_MIN T_DAILY_MEAN T_DAILY_AVG P_DAILY_CALC SOLARAD_DAILY ... SOIL_MOISTURE_20_DAILY SOIL_MOISTURE_50_DAILY SOIL_MOISTURE_100_DAILY SOIL_TEMP_5_DAILY SOIL_TEMP_10_DAILY SOIL_TEMP_20_DAILY SOIL_TEMP_50_DAILY SOIL_TEMP_100_DAILY Unnamed: 28 year LST_DATE 2017-10-04 64756 2.622 -73.74 41.79 NaN NaN NaN NaN NaN NaN ... NaN NaN NaN NaN NaN NaN NaN NaN NaN 2017 2018-10-13 64756 2.622 -73.74 41.79 NaN NaN NaN NaN 4.6 NaN ... NaN NaN NaN NaN NaN NaN NaN NaN NaN 2018 2019-08-10 64756 2.622 -73.74 41.79 NaN NaN NaN NaN NaN NaN ... NaN NaN NaN NaN NaN NaN NaN NaN NaN 2019 2019-08-11 64756 -9.000 -73.74 41.79 NaN NaN NaN NaN NaN NaN ... NaN NaN NaN NaN NaN NaN NaN NaN NaN 2019 2019-08-12 64756 -9.000 -73.74 41.79 NaN NaN NaN NaN NaN NaN ... NaN NaN NaN NaN NaN NaN NaN NaN NaN 2019 2019-08-13 64756 -9.000 -73.74 41.79 NaN NaN NaN NaN NaN NaN ... NaN NaN NaN NaN NaN NaN NaN NaN NaN 2019 2019-08-14 64756 -9.000 -73.74 41.79 NaN NaN NaN NaN NaN NaN ... NaN NaN NaN NaN NaN NaN NaN NaN NaN 2019 2019-08-15 64756 -9.000 -73.74 41.79 NaN NaN NaN NaN NaN NaN ... NaN NaN NaN NaN NaN NaN NaN NaN NaN 2019 2019-08-16 64756 2.622 -73.74 41.79 NaN NaN NaN NaN NaN NaN ... NaN NaN NaN NaN NaN NaN NaN NaN NaN 2019 2019-09-25 64756 2.622 -73.74 41.79 NaN NaN NaN NaN NaN NaN ... NaN NaN NaN NaN NaN NaN NaN NaN NaN 2019 2021-01-04 64756 2.622 -73.74 41.79 NaN NaN NaN NaN NaN NaN ... NaN NaN NaN NaN NaN NaN NaN NaN NaN 2021 2021-11-16 64756 2.622 -73.74 41.79 NaN NaN NaN NaN 0.0 NaN ... NaN NaN NaN NaN NaN NaN NaN NaN NaN 2021 <p>12 rows \u00d7 28 columns</p> <p>Instead of setting the number of observations, we could set the time period of each window. Each window will be a variable sized based on the observations included in the time-period.</p> In\u00a0[41]: Copied! <pre># Note that days with missing values will be skipped. \ndf.rolling('30D', center=True).T_DAILY_MEAN.mean().plot()\n</pre> # Note that days with missing values will be skipped.  df.rolling('30D', center=True).T_DAILY_MEAN.mean().plot()  Out[41]: <pre>&lt;Axes: xlabel='LST_DATE'&gt;</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> <p>Sometimes you may want to fill in the missing values. There are several ways to fill missing data in Pandas.</p> In\u00a0[43]: Copied! <pre># Let's first extract a subset of the data\ndf_sub = df.loc['2017-01-01':'2017-12-31']\n</pre> # Let's first extract a subset of the data df_sub = df.loc['2017-01-01':'2017-12-31'] In\u00a0[44]: Copied! <pre># Note there are data breaks in February.\ndf_sub['SOIL_MOISTURE_10_DAILY'].plot()\n</pre> # Note there are data breaks in February. df_sub['SOIL_MOISTURE_10_DAILY'].plot() Out[44]: <pre>&lt;Axes: xlabel='LST_DATE'&gt;</pre> In\u00a0[45]: Copied! <pre># Fill values forward using ffill function\n\ndf_sub.ffill()['SOIL_MOISTURE_10_DAILY'].plot(label = 'Forward')\n\n# Fill values backward using bfill function\n\ndf_sub.bfill()['SOIL_MOISTURE_10_DAILY'].plot(label = 'Backward')\n\n# Using interpolate function:\n\ndf_sub['SOIL_MOISTURE_10_DAILY'].interpolate('linear').plot(label = 'Linear Interploation')\n\nplt.legend()\n</pre> # Fill values forward using ffill function  df_sub.ffill()['SOIL_MOISTURE_10_DAILY'].plot(label = 'Forward')  # Fill values backward using bfill function  df_sub.bfill()['SOIL_MOISTURE_10_DAILY'].plot(label = 'Backward')  # Using interpolate function:  df_sub['SOIL_MOISTURE_10_DAILY'].interpolate('linear').plot(label = 'Linear Interploation')  plt.legend() Out[45]: <pre>&lt;matplotlib.legend.Legend at 0x3318f06d0&gt;</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> <p>Recall the four major components of time series: seasonality, cycle, trend and variations. Many environmental datasets we deal with (e.g., temperature, precipitation, air quality) vary seasonally. A common way to analyze such data is to create a \"climatology,\" which contains the average values in each month or day of the year. We can do this easily with groupby. Recall that df.index is a pandas DateTimeIndex object.</p> In\u00a0[46]: Copied! <pre>monthly_climatology = df.groupby(df.index.month).mean(numeric_only=True)\nmonthly_climatology\n</pre> monthly_climatology = df.groupby(df.index.month).mean(numeric_only=True) monthly_climatology Out[46]: WBANNO CRX_VN LONGITUDE LATITUDE T_DAILY_MAX T_DAILY_MIN T_DAILY_MEAN T_DAILY_AVG P_DAILY_CALC SOLARAD_DAILY ... SOIL_MOISTURE_20_DAILY SOIL_MOISTURE_50_DAILY SOIL_MOISTURE_100_DAILY SOIL_TEMP_5_DAILY SOIL_TEMP_10_DAILY SOIL_TEMP_20_DAILY SOIL_TEMP_50_DAILY SOIL_TEMP_100_DAILY Unnamed: 28 year LST_DATE 1 64756.0 2.564857 -73.74 41.79 2.200000 -7.550463 -2.678241 -2.442130 2.217130 5.655139 ... 0.230433 0.164727 0.166809 0.393056 0.472685 0.963889 1.983796 3.371759 NaN 2019.000000 2 64756.0 2.564424 -73.74 41.79 4.866162 -5.901010 -0.519192 -0.220202 3.449495 8.359444 ... 0.219145 0.163520 0.165425 0.557071 0.518687 0.707071 1.256566 2.156061 NaN 2018.989899 3 64756.0 2.564857 -73.74 41.79 9.015668 -2.634101 3.184793 3.370046 2.426728 12.813917 ... 0.224130 0.168618 0.166180 3.385714 3.270507 3.157604 3.182488 3.337788 NaN 2019.000000 4 64756.0 2.564857 -73.74 41.79 14.930476 1.948095 8.438095 8.733810 3.217143 14.977381 ... 0.235376 0.165395 0.165433 9.685714 9.460476 8.950000 8.119524 7.199524 NaN 2019.000000 5 64756.0 2.564857 -73.74 41.79 20.996774 8.094009 14.548848 14.772811 3.182949 17.912673 ... 0.221042 0.156848 0.161083 16.721198 16.471889 15.606019 14.184793 12.509217 NaN 2019.000000 6 64756.0 2.564857 -73.74 41.79 25.874286 12.033810 18.952857 19.285714 2.290000 21.610095 ... 0.162114 0.136386 0.153190 22.399524 22.177619 21.112381 19.530476 17.661429 NaN 2019.000000 7 64756.0 2.564857 -73.74 41.79 29.040092 15.894470 22.465899 22.322120 3.880184 20.864101 ... 0.113350 0.118535 0.139206 25.527189 25.406912 24.316204 22.814286 21.129630 NaN 2019.000000 8 64756.0 2.297069 -73.74 41.79 28.139048 15.543810 21.838571 21.615714 3.969048 18.131429 ... 0.128214 0.122652 0.136627 24.912857 24.918095 24.244762 23.358571 22.286190 NaN 2019.000000 9 64756.0 2.564857 -73.74 41.79 23.720096 11.202871 17.460287 17.344019 3.948804 14.033301 ... 0.151890 0.127550 0.141841 20.640191 20.736364 20.594258 20.666986 20.554067 NaN 2019.000000 10 64756.0 2.590664 -73.74 41.79 17.773488 5.738140 11.753023 11.740465 3.637963 9.193674 ... 0.187633 0.141386 0.144750 14.663256 14.799070 15.074419 15.892558 16.645581 NaN 2019.000000 11 64756.0 2.593429 -73.74 41.79 10.377512 -1.277990 4.547368 4.720574 3.301905 6.567895 ... 0.237167 0.166742 0.161895 7.128708 7.302392 7.955288 9.385167 10.990909 NaN 2019.000000 12 64756.0 2.593429 -73.74 41.79 4.488018 -4.917972 -0.217512 0.055760 3.121198 4.639954 ... 0.242934 0.171530 0.170230 2.254839 2.385714 2.946083 4.288479 5.912442 NaN 2019.000000 <p>12 rows \u00d7 28 columns</p> <p>Each row in this new dataframe respresents the average values for the months (1=January, 2=February, etc.)</p> <p>We can apply more customized aggregations, as with any groupby operation. Below we keep the mean of the mean, max of the max, and min of the min for the temperature measurements.</p> In\u00a0[47]: Copied! <pre>monthly_T_climatology = df.groupby(df.index.month).aggregate({'T_DAILY_MEAN': 'mean',\n                                                              'T_DAILY_MAX': 'max',\n                                                              'T_DAILY_MIN': 'min'})\nmonthly_T_climatology\n</pre> monthly_T_climatology = df.groupby(df.index.month).aggregate({'T_DAILY_MEAN': 'mean',                                                               'T_DAILY_MAX': 'max',                                                               'T_DAILY_MIN': 'min'}) monthly_T_climatology Out[47]: T_DAILY_MEAN T_DAILY_MAX T_DAILY_MIN LST_DATE 1 -2.678241 19.8 -26.0 2 -0.519192 24.9 -24.7 3 3.184793 26.8 -17.4 4 8.438095 30.6 -11.3 5 14.548848 33.4 -3.1 6 18.952857 34.5 1.5 7 22.465899 36.2 8.2 8 21.838571 36.5 6.0 9 17.460287 32.7 -1.6 10 11.753023 29.9 -5.9 11 4.547368 24.4 -15.9 12 -0.217512 17.9 -21.8 In\u00a0[48]: Copied! <pre>monthly_T_climatology.plot(marker='o')\n</pre> monthly_T_climatology.plot(marker='o') Out[48]: <pre>&lt;Axes: xlabel='LST_DATE'&gt;</pre> <p>If we want to do it on a finer scale, we can group by day of year.</p> In\u00a0[49]: Copied! <pre>daily_T_climatology = df.groupby(df.index.dayofyear).aggregate({'T_DAILY_MEAN': 'mean',\n                                                            'T_DAILY_MAX': 'max',\n                                                            'T_DAILY_MIN': 'min'})\ndaily_T_climatology.plot(marker='.')\n</pre> daily_T_climatology = df.groupby(df.index.dayofyear).aggregate({'T_DAILY_MEAN': 'mean',                                                             'T_DAILY_MAX': 'max',                                                             'T_DAILY_MIN': 'min'}) daily_T_climatology.plot(marker='.') Out[49]: <pre>&lt;Axes: xlabel='LST_DATE'&gt;</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> <p>A common mode of time series analysis is to remove the seasonality or cyclic patterns from a signal to focus only on the variations or anomaly values. This can be accomplished with transformation.</p> In\u00a0[50]: Copied! <pre>def standardize(x):\n    return (x - x.mean())/x.std()\n\nanomaly = df.groupby(df.index.month).transform(standardize)\n</pre> def standardize(x):     return (x - x.mean())/x.std()  anomaly = df.groupby(df.index.month).transform(standardize)  In\u00a0[51]: Copied! <pre>anomaly.plot(y='T_DAILY_MEAN')\n</pre> anomaly.plot(y='T_DAILY_MEAN') Out[51]: <pre>&lt;Axes: xlabel='LST_DATE'&gt;</pre> <p>We learned about linear regression from previous week. We can similarly apply the linear regression to time series data to fit a linear trend.</p> In\u00a0[52]: Copied! <pre>import statsmodels.api as sm\n</pre> import statsmodels.api as sm <p>To focus on the trend component, we could first resample the data to annual scale, so that the other components of the time series (seasonality and variations) do not affect the trends. Note here we just introduce the most basic trend analysis. Check out Venier et al. (2012) for some advanced trend analysis models used in Environmental Science research.</p> In\u00a0[54]: Copied! <pre>df_year = df.resample('YE').mean()\n</pre> df_year = df.resample('YE').mean() In\u00a0[55]: Copied! <pre>df_year.index\n</pre> df_year.index Out[55]: <pre>DatetimeIndex(['2016-12-31', '2017-12-31', '2018-12-31', '2019-12-31',\n               '2020-12-31', '2021-12-31', '2022-12-31'],\n              dtype='datetime64[ns]', name='LST_DATE', freq='YE-DEC')</pre> <p>statsmodels do not recognize datetime object, so we need to convert Datetime into a numerical variable like float.</p> In\u00a0[56]: Copied! <pre># Define the independent (X) and dependent (y) variables\nX = df_year.index.year   # Independent variable is converted to  year.\ny = df_year['SOIL_MOISTURE_5_DAILY']  # Dependent variable\n</pre> # Define the independent (X) and dependent (y) variables X = df_year.index.year   # Independent variable is converted to  year. y = df_year['SOIL_MOISTURE_5_DAILY']  # Dependent variable  In\u00a0[57]: Copied! <pre># Add a constant (intercept) to X\nX_with_const = sm.add_constant(X)\n\n# Note that the data have missing values. If we want to skip the missing values, we need to set missing to be 'drop'.\nmodel = sm.OLS(y, X_with_const, missing = 'drop').fit()\n</pre> # Add a constant (intercept) to X X_with_const = sm.add_constant(X)  # Note that the data have missing values. If we want to skip the missing values, we need to set missing to be 'drop'. model = sm.OLS(y, X_with_const, missing = 'drop').fit()  In\u00a0[58]: Copied! <pre>pred_y = model.predict(X_with_const)\n</pre> pred_y = model.predict(X_with_const) In\u00a0[59]: Copied! <pre>model.summary()\n</pre> model.summary() <pre>/Users/xjin/miniforge3/envs/esa_env/lib/python3.9/site-packages/statsmodels/stats/stattools.py:74: ValueWarning: omni_normtest is not valid with less than 8 observations; 7 samples were given.\n  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\n</pre> Out[59]: OLS Regression Results Dep. Variable: SOIL_MOISTURE_5_DAILY   R-squared:             0.379 Model: OLS   Adj. R-squared:        0.255 Method: Least Squares   F-statistic:           3.056 Date: Sun, 06 Oct 2024   Prob (F-statistic):  0.141 Time: 15:32:06   Log-Likelihood:       16.947 No. Observations:      7   AIC:                  -29.89 Df Residuals:      5   BIC:                  -30.00 Df Model:      1 Covariance Type: nonrobust coef std err t P&gt;|t| [0.025 0.975] const   -16.7584     9.704    -1.727  0.145   -41.703     8.186 x1     0.0084     0.005     1.748  0.141    -0.004     0.021 Omnibus:    nan   Durbin-Watson:         2.243 Prob(Omnibus):    nan   Jarque-Bera (JB):      0.522 Skew:  0.306   Prob(JB):              0.770 Kurtosis:  1.811   Cond. No.           2.04e+06 Notes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.[2] The condition number is large, 2.04e+06. This might indicate that there arestrong multicollinearity or other numerical problems.  In\u00a0[61]: Copied! <pre>plt.plot(df_year.index,pred_y)\nplt.plot(df_year.index,y)\n</pre> plt.plot(df_year.index,pred_y) plt.plot(df_year.index,y) Out[61]: <pre>[&lt;matplotlib.lines.Line2D at 0x3366977f0&gt;]</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> <p>If the dataset you used for correlation analysis happens to have a temporal dimension, this should be a good dataset to use. This way, you could continue melding this assignment into your final paper.</p> <p>If you have problems finding a good dataset, you could use the ozone measurements we used last week (Millbrook_NY_daily_ozone_2022.csv).</p> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"Week_7_Time_Series_Analysis/#week-7-time-series-analysis","title":"Week 7: Time series analysis\u00b6","text":"<p>Learning Goals:</p> <ol> <li>Understand the Datetime objects in Python.</li> <li>Analyze the four components of time series: seasonality, cycle, trend and variations.</li> </ol>"},{"location":"Week_7_Time_Series_Analysis/#1-working-with-datetime-objects","title":"1. Working with Datetime objects\u00b6","text":""},{"location":"Week_7_Time_Series_Analysis/#11-setting-date-range","title":"1.1 Setting date range\u00b6","text":"<p>The pd.date_range() function allows you to build a DatetimeIndex with a fixed frequency. This can be done by specifying a start date and an end date as follows:</p>"},{"location":"Week_7_Time_Series_Analysis/#12-dealing-with-existing-timestamps","title":"1.2 Dealing with existing timestamps\u00b6","text":"<p>Ideally the tabular data we use already have date and time information. In Pandas, we could set the column type as datetime object.</p> <p>Here we're going to use daily weather data at Millbrook, NY site. We used this dataset last week.</p>"},{"location":"Week_7_Time_Series_Analysis/#13-plotting-time-series-in-pandas","title":"1.3 Plotting time series in Pandas\u00b6","text":""},{"location":"Week_7_Time_Series_Analysis/#exercise-1-make-a-time-series-plot-of-daily-maximum-and-minmum-temperature-you-should-see-two-lines","title":"Exercise 1: Make a time series plot of daily maximum and minmum temperature. You should see two lines.\u00b6","text":""},{"location":"Week_7_Time_Series_Analysis/#14-access-datetime-attributes","title":"1.4 Access datetime attributes\u00b6","text":""},{"location":"Week_7_Time_Series_Analysis/#exercise-2-create-a-column-in-df-that-represents-the-month-of-the-date","title":"Exercise 2: Create a column in <code>df</code> that represents the month of the date.\u00b6","text":""},{"location":"Week_7_Time_Series_Analysis/#2-temporal-resampling","title":"2. Temporal resampling\u00b6","text":"<p>Another common operation we apply to time series is to change the resolution of a dataset by resampling in time. Pandas exposes this through the resample function. The resample periods are specified using pandas offset index syntax.</p>"},{"location":"Week_7_Time_Series_Analysis/#21-resample-function","title":"2.1 Resample function\u00b6","text":""},{"location":"Week_7_Time_Series_Analysis/#22-rolling-operations","title":"2.2 Rolling Operations\u00b6","text":""},{"location":"Week_7_Time_Series_Analysis/#exercise-3-calculate-and-plot-10-day-rolling-mean-of-daily-max-temperature-t_daily_max","title":"Exercise 3: Calculate and plot 10-day rolling mean of daily max temperature <code>T_DAILY_MAX</code>.\u00b6","text":""},{"location":"Week_7_Time_Series_Analysis/#23-filling-missing-data","title":"2.3 Filling missing data\u00b6","text":""},{"location":"Week_7_Time_Series_Analysis/#exercise-4-based-on-the-above-figure-explain-what-is-the-difference-among-ffill-bfill-and-interpolate","title":"Exercise 4: Based on the above figure, explain what is the difference among <code>ffill</code>, <code>bfill</code> and <code>interpolate</code>.\u00b6","text":""},{"location":"Week_7_Time_Series_Analysis/#3-analyze-the-seasonality-and-cyclic-patterns-of-time-series","title":"3. Analyze the seasonality and cyclic patterns of time series\u00b6","text":""},{"location":"Week_7_Time_Series_Analysis/#exercise-5-calculate-and-plot-the-seasonal-cycle-of-solar-radiation-solarad_daily-at-monthly-scale","title":"Exercise 5: Calculate and plot the seasonal cycle of solar radiation <code>SOLARAD_DAILY</code> at monthly scale.\u00b6","text":""},{"location":"Week_7_Time_Series_Analysis/#4-analyze-variations-or-anomalies","title":"4. Analyze variations or anomalies\u00b6","text":""},{"location":"Week_7_Time_Series_Analysis/#5-trend-analysis","title":"5. Trend Analysis\u00b6","text":""},{"location":"Week_7_Time_Series_Analysis/#exercise-6-in-the-above-example-what-is-the-long-term-trend-of-soil_moisture-is-the-trend-statistically-significant-p-value-005","title":"Exercise 6: In the above example, what is the long term trend of SOIL_MOISTURE? Is the trend statistically significant (p value &lt; 0.05)?\u00b6","text":""},{"location":"Week_7_Time_Series_Analysis/#6-assignment-conduct-time-series-analysis-for-a-dataset-youve-found","title":"6. Assignment: Conduct time series analysis for a dataset you've found.\u00b6","text":""},{"location":"Week_7_Time_Series_Analysis/#61-find-out-the-column-that-has-date-or-time-information-read-in-the-file-using-pandas-set-the-parse_dates-to-be-the-columns-of-the-date-and-time","title":"6.1 Find out the column that has date or time information. Read in the file using Pandas. Set the <code>parse_dates</code> to be the column(s) of the date and time.\u00b6","text":""},{"location":"Week_7_Time_Series_Analysis/#62-make-a-time-series-plot-of-one-of-the-measurements-columns","title":"6.2 Make a time series plot of one of the measurements columns.\u00b6","text":""},{"location":"Week_7_Time_Series_Analysis/#63-creat-two-new-columns-year-and-month-to-represent-the-year-and-month-the-data","title":"6.3 Creat two new columns <code>year</code> and <code>month</code> to represent the year and month the data.\u00b6","text":""},{"location":"Week_7_Time_Series_Analysis/#64-calculate-and-plot-the-monthly-climatology-of-the-measurements","title":"6.4 Calculate and plot the monthly climatology of the measurements.\u00b6","text":""},{"location":"Week_7_Time_Series_Analysis/#65-plot-standardized-measurements-with-seasonal-cycle-removed","title":"6.5 Plot standardized measurements with seasonal cycle removed.\u00b6","text":""},{"location":"Week_7_Time_Series_Analysis/#66-calculate-the-long-term-trend-of-the-data-report-the-trend-and-statistical-significance-p-value-of-the-trend","title":"6.6 Calculate the long-term trend of the data. Report the trend and statistical significance (p value) of the trend.\u00b6","text":""},{"location":"Week_8_Environmental_Data_Visualization/","title":"Week 8: Environmental data visualization","text":"<p>This week, we're going to dive into Matplotlib,one of the most widely used Python libraries for data visualization. Matplotlib offers a powerful and flexible way to create a wide range of static, animated, and interactive plots.</p> <p>Let's first import Matplotlib</p> In\u00a0[2]: Copied! <pre>import matplotlib.pyplot as plt\n</pre> import matplotlib.pyplot as plt  <p>Before diving into specific visualizations, let's understand the basic elements of a Matplotlib plot:</p> <p>Figure: The overall window or page that everything is drawn on.  Axes: The area on which the data is plotted (like a graph). Plot: The graphical representation of the data points (line, scatter, etc.). </p> In\u00a0[3]: Copied! <pre>fig = plt.figure()\n</pre> fig = plt.figure() <pre>&lt;Figure size 640x480 with 0 Axes&gt;</pre> In\u00a0[4]: Copied! <pre># Specify figure size\nfig = plt.figure(figsize=(13, 5))\n</pre> # Specify figure size fig = plt.figure(figsize=(13, 5)) <pre>&lt;Figure size 1300x500 with 0 Axes&gt;</pre> <p>Note: figsize parameter controls the width and height of the figure in inches.</p> <p>If you notice the output of the figure size is 1300 x 500, which refers to the number of pixels.</p> <p>The resolution of the figure is controlled by the DPI (Dots Per Inch) setting. By default, Matplotlib uses a DPI of 100, meaning that the number of pixels per inch is 100. So, if you create a figure with figsize=(8, 6), the resulting image will have a resolution of 800 pixels (8 inches \u00d7 100 DPI) by 600 pixels (6 inches \u00d7 100 DPI).</p> <p>You can also change the DPI of the figure:</p> In\u00a0[5]: Copied! <pre># Specify DPI \nfig = plt.figure(figsize=(13, 5), dpi = 150)\n</pre> # Specify DPI  fig = plt.figure(figsize=(13, 5), dpi = 150)  <pre>&lt;Figure size 1950x750 with 0 Axes&gt;</pre> In\u00a0[7]: Copied! <pre>fig = plt.figure()\n\nax = fig.add_axes([0, 0, 1, 1])\n</pre> fig = plt.figure()  ax = fig.add_axes([0, 0, 1, 1]) <p>The list [0, 0, 1, 1] specifies the position and size of the axes in normalized figure coordinates, where values range from 0 to 1. Here's what each element of the list represents:</p> <p>0: The left position of the axes relative to the figure (0 means the far left edge).</p> <p>0: The bottom position of the axes relative to the figure (0 means the bottom edge).</p> <p>1: The width of the axes as a fraction of the figure width (1 means it spans the entire width of the figure).</p> <p>1: The height of the axes as a fraction of the figure height (1 means it spans the entire height of the figure).</p> In\u00a0[8]: Copied! <pre># Define ax that occupies left half of the figure.\nfig = plt.figure()\nax = fig.add_axes([0, 0, 0.5, 1])\n</pre> # Define ax that occupies left half of the figure. fig = plt.figure() ax = fig.add_axes([0, 0, 0.5, 1]) In\u00a0[9]: Copied! <pre># Define multiple axes:\nfig = plt.figure()\nax1 = fig.add_axes([0, 0, 0.5, 1])\n# Set the facecolor of the plot area.\nax2 = fig.add_axes([0.6, 0, 0.3, 0.5], facecolor='g')\n</pre> # Define multiple axes: fig = plt.figure() ax1 = fig.add_axes([0, 0, 0.5, 1]) # Set the facecolor of the plot area. ax2 = fig.add_axes([0.6, 0, 0.3, 0.5], facecolor='g') In\u00a0[10]: Copied! <pre>fig = plt.figure()\naxes = fig.subplots(nrows=2, ncols=3)\n</pre> fig = plt.figure() axes = fig.subplots(nrows=2, ncols=3) In\u00a0[11]: Copied! <pre>fig = plt.figure(figsize=(12, 6))\naxes = fig.subplots(nrows=2, ncols=3)\n</pre> fig = plt.figure(figsize=(12, 6)) axes = fig.subplots(nrows=2, ncols=3) In\u00a0[12]: Copied! <pre># See what axes look like.\naxes\n</pre> # See what axes look like. axes Out[12]: <pre>array([[&lt;Axes: &gt;, &lt;Axes: &gt;, &lt;Axes: &gt;],\n       [&lt;Axes: &gt;, &lt;Axes: &gt;, &lt;Axes: &gt;]], dtype=object)</pre> <p>There is a shorthand for doing this all at once.</p> <p>This is our recommended way to create new figures!</p> In\u00a0[13]: Copied! <pre>fig, ax = plt.subplots()\n</pre> fig, ax = plt.subplots() In\u00a0[18]: Copied! <pre>type(ax)\n</pre> type(ax) Out[18]: <pre>matplotlib.axes._axes.Axes</pre> In\u00a0[15]: Copied! <pre>fig, axes = plt.subplots(ncols=2, figsize=(8, 4), subplot_kw={'facecolor': 'g'})\n</pre> fig, axes = plt.subplots(ncols=2, figsize=(8, 4), subplot_kw={'facecolor': 'g'}) In\u00a0[19]: Copied! <pre>type(axes)\n</pre> type(axes) Out[19]: <pre>numpy.ndarray</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[21]: Copied! <pre># create some data to plot\nimport numpy as np\nx = np.linspace(-np.pi, np.pi, 100)\ny = np.cos(x)\nz = np.sin(6*x)\n</pre> # create some data to plot import numpy as np x = np.linspace(-np.pi, np.pi, 100) y = np.cos(x) z = np.sin(6*x) In\u00a0[22]: Copied! <pre># First, define the figure and ax. \nfig, ax = plt.subplots()\n# Draw data into axes.\nax.plot(x, y)\n</pre> # First, define the figure and ax.  fig, ax = plt.subplots() # Draw data into axes. ax.plot(x, y) Out[22]: <pre>[&lt;matplotlib.lines.Line2D at 0x112ea7520&gt;]</pre> <p>This does the same thing as</p> In\u00a0[23]: Copied! <pre>plt.plot(x, y)\n</pre> plt.plot(x, y) Out[23]: <pre>[&lt;matplotlib.lines.Line2D at 0x1126de580&gt;]</pre> <p>So why do we need to define figure and axes first?</p> <p>This starts to matter when we have multiple axes to worry about.</p> In\u00a0[24]: Copied! <pre># Define to axes (two ploting areas).\nfig, axes = plt.subplots(figsize=(8, 4), ncols=2)\n# axes is a Numpy array, and we can separate them into two variables, each pointing to a ploting area. \nax0, ax1 = axes\n# Plot on the first ax:\nax0.plot(x, y)\n# Plot on the second ax\nax1.plot(x, z)\n</pre> # Define to axes (two ploting areas). fig, axes = plt.subplots(figsize=(8, 4), ncols=2) # axes is a Numpy array, and we can separate them into two variables, each pointing to a ploting area.  ax0, ax1 = axes # Plot on the first ax: ax0.plot(x, y) # Plot on the second ax ax1.plot(x, z) Out[24]: <pre>[&lt;matplotlib.lines.Line2D at 0x1126233a0&gt;]</pre> <p>When making plot, we should always remember to label the x and y axis. Figure title is also important. See Rule #4 of the reading assignment.</p> In\u00a0[27]: Copied! <pre>fig, axes = plt.subplots(figsize=(8, 4), ncols=2)\nax0, ax1 = axes\n\nax0.plot(x, y)\nax0.set_xlabel('x')\nax0.set_ylabel('y')\nax0.set_title('x vs. y')\n\nax1.plot(x, z)\nax1.set_xlabel('x')\nax1.set_ylabel('z')\nax1.set_title('x vs. z')\n\n# squeeze everything in\nplt.tight_layout()\n</pre> fig, axes = plt.subplots(figsize=(8, 4), ncols=2) ax0, ax1 = axes  ax0.plot(x, y) ax0.set_xlabel('x') ax0.set_ylabel('y') ax0.set_title('x vs. y')  ax1.plot(x, z) ax1.set_xlabel('x') ax1.set_ylabel('z') ax1.set_title('x vs. z')  # squeeze everything in plt.tight_layout() In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[32]: Copied! <pre>fig, axes = plt.subplots(figsize=(16, 5), ncols=3)\naxes[0].plot(x, y, linestyle='dashed')\naxes[0].plot(x, z, linestyle='--')\n\naxes[1].plot(x, y, linestyle='dotted')\naxes[1].plot(x, z, linestyle=':')\n\naxes[2].plot(x, y, linestyle='dashdot', linewidth=5)\naxes[2].plot(x, z, linestyle='-.', linewidth=0.5)\n</pre> fig, axes = plt.subplots(figsize=(16, 5), ncols=3) axes[0].plot(x, y, linestyle='dashed') axes[0].plot(x, z, linestyle='--')  axes[1].plot(x, y, linestyle='dotted') axes[1].plot(x, z, linestyle=':')  axes[2].plot(x, y, linestyle='dashdot', linewidth=5) axes[2].plot(x, z, linestyle='-.', linewidth=0.5)  Out[32]: <pre>[&lt;matplotlib.lines.Line2D at 0x171881f70&gt;]</pre> In\u00a0[33]: Copied! <pre>fig, ax = plt.subplots()\nax.plot(x, y, color='k')\nax.plot(x, z, color='r')\n</pre> fig, ax = plt.subplots() ax.plot(x, y, color='k') ax.plot(x, z, color='r') Out[33]: <pre>[&lt;matplotlib.lines.Line2D at 0x17198bf40&gt;]</pre> <p>Other ways to specify colors:</p> In\u00a0[35]: Copied! <pre>fig, axes = plt.subplots(figsize=(16, 5), ncols=3)\n\n# grayscale\naxes[0].plot(x, y, color='0.8')\naxes[0].plot(x, z, color='0.2')\n\n# RGB tuple\naxes[1].plot(x, y, color=(1, 0, 0.7))\naxes[1].plot(x, z, color=(0, 0.4, 0.3))\n\n# HTML hex code: https://htmlcolorcodes.com\naxes[2].plot(x, y, color='#00dcba')\naxes[2].plot(x, z, color='#b029ee')\n</pre> fig, axes = plt.subplots(figsize=(16, 5), ncols=3)  # grayscale axes[0].plot(x, y, color='0.8') axes[0].plot(x, z, color='0.2')  # RGB tuple axes[1].plot(x, y, color=(1, 0, 0.7)) axes[1].plot(x, z, color=(0, 0.4, 0.3))  # HTML hex code: https://htmlcolorcodes.com axes[2].plot(x, y, color='#00dcba') axes[2].plot(x, z, color='#b029ee') Out[35]: <pre>[&lt;matplotlib.lines.Line2D at 0x112edd820&gt;]</pre> <p>There is a default color cycle built into matplotlib.</p> In\u00a0[36]: Copied! <pre>plt.rcParams['axes.prop_cycle']\n</pre> plt.rcParams['axes.prop_cycle'] Out[36]: 'color''#1f77b4''#ff7f0e''#2ca02c''#d62728''#9467bd''#8c564b''#e377c2''#7f7f7f''#bcbd22''#17becf' In\u00a0[37]: Copied! <pre>fig, ax = plt.subplots(figsize=(12, 10))\nfor factor in np.linspace(0.2, 1, 11):\n    ax.plot(x, factor*y)\n</pre> fig, ax = plt.subplots(figsize=(12, 10)) for factor in np.linspace(0.2, 1, 11):     ax.plot(x, factor*y) In\u00a0[38]: Copied! <pre>fig, axes = plt.subplots(figsize=(12, 5), ncols=2)\n\naxes[0].plot(x[:20], y[:20], marker='.')\naxes[0].plot(x[:20], z[:20], marker='o')\n\naxes[1].plot(x[:20], z[:20], marker='^',\n             markersize=10, markerfacecolor='r',\n             markeredgecolor='k')\n</pre> fig, axes = plt.subplots(figsize=(12, 5), ncols=2)  axes[0].plot(x[:20], y[:20], marker='.') axes[0].plot(x[:20], z[:20], marker='o')  axes[1].plot(x[:20], z[:20], marker='^',              markersize=10, markerfacecolor='r',              markeredgecolor='k') Out[38]: <pre>[&lt;matplotlib.lines.Line2D at 0x1130d1cd0&gt;]</pre> In\u00a0[39]: Copied! <pre>fig, ax = plt.subplots(figsize=(12, 7))\nax.plot(x, y)\n\nax.set_xlabel('x')\nax.set_ylabel('y')\nax.set_title('A complicated math function: $f(x) = \\cos(x)$')\n\nax.set_xticks(np.pi * np.array([-1, 0, 1]))\nax.set_xticklabels(['$-\\pi$', '0', '$\\pi$'])\nax.set_yticks([-1, 0, 1])\n\nax.set_yticks(np.arange(-1, 1.1, 0.2), minor=True)\n#ax.set_xticks(np.arange(-3, 3.1, 0.2), minor=True)\n\nax.grid(which='minor', linestyle='--')\nax.grid(which='major', linewidth=2)\n</pre> fig, ax = plt.subplots(figsize=(12, 7)) ax.plot(x, y)  ax.set_xlabel('x') ax.set_ylabel('y') ax.set_title('A complicated math function: $f(x) = \\cos(x)$')  ax.set_xticks(np.pi * np.array([-1, 0, 1])) ax.set_xticklabels(['$-\\pi$', '0', '$\\pi$']) ax.set_yticks([-1, 0, 1])  ax.set_yticks(np.arange(-1, 1.1, 0.2), minor=True) #ax.set_xticks(np.arange(-3, 3.1, 0.2), minor=True)  ax.grid(which='minor', linestyle='--') ax.grid(which='major', linewidth=2)  In\u00a0[41]: Copied! <pre>fig, ax = plt.subplots()\nax.plot(x, y, x, z)\nax.set_xlim(-5, 5)\nax.set_ylim(-3, 3)\n</pre> fig, ax = plt.subplots() ax.plot(x, y, x, z) ax.set_xlim(-5, 5) ax.set_ylim(-3, 3) Out[41]: <pre>(-3.0, 3.0)</pre> <p>The same data, if you set the y axis limit very large, readers may interpret this as a straight line with little variations</p> In\u00a0[42]: Copied! <pre>fig, ax = plt.subplots()\nax.plot(x, y, x, z)\nax.set_xlim(-5, 5)\nax.set_ylim(-100, 100)\n</pre> fig, ax = plt.subplots() ax.plot(x, y, x, z) ax.set_xlim(-5, 5) ax.set_ylim(-100, 100) Out[42]: <pre>(-100.0, 100.0)</pre> In\u00a0[43]: Copied! <pre>fig, ax = plt.subplots()\nax.plot(x, y)\nax.text(-3, 0.3, 'hello world')\n</pre> fig, ax = plt.subplots() ax.plot(x, y) ax.text(-3, 0.3, 'hello world') Out[43]: <pre>Text(-3, 0.3, 'hello world')</pre> <p>The position of the text is set by the data coordinates. If we want to set it relative to the ax, we can set transform:</p> <p>(0, 0) refers to the bottom-left corner of the axes.</p> <p>(1, 1) refers to the top-right corner of the axes.</p> In\u00a0[47]: Copied! <pre>fig, ax = plt.subplots()\nax.plot(x, y)\n\n# Text will be drawn on 10% from the left side of the axes, 90% from the bottom of the axes (close to the top).\nax.text(0.1, 0.9, 'hello world', transform=ax.transAxes)\n</pre> fig, ax = plt.subplots() ax.plot(x, y)  # Text will be drawn on 10% from the left side of the axes, 90% from the bottom of the axes (close to the top). ax.text(0.1, 0.9, 'hello world', transform=ax.transAxes)  Out[47]: <pre>Text(0.1, 0.9, 'hello world')</pre> In\u00a0[50]: Copied! <pre>fig, ax = plt.subplots()\nax.plot(x, y)\nax.annotate('the maximum', xy=(0, 1),\n             xytext=(0, 0), arrowprops={'facecolor': 'k'})\n</pre> fig, ax = plt.subplots() ax.plot(x, y) ax.annotate('the maximum', xy=(0, 1),              xytext=(0, 0), arrowprops={'facecolor': 'k'}) Out[50]: <pre>Text(0, 0, 'the maximum')</pre> <p>Notes: xy referrs to the to annotate. xytext : is the position (x, y) to place the text at. The coordinate system is determined by the data coordinates</p> In\u00a0[60]: Copied! <pre>\n</pre> Out[60]: <pre>Text(0.5, 1.0, 'x vs. y')</pre> In\u00a0[61]: Copied! <pre>fig, ax = plt.subplots()\n# Set color to vary with the value of x, and the size of the marker varies with the function defined.\nsplot = ax.scatter(y, z, c=x, s=(100*z**2 + 5))\nfig.colorbar(splot)\n</pre> fig, ax = plt.subplots() # Set color to vary with the value of x, and the size of the marker varies with the function defined. splot = ax.scatter(y, z, c=x, s=(100*z**2 + 5)) fig.colorbar(splot) Out[61]: <pre>&lt;matplotlib.colorbar.Colorbar at 0x17212ff70&gt;</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[62]: Copied! <pre>labels = ['first', 'second', 'third']\nvalues = [10, 5, 30]\n\nfig, axes = plt.subplots(figsize=(10, 5), ncols=2)\naxes[0].bar(labels, values)\naxes[1].barh(labels, values)\n</pre> labels = ['first', 'second', 'third'] values = [10, 5, 30]  fig, axes = plt.subplots(figsize=(10, 5), ncols=2) axes[0].bar(labels, values) axes[1].barh(labels, values) Out[62]: <pre>&lt;BarContainer object of 3 artists&gt;</pre> <p>In this problem, we will continue using the daily weather data from a NOAA station in Millbrook, NY.</p> <p>The cell below uses pandas to load the data and populate a bunch of numpy arrays (t_daily_min, t_daily_max, etc.)</p> In\u00a0[65]: Copied! <pre>import pandas as pd\n\ndf = pd.read_csv('Millbrook_NY_daily_weather.csv', parse_dates=['LST_DATE'])\ndf = df.set_index('LST_DATE')\n\n#########################################################\n#### BELOW ARE THE VARIABLES YOU SHOULD USE IN THE PLOTS!\n#### (numpy arrays) \n#### NO PANDAS ALLOWED!\n#########################################################\n\nt_daily_min = df.T_DAILY_MIN.values\nt_daily_max = df.T_DAILY_MAX.values\nt_daily_mean = df.T_DAILY_MEAN.values\np_daily_calc = df.P_DAILY_CALC.values\nsoil_moisture_5 = df.SOIL_MOISTURE_5_DAILY.values\nsoil_moisture_10 = df.SOIL_MOISTURE_10_DAILY.values\nsoil_moisture_20 = df.SOIL_MOISTURE_20_DAILY.values\nsoil_moisture_50 = df.SOIL_MOISTURE_50_DAILY.values\nsoil_moisture_100 = df.SOIL_MOISTURE_100_DAILY.values\ndate = df.index.values\n</pre> import pandas as pd  df = pd.read_csv('Millbrook_NY_daily_weather.csv', parse_dates=['LST_DATE']) df = df.set_index('LST_DATE')  ######################################################### #### BELOW ARE THE VARIABLES YOU SHOULD USE IN THE PLOTS! #### (numpy arrays)  #### NO PANDAS ALLOWED! #########################################################  t_daily_min = df.T_DAILY_MIN.values t_daily_max = df.T_DAILY_MAX.values t_daily_mean = df.T_DAILY_MEAN.values p_daily_calc = df.P_DAILY_CALC.values soil_moisture_5 = df.SOIL_MOISTURE_5_DAILY.values soil_moisture_10 = df.SOIL_MOISTURE_10_DAILY.values soil_moisture_20 = df.SOIL_MOISTURE_20_DAILY.values soil_moisture_50 = df.SOIL_MOISTURE_50_DAILY.values soil_moisture_100 = df.SOIL_MOISTURE_100_DAILY.values date = df.index.values <p>Hint Range values can be plotted using fill_between function in matplotlib.</p> In\u00a0[67]: Copied! <pre>\n</pre> <p>Find two figures from your previous assignments (Assignments 6 and 7) that use your own dataset. Improve the visualizations of the data by adding more figure elements, setting an appropriate figure size, adjusting axis limits, applying colors, and adding labels. Try to apply the ten rules you learned to create a compelling figure.</p> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"Week_8_Environmental_Data_Visualization/#week-8-environmental-data-visualization","title":"Week 8: Environmental data visualization\u00b6","text":""},{"location":"Week_8_Environmental_Data_Visualization/#1-basic-components-of-a-matplotlib-plot","title":"1. Basic Components of a Matplotlib Plot\u00b6","text":""},{"location":"Week_8_Environmental_Data_Visualization/#11-figure","title":"1.1 Figure\u00b6","text":"<p>The figure is the highest level of organization of matplotlib objects. If we want, we can create a figure explicitly.</p>"},{"location":"Week_8_Environmental_Data_Visualization/#12-axes","title":"1.2 Axes\u00b6","text":"<p>Axes define the area on which the data is plotted (like a graph).</p>"},{"location":"Week_8_Environmental_Data_Visualization/#13-subplots","title":"1.3 Subplots\u00b6","text":"<p>In Matplotlib, subplots allow you to create multiple plots (also known as axes) in a single figure. This is particularly useful when you want to display several related visualizations side-by-side or in a grid format. The function most commonly used to create subplots is plt.subplots(), which simplifies the process of creating multiple plots and managing their layout.</p>"},{"location":"Week_8_Environmental_Data_Visualization/#exercise-1-create-a-figure-with-3-columns-x-4-rows-axes-set-the-figsize-to-be-10-inches-in-width-and-8-inches-in-height-set-the-facecolor-to-be-purple","title":"Exercise 1: Create a figure with 3 columns x 4 rows axes. Set the figsize to be 10 inches in width, and 8 inches in height. Set the facecolor to be purple.\u00b6","text":""},{"location":"Week_8_Environmental_Data_Visualization/#2-drawing-into-axes","title":"2. Drawing into Axes\u00b6","text":"<p>All plots are drawn into axes. It is easiest to understand how matplotlib works if you use the object-oriented style.</p>"},{"location":"Week_8_Environmental_Data_Visualization/#21-displaying-the-data","title":"2.1 Displaying the data\u00b6","text":""},{"location":"Week_8_Environmental_Data_Visualization/#22-labeling-plots","title":"2.2 Labeling Plots\u00b6","text":""},{"location":"Week_8_Environmental_Data_Visualization/#exercise-2-make-a-figure-with-a-single-ax-and-merge-the-above-two-plots-into-one-plot","title":"Exercise 2: Make a figure with a single ax, and merge the above two plots into one plot.\u00b6","text":""},{"location":"Week_8_Environmental_Data_Visualization/#3-customizing-line-plots","title":"3. Customizing Line Plots\u00b6","text":""},{"location":"Week_8_Environmental_Data_Visualization/#31-line-styles","title":"3.1 Line Styles\u00b6","text":""},{"location":"Week_8_Environmental_Data_Visualization/#32-colors","title":"3.2 Colors\u00b6","text":"<p>As described in the colors documentation, there are some special codes for commonly used colors:</p> <ul> <li>b: blue</li> <li>g: green</li> <li>r: red</li> <li>c: cyan</li> <li>m: magenta</li> <li>y: yellow</li> <li>k: black</li> <li>w: white</li> </ul>"},{"location":"Week_8_Environmental_Data_Visualization/#33-markers","title":"3.3 Markers\u00b6","text":"<p>There are lots of different markers availabile in matplotlib!</p>"},{"location":"Week_8_Environmental_Data_Visualization/#34-label-ticks-and-gridlines","title":"3.4 Label, Ticks, and Gridlines\u00b6","text":""},{"location":"Week_8_Environmental_Data_Visualization/#35-axis-limits","title":"3.5 Axis Limits\u00b6","text":"<p>Setting axis limit can affect how the readers interpret the data. It's recommended to set the axis limit appropriately so that it does mislead the readers (Rule #7 in the reading assignment).</p>"},{"location":"Week_8_Environmental_Data_Visualization/#36-text-annotations","title":"3.6 Text Annotations\u00b6","text":""},{"location":"Week_8_Environmental_Data_Visualization/#annotate-function","title":"Annotate function\u00b6","text":"<p>annotate function is also used to add text annotations to a plot, often with an arrow pointing from the annotation text to a specific point on the plot.</p>"},{"location":"Week_8_Environmental_Data_Visualization/#exercise-3-make-a-plot-that-looks-like-the-figure-below","title":"Exercise 3: Make a plot that looks like the figure below.\u00b6","text":""},{"location":"Week_8_Environmental_Data_Visualization/#4-other-1d-plots","title":"4. Other 1D Plots\u00b6","text":""},{"location":"Week_8_Environmental_Data_Visualization/#41-scatter-plots","title":"4.1 Scatter Plots\u00b6","text":""},{"location":"Week_8_Environmental_Data_Visualization/#42-bar-plots","title":"4.2 Bar Plots\u00b6","text":""},{"location":"Week_8_Environmental_Data_Visualization/#5-assignment","title":"5. Assignment:\u00b6","text":""},{"location":"Week_8_Environmental_Data_Visualization/#51-recreate-a-figure-using-matplotlib","title":"5.1 Recreate a figure using Matplotlib\u00b6","text":""},{"location":"Week_8_Environmental_Data_Visualization/#recreate-the-plot-you-see-below-note-that-you-should-use-the-variables-defined-above-dont-make-plot-use-pandas-please-just-use-matplotlib-to-make-the-plots","title":"Recreate the plot you see below. Note that you should use the variables defined above. Don't make plot use Pandas. Please just use Matplotlib to make the plots!\u00b6","text":""},{"location":"Week_8_Environmental_Data_Visualization/#52-improve-the-figures-you-made-from-previous-home-assignments","title":"5.2 Improve the figures you made from previous home assignments.\u00b6","text":""},{"location":"Week_8_Environmental_Data_Visualization/#figure-1-original-figure","title":"Figure 1: Original figure\u00b6","text":""},{"location":"Week_8_Environmental_Data_Visualization/#figure-1-improved-version","title":"Figure 1: Improved version\u00b6","text":""},{"location":"Week_8_Environmental_Data_Visualization/#figure-2-original-figure","title":"Figure 2: Original figure\u00b6","text":""},{"location":"Week_8_Environmental_Data_Visualization/#figure-2-improved-version","title":"Figure 2: Improved version\u00b6","text":""},{"location":"Week_9_Xarray/","title":"Week 9: Xarray for multidimensional gridded data","text":"<p>Here is an example of how we might structure a dataset for a weather forecast:</p> <p>You'll notice multiple data variables (temperature, precipitation), coordinate variables (latitude, longitude), and dimensions (x, y, t). We'll cover how these fit into Xarray's data structures below.</p> <p>Xarray doesn\u2019t just keep track of labels on arrays \u2013 it uses them to provide a powerful and concise interface. For example:</p> <ul> <li><p>Apply operations over dimensions by name: <code>x.sum('time')</code>.</p> </li> <li><p>Select values by label (or logical location) instead of integer location: <code>x.loc['2014-01-01']</code> or <code>x.sel(time='2014-01-01')</code>.</p> </li> <li><p>Mathematical operations (e.g., <code>x - y</code>) vectorize across multiple dimensions (array broadcasting) based on dimension names, not shape.</p> </li> <li><p>Easily use the split-apply-combine paradigm with groupby: <code>x.groupby('time.dayofyear').mean()</code>.</p> </li> <li><p>Database-like alignment based on coordinate labels that smoothly handles missing values: <code>x, y = xr.align(x, y, join='outer')</code>.</p> </li> <li><p>Keep track of arbitrary metadata in the form of a Python dictionary: <code>x.attrs</code>.</p> </li> </ul> <p>The N-dimensional nature of xarray\u2019s data structures makes it suitable for dealing with multi-dimensional scientific data, and its use of dimension names instead of axis labels (<code>dim='time'</code> instead of <code>axis=0</code>) makes such arrays much more manageable than the raw numpy ndarray: with xarray, you don\u2019t need to keep track of the order of an array\u2019s dimensions or insert dummy dimensions of size 1 to align arrays (e.g., using np.newaxis).</p> <p>The immediate payoff of using xarray is that you\u2019ll write less code. The long-term payoff is that you\u2019ll understand what you were thinking when you come back to look at it weeks or months later.</p> <p>A <code>DataArray</code> has four essential attributes:</p> <ul> <li><code>values</code>: a <code>numpy.ndarray</code> holding the array\u2019s values</li> <li><code>dims</code>: dimension names for each axis (e.g., <code>('x', 'y', 'z')</code>)</li> <li><code>coords</code>: a dict-like container of arrays (coordinates) that label each point (e.g., 1-dimensional arrays of numbers, datetime objects or strings)</li> <li><code>attrs</code>: an <code>OrderedDict</code> to hold arbitrary metadata (attributes)</li> </ul> In\u00a0[1]: Copied! <pre># First import xarray \nimport matplotlib.pyplot as plt\nimport numpy as np\nimport xarray as xr\n</pre> # First import xarray  import matplotlib.pyplot as plt import numpy as np import xarray as xr <p>Here we will focus on using NetCDF data. NetCDF is widely used in international projects, governmental organizations (like NASA, NOAA), and academic institutions. Its adoption in climate models, geospatial data, remote sensing, and weather forecasting systems cements its role as a go-to format for many researchers. NetCDF efficiently handles multidimensional data (e.g., space, time, and variables like temperature or pressure), which is crucial in environmental science analysis where data often have complex, high-dimensional structures. It is commonly used for time series, 3D models, and spatially distributed data.</p> <p>Python's xarray library is widely used for handling NetCDF data due to its powerful and flexible features tailored for working with labeled, multidimensional arrays.</p> <p>Here we use an example air temperature data from NCEP-NCAR Reanalysis .</p> <p>Like Pandas, xarray also has a built-in function to easily read in NetCDF data as an xarray Dataset:</p> In\u00a0[2]: Copied! <pre>ds = xr.open_dataset('air.sig995.2023.nc')\nds\n</pre> ds = xr.open_dataset('air.sig995.2023.nc') ds Out[2]: <pre>&lt;xarray.Dataset&gt;\nDimensions:    (lat: 73, lon: 144, time: 365, nbnds: 2)\nCoordinates:\n  * lat        (lat) float32 90.0 87.5 85.0 82.5 ... -82.5 -85.0 -87.5 -90.0\n  * lon        (lon) float32 0.0 2.5 5.0 7.5 10.0 ... 350.0 352.5 355.0 357.5\n  * time       (time) datetime64[ns] 2023-01-01 2023-01-02 ... 2023-12-31\nDimensions without coordinates: nbnds\nData variables:\n    air        (time, lat, lon) float32 ...\n    time_bnds  (time, nbnds) float64 ...\nAttributes:\n    Conventions:    COARDS\n    title:          mean daily NMC reanalysis (2014)\n    history:        created 2017/12 by Hoop (netCDF2.3)\n    description:    Data is from NMC initialized reanalysis\\n(4x/day).  These...\n    platform:       Model\n    References:     http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reana...\n    dataset_title:  NCEP-NCAR Reanalysis 1</pre>xarray.Dataset<ul><li>Dimensions:<ul><li>lat: 73</li><li>lon: 144</li><li>time: 365</li><li>nbnds: 2</li></ul></li><li>Coordinates: (3)<ul><li>lat(lat)float3290.0 87.5 85.0 ... -87.5 -90.0units :degrees_northactual_range :[ 90. -90.]long_name :Latitudestandard_name :latitudeaxis :Y<pre>array([ 90. ,  87.5,  85. ,  82.5,  80. ,  77.5,  75. ,  72.5,  70. ,  67.5,\n        65. ,  62.5,  60. ,  57.5,  55. ,  52.5,  50. ,  47.5,  45. ,  42.5,\n        40. ,  37.5,  35. ,  32.5,  30. ,  27.5,  25. ,  22.5,  20. ,  17.5,\n        15. ,  12.5,  10. ,   7.5,   5. ,   2.5,   0. ,  -2.5,  -5. ,  -7.5,\n       -10. , -12.5, -15. , -17.5, -20. , -22.5, -25. , -27.5, -30. , -32.5,\n       -35. , -37.5, -40. , -42.5, -45. , -47.5, -50. , -52.5, -55. , -57.5,\n       -60. , -62.5, -65. , -67.5, -70. , -72.5, -75. , -77.5, -80. , -82.5,\n       -85. , -87.5, -90. ], dtype=float32)</pre></li><li>lon(lon)float320.0 2.5 5.0 ... 352.5 355.0 357.5units :degrees_eastlong_name :Longitudeactual_range :[  0.  357.5]standard_name :longitudeaxis :X<pre>array([  0. ,   2.5,   5. ,   7.5,  10. ,  12.5,  15. ,  17.5,  20. ,  22.5,\n        25. ,  27.5,  30. ,  32.5,  35. ,  37.5,  40. ,  42.5,  45. ,  47.5,\n        50. ,  52.5,  55. ,  57.5,  60. ,  62.5,  65. ,  67.5,  70. ,  72.5,\n        75. ,  77.5,  80. ,  82.5,  85. ,  87.5,  90. ,  92.5,  95. ,  97.5,\n       100. , 102.5, 105. , 107.5, 110. , 112.5, 115. , 117.5, 120. , 122.5,\n       125. , 127.5, 130. , 132.5, 135. , 137.5, 140. , 142.5, 145. , 147.5,\n       150. , 152.5, 155. , 157.5, 160. , 162.5, 165. , 167.5, 170. , 172.5,\n       175. , 177.5, 180. , 182.5, 185. , 187.5, 190. , 192.5, 195. , 197.5,\n       200. , 202.5, 205. , 207.5, 210. , 212.5, 215. , 217.5, 220. , 222.5,\n       225. , 227.5, 230. , 232.5, 235. , 237.5, 240. , 242.5, 245. , 247.5,\n       250. , 252.5, 255. , 257.5, 260. , 262.5, 265. , 267.5, 270. , 272.5,\n       275. , 277.5, 280. , 282.5, 285. , 287.5, 290. , 292.5, 295. , 297.5,\n       300. , 302.5, 305. , 307.5, 310. , 312.5, 315. , 317.5, 320. , 322.5,\n       325. , 327.5, 330. , 332.5, 335. , 337.5, 340. , 342.5, 345. , 347.5,\n       350. , 352.5, 355. , 357.5], dtype=float32)</pre></li><li>time(time)datetime64[ns]2023-01-01 ... 2023-12-31long_name :Timedelta_t :0000-00-01 00:00:00standard_name :timeaxis :Tavg_period :0000-00-01 00:00:00coordinate_defines :startactual_range :[1954776. 1963512.]<pre>array(['2023-01-01T00:00:00.000000000', '2023-01-02T00:00:00.000000000',\n       '2023-01-03T00:00:00.000000000', ..., '2023-12-29T00:00:00.000000000',\n       '2023-12-30T00:00:00.000000000', '2023-12-31T00:00:00.000000000'],\n      dtype='datetime64[ns]')</pre></li></ul></li><li>Data variables: (2)<ul><li>air(time, lat, lon)float32...long_name :mean Daily Air temperature at sigma level 995units :degKprecision :2GRIB_id :11GRIB_name :TMPvar_desc :Air temperaturedataset :NCEP Reanalysis Daily Averagesstatistic :Meanparent_stat :Individual Obsvalid_range :[185.16 331.16]level_desc :0.995 sigmaactual_range :[191.4  318.05]<pre>[3836880 values with dtype=float32]</pre></li><li>time_bnds(time, nbnds)float64...<pre>[730 values with dtype=float64]</pre></li></ul></li><li>Indexes: (3)<ul><li>latPandasIndex<pre>PandasIndex(Index([ 90.0,  87.5,  85.0,  82.5,  80.0,  77.5,  75.0,  72.5,  70.0,  67.5,\n        65.0,  62.5,  60.0,  57.5,  55.0,  52.5,  50.0,  47.5,  45.0,  42.5,\n        40.0,  37.5,  35.0,  32.5,  30.0,  27.5,  25.0,  22.5,  20.0,  17.5,\n        15.0,  12.5,  10.0,   7.5,   5.0,   2.5,   0.0,  -2.5,  -5.0,  -7.5,\n       -10.0, -12.5, -15.0, -17.5, -20.0, -22.5, -25.0, -27.5, -30.0, -32.5,\n       -35.0, -37.5, -40.0, -42.5, -45.0, -47.5, -50.0, -52.5, -55.0, -57.5,\n       -60.0, -62.5, -65.0, -67.5, -70.0, -72.5, -75.0, -77.5, -80.0, -82.5,\n       -85.0, -87.5, -90.0],\n      dtype='float32', name='lat'))</pre></li><li>lonPandasIndex<pre>PandasIndex(Index([  0.0,   2.5,   5.0,   7.5,  10.0,  12.5,  15.0,  17.5,  20.0,  22.5,\n       ...\n       335.0, 337.5, 340.0, 342.5, 345.0, 347.5, 350.0, 352.5, 355.0, 357.5],\n      dtype='float32', name='lon', length=144))</pre></li><li>timePandasIndex<pre>PandasIndex(DatetimeIndex(['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04',\n               '2023-01-05', '2023-01-06', '2023-01-07', '2023-01-08',\n               '2023-01-09', '2023-01-10',\n               ...\n               '2023-12-22', '2023-12-23', '2023-12-24', '2023-12-25',\n               '2023-12-26', '2023-12-27', '2023-12-28', '2023-12-29',\n               '2023-12-30', '2023-12-31'],\n              dtype='datetime64[ns]', name='time', length=365, freq=None))</pre></li></ul></li><li>Attributes: (7)Conventions :COARDStitle :mean daily NMC reanalysis (2014)history :created 2017/12 by Hoop (netCDF2.3)description :Data is from NMC initialized reanalysis (4x/day).  These are the 0.9950 sigma level values.platform :ModelReferences :http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reanalysis.htmldataset_title :NCEP-NCAR Reanalysis 1</li></ul> <p>We can access \"layers\" of the Dataset (individual DataArrays) with dictionary syntax</p> In\u00a0[3]: Copied! <pre>ds[\"air\"]\n</pre> ds[\"air\"] Out[3]: <pre>&lt;xarray.DataArray 'air' (time: 365, lat: 73, lon: 144)&gt;\n[3836880 values with dtype=float32]\nCoordinates:\n  * lat      (lat) float32 90.0 87.5 85.0 82.5 80.0 ... -82.5 -85.0 -87.5 -90.0\n  * lon      (lon) float32 0.0 2.5 5.0 7.5 10.0 ... 350.0 352.5 355.0 357.5\n  * time     (time) datetime64[ns] 2023-01-01 2023-01-02 ... 2023-12-31\nAttributes:\n    long_name:     mean Daily Air temperature at sigma level 995\n    units:         degK\n    precision:     2\n    GRIB_id:       11\n    GRIB_name:     TMP\n    var_desc:      Air temperature\n    dataset:       NCEP Reanalysis Daily Averages\n    statistic:     Mean\n    parent_stat:   Individual Obs\n    valid_range:   [185.16 331.16]\n    level_desc:    0.995 sigma\n    actual_range:  [191.4  318.05]</pre>xarray.DataArray'air'<ul><li>time: 365</li><li>lat: 73</li><li>lon: 144</li></ul><ul><li>...<pre>[3836880 values with dtype=float32]</pre></li><li>Coordinates: (3)<ul><li>lat(lat)float3290.0 87.5 85.0 ... -87.5 -90.0units :degrees_northactual_range :[ 90. -90.]long_name :Latitudestandard_name :latitudeaxis :Y<pre>array([ 90. ,  87.5,  85. ,  82.5,  80. ,  77.5,  75. ,  72.5,  70. ,  67.5,\n        65. ,  62.5,  60. ,  57.5,  55. ,  52.5,  50. ,  47.5,  45. ,  42.5,\n        40. ,  37.5,  35. ,  32.5,  30. ,  27.5,  25. ,  22.5,  20. ,  17.5,\n        15. ,  12.5,  10. ,   7.5,   5. ,   2.5,   0. ,  -2.5,  -5. ,  -7.5,\n       -10. , -12.5, -15. , -17.5, -20. , -22.5, -25. , -27.5, -30. , -32.5,\n       -35. , -37.5, -40. , -42.5, -45. , -47.5, -50. , -52.5, -55. , -57.5,\n       -60. , -62.5, -65. , -67.5, -70. , -72.5, -75. , -77.5, -80. , -82.5,\n       -85. , -87.5, -90. ], dtype=float32)</pre></li><li>lon(lon)float320.0 2.5 5.0 ... 352.5 355.0 357.5units :degrees_eastlong_name :Longitudeactual_range :[  0.  357.5]standard_name :longitudeaxis :X<pre>array([  0. ,   2.5,   5. ,   7.5,  10. ,  12.5,  15. ,  17.5,  20. ,  22.5,\n        25. ,  27.5,  30. ,  32.5,  35. ,  37.5,  40. ,  42.5,  45. ,  47.5,\n        50. ,  52.5,  55. ,  57.5,  60. ,  62.5,  65. ,  67.5,  70. ,  72.5,\n        75. ,  77.5,  80. ,  82.5,  85. ,  87.5,  90. ,  92.5,  95. ,  97.5,\n       100. , 102.5, 105. , 107.5, 110. , 112.5, 115. , 117.5, 120. , 122.5,\n       125. , 127.5, 130. , 132.5, 135. , 137.5, 140. , 142.5, 145. , 147.5,\n       150. , 152.5, 155. , 157.5, 160. , 162.5, 165. , 167.5, 170. , 172.5,\n       175. , 177.5, 180. , 182.5, 185. , 187.5, 190. , 192.5, 195. , 197.5,\n       200. , 202.5, 205. , 207.5, 210. , 212.5, 215. , 217.5, 220. , 222.5,\n       225. , 227.5, 230. , 232.5, 235. , 237.5, 240. , 242.5, 245. , 247.5,\n       250. , 252.5, 255. , 257.5, 260. , 262.5, 265. , 267.5, 270. , 272.5,\n       275. , 277.5, 280. , 282.5, 285. , 287.5, 290. , 292.5, 295. , 297.5,\n       300. , 302.5, 305. , 307.5, 310. , 312.5, 315. , 317.5, 320. , 322.5,\n       325. , 327.5, 330. , 332.5, 335. , 337.5, 340. , 342.5, 345. , 347.5,\n       350. , 352.5, 355. , 357.5], dtype=float32)</pre></li><li>time(time)datetime64[ns]2023-01-01 ... 2023-12-31long_name :Timedelta_t :0000-00-01 00:00:00standard_name :timeaxis :Tavg_period :0000-00-01 00:00:00coordinate_defines :startactual_range :[1954776. 1963512.]<pre>array(['2023-01-01T00:00:00.000000000', '2023-01-02T00:00:00.000000000',\n       '2023-01-03T00:00:00.000000000', ..., '2023-12-29T00:00:00.000000000',\n       '2023-12-30T00:00:00.000000000', '2023-12-31T00:00:00.000000000'],\n      dtype='datetime64[ns]')</pre></li></ul></li><li>Indexes: (3)<ul><li>latPandasIndex<pre>PandasIndex(Index([ 90.0,  87.5,  85.0,  82.5,  80.0,  77.5,  75.0,  72.5,  70.0,  67.5,\n        65.0,  62.5,  60.0,  57.5,  55.0,  52.5,  50.0,  47.5,  45.0,  42.5,\n        40.0,  37.5,  35.0,  32.5,  30.0,  27.5,  25.0,  22.5,  20.0,  17.5,\n        15.0,  12.5,  10.0,   7.5,   5.0,   2.5,   0.0,  -2.5,  -5.0,  -7.5,\n       -10.0, -12.5, -15.0, -17.5, -20.0, -22.5, -25.0, -27.5, -30.0, -32.5,\n       -35.0, -37.5, -40.0, -42.5, -45.0, -47.5, -50.0, -52.5, -55.0, -57.5,\n       -60.0, -62.5, -65.0, -67.5, -70.0, -72.5, -75.0, -77.5, -80.0, -82.5,\n       -85.0, -87.5, -90.0],\n      dtype='float32', name='lat'))</pre></li><li>lonPandasIndex<pre>PandasIndex(Index([  0.0,   2.5,   5.0,   7.5,  10.0,  12.5,  15.0,  17.5,  20.0,  22.5,\n       ...\n       335.0, 337.5, 340.0, 342.5, 345.0, 347.5, 350.0, 352.5, 355.0, 357.5],\n      dtype='float32', name='lon', length=144))</pre></li><li>timePandasIndex<pre>PandasIndex(DatetimeIndex(['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04',\n               '2023-01-05', '2023-01-06', '2023-01-07', '2023-01-08',\n               '2023-01-09', '2023-01-10',\n               ...\n               '2023-12-22', '2023-12-23', '2023-12-24', '2023-12-25',\n               '2023-12-26', '2023-12-27', '2023-12-28', '2023-12-29',\n               '2023-12-30', '2023-12-31'],\n              dtype='datetime64[ns]', name='time', length=365, freq=None))</pre></li></ul></li><li>Attributes: (12)long_name :mean Daily Air temperature at sigma level 995units :degKprecision :2GRIB_id :11GRIB_name :TMPvar_desc :Air temperaturedataset :NCEP Reanalysis Daily Averagesstatistic :Meanparent_stat :Individual Obsvalid_range :[185.16 331.16]level_desc :0.995 sigmaactual_range :[191.4  318.05]</li></ul> <p>We can save some typing by using the \"attribute\" or \"dot\" notation. This won't work for variable names that clash with built-in method names (for example, <code>mean</code>).</p> In\u00a0[4]: Copied! <pre>ds.air\n</pre> ds.air Out[4]: <pre>&lt;xarray.DataArray 'air' (time: 365, lat: 73, lon: 144)&gt;\n[3836880 values with dtype=float32]\nCoordinates:\n  * lat      (lat) float32 90.0 87.5 85.0 82.5 80.0 ... -82.5 -85.0 -87.5 -90.0\n  * lon      (lon) float32 0.0 2.5 5.0 7.5 10.0 ... 350.0 352.5 355.0 357.5\n  * time     (time) datetime64[ns] 2023-01-01 2023-01-02 ... 2023-12-31\nAttributes:\n    long_name:     mean Daily Air temperature at sigma level 995\n    units:         degK\n    precision:     2\n    GRIB_id:       11\n    GRIB_name:     TMP\n    var_desc:      Air temperature\n    dataset:       NCEP Reanalysis Daily Averages\n    statistic:     Mean\n    parent_stat:   Individual Obs\n    valid_range:   [185.16 331.16]\n    level_desc:    0.995 sigma\n    actual_range:  [191.4  318.05]</pre>xarray.DataArray'air'<ul><li>time: 365</li><li>lat: 73</li><li>lon: 144</li></ul><ul><li>...<pre>[3836880 values with dtype=float32]</pre></li><li>Coordinates: (3)<ul><li>lat(lat)float3290.0 87.5 85.0 ... -87.5 -90.0units :degrees_northactual_range :[ 90. -90.]long_name :Latitudestandard_name :latitudeaxis :Y<pre>array([ 90. ,  87.5,  85. ,  82.5,  80. ,  77.5,  75. ,  72.5,  70. ,  67.5,\n        65. ,  62.5,  60. ,  57.5,  55. ,  52.5,  50. ,  47.5,  45. ,  42.5,\n        40. ,  37.5,  35. ,  32.5,  30. ,  27.5,  25. ,  22.5,  20. ,  17.5,\n        15. ,  12.5,  10. ,   7.5,   5. ,   2.5,   0. ,  -2.5,  -5. ,  -7.5,\n       -10. , -12.5, -15. , -17.5, -20. , -22.5, -25. , -27.5, -30. , -32.5,\n       -35. , -37.5, -40. , -42.5, -45. , -47.5, -50. , -52.5, -55. , -57.5,\n       -60. , -62.5, -65. , -67.5, -70. , -72.5, -75. , -77.5, -80. , -82.5,\n       -85. , -87.5, -90. ], dtype=float32)</pre></li><li>lon(lon)float320.0 2.5 5.0 ... 352.5 355.0 357.5units :degrees_eastlong_name :Longitudeactual_range :[  0.  357.5]standard_name :longitudeaxis :X<pre>array([  0. ,   2.5,   5. ,   7.5,  10. ,  12.5,  15. ,  17.5,  20. ,  22.5,\n        25. ,  27.5,  30. ,  32.5,  35. ,  37.5,  40. ,  42.5,  45. ,  47.5,\n        50. ,  52.5,  55. ,  57.5,  60. ,  62.5,  65. ,  67.5,  70. ,  72.5,\n        75. ,  77.5,  80. ,  82.5,  85. ,  87.5,  90. ,  92.5,  95. ,  97.5,\n       100. , 102.5, 105. , 107.5, 110. , 112.5, 115. , 117.5, 120. , 122.5,\n       125. , 127.5, 130. , 132.5, 135. , 137.5, 140. , 142.5, 145. , 147.5,\n       150. , 152.5, 155. , 157.5, 160. , 162.5, 165. , 167.5, 170. , 172.5,\n       175. , 177.5, 180. , 182.5, 185. , 187.5, 190. , 192.5, 195. , 197.5,\n       200. , 202.5, 205. , 207.5, 210. , 212.5, 215. , 217.5, 220. , 222.5,\n       225. , 227.5, 230. , 232.5, 235. , 237.5, 240. , 242.5, 245. , 247.5,\n       250. , 252.5, 255. , 257.5, 260. , 262.5, 265. , 267.5, 270. , 272.5,\n       275. , 277.5, 280. , 282.5, 285. , 287.5, 290. , 292.5, 295. , 297.5,\n       300. , 302.5, 305. , 307.5, 310. , 312.5, 315. , 317.5, 320. , 322.5,\n       325. , 327.5, 330. , 332.5, 335. , 337.5, 340. , 342.5, 345. , 347.5,\n       350. , 352.5, 355. , 357.5], dtype=float32)</pre></li><li>time(time)datetime64[ns]2023-01-01 ... 2023-12-31long_name :Timedelta_t :0000-00-01 00:00:00standard_name :timeaxis :Tavg_period :0000-00-01 00:00:00coordinate_defines :startactual_range :[1954776. 1963512.]<pre>array(['2023-01-01T00:00:00.000000000', '2023-01-02T00:00:00.000000000',\n       '2023-01-03T00:00:00.000000000', ..., '2023-12-29T00:00:00.000000000',\n       '2023-12-30T00:00:00.000000000', '2023-12-31T00:00:00.000000000'],\n      dtype='datetime64[ns]')</pre></li></ul></li><li>Indexes: (3)<ul><li>latPandasIndex<pre>PandasIndex(Index([ 90.0,  87.5,  85.0,  82.5,  80.0,  77.5,  75.0,  72.5,  70.0,  67.5,\n        65.0,  62.5,  60.0,  57.5,  55.0,  52.5,  50.0,  47.5,  45.0,  42.5,\n        40.0,  37.5,  35.0,  32.5,  30.0,  27.5,  25.0,  22.5,  20.0,  17.5,\n        15.0,  12.5,  10.0,   7.5,   5.0,   2.5,   0.0,  -2.5,  -5.0,  -7.5,\n       -10.0, -12.5, -15.0, -17.5, -20.0, -22.5, -25.0, -27.5, -30.0, -32.5,\n       -35.0, -37.5, -40.0, -42.5, -45.0, -47.5, -50.0, -52.5, -55.0, -57.5,\n       -60.0, -62.5, -65.0, -67.5, -70.0, -72.5, -75.0, -77.5, -80.0, -82.5,\n       -85.0, -87.5, -90.0],\n      dtype='float32', name='lat'))</pre></li><li>lonPandasIndex<pre>PandasIndex(Index([  0.0,   2.5,   5.0,   7.5,  10.0,  12.5,  15.0,  17.5,  20.0,  22.5,\n       ...\n       335.0, 337.5, 340.0, 342.5, 345.0, 347.5, 350.0, 352.5, 355.0, 357.5],\n      dtype='float32', name='lon', length=144))</pre></li><li>timePandasIndex<pre>PandasIndex(DatetimeIndex(['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04',\n               '2023-01-05', '2023-01-06', '2023-01-07', '2023-01-08',\n               '2023-01-09', '2023-01-10',\n               ...\n               '2023-12-22', '2023-12-23', '2023-12-24', '2023-12-25',\n               '2023-12-26', '2023-12-27', '2023-12-28', '2023-12-29',\n               '2023-12-30', '2023-12-31'],\n              dtype='datetime64[ns]', name='time', length=365, freq=None))</pre></li></ul></li><li>Attributes: (12)long_name :mean Daily Air temperature at sigma level 995units :degKprecision :2GRIB_id :11GRIB_name :TMPvar_desc :Air temperaturedataset :NCEP Reanalysis Daily Averagesstatistic :Meanparent_stat :Individual Obsvalid_range :[185.16 331.16]level_desc :0.995 sigmaactual_range :[191.4  318.05]</li></ul> In\u00a0[5]: Copied! <pre>da = ds[\"air\"]\nda\n</pre> da = ds[\"air\"] da Out[5]: <pre>&lt;xarray.DataArray 'air' (time: 365, lat: 73, lon: 144)&gt;\n[3836880 values with dtype=float32]\nCoordinates:\n  * lat      (lat) float32 90.0 87.5 85.0 82.5 80.0 ... -82.5 -85.0 -87.5 -90.0\n  * lon      (lon) float32 0.0 2.5 5.0 7.5 10.0 ... 350.0 352.5 355.0 357.5\n  * time     (time) datetime64[ns] 2023-01-01 2023-01-02 ... 2023-12-31\nAttributes:\n    long_name:     mean Daily Air temperature at sigma level 995\n    units:         degK\n    precision:     2\n    GRIB_id:       11\n    GRIB_name:     TMP\n    var_desc:      Air temperature\n    dataset:       NCEP Reanalysis Daily Averages\n    statistic:     Mean\n    parent_stat:   Individual Obs\n    valid_range:   [185.16 331.16]\n    level_desc:    0.995 sigma\n    actual_range:  [191.4  318.05]</pre>xarray.DataArray'air'<ul><li>time: 365</li><li>lat: 73</li><li>lon: 144</li></ul><ul><li>...<pre>[3836880 values with dtype=float32]</pre></li><li>Coordinates: (3)<ul><li>lat(lat)float3290.0 87.5 85.0 ... -87.5 -90.0units :degrees_northactual_range :[ 90. -90.]long_name :Latitudestandard_name :latitudeaxis :Y<pre>array([ 90. ,  87.5,  85. ,  82.5,  80. ,  77.5,  75. ,  72.5,  70. ,  67.5,\n        65. ,  62.5,  60. ,  57.5,  55. ,  52.5,  50. ,  47.5,  45. ,  42.5,\n        40. ,  37.5,  35. ,  32.5,  30. ,  27.5,  25. ,  22.5,  20. ,  17.5,\n        15. ,  12.5,  10. ,   7.5,   5. ,   2.5,   0. ,  -2.5,  -5. ,  -7.5,\n       -10. , -12.5, -15. , -17.5, -20. , -22.5, -25. , -27.5, -30. , -32.5,\n       -35. , -37.5, -40. , -42.5, -45. , -47.5, -50. , -52.5, -55. , -57.5,\n       -60. , -62.5, -65. , -67.5, -70. , -72.5, -75. , -77.5, -80. , -82.5,\n       -85. , -87.5, -90. ], dtype=float32)</pre></li><li>lon(lon)float320.0 2.5 5.0 ... 352.5 355.0 357.5units :degrees_eastlong_name :Longitudeactual_range :[  0.  357.5]standard_name :longitudeaxis :X<pre>array([  0. ,   2.5,   5. ,   7.5,  10. ,  12.5,  15. ,  17.5,  20. ,  22.5,\n        25. ,  27.5,  30. ,  32.5,  35. ,  37.5,  40. ,  42.5,  45. ,  47.5,\n        50. ,  52.5,  55. ,  57.5,  60. ,  62.5,  65. ,  67.5,  70. ,  72.5,\n        75. ,  77.5,  80. ,  82.5,  85. ,  87.5,  90. ,  92.5,  95. ,  97.5,\n       100. , 102.5, 105. , 107.5, 110. , 112.5, 115. , 117.5, 120. , 122.5,\n       125. , 127.5, 130. , 132.5, 135. , 137.5, 140. , 142.5, 145. , 147.5,\n       150. , 152.5, 155. , 157.5, 160. , 162.5, 165. , 167.5, 170. , 172.5,\n       175. , 177.5, 180. , 182.5, 185. , 187.5, 190. , 192.5, 195. , 197.5,\n       200. , 202.5, 205. , 207.5, 210. , 212.5, 215. , 217.5, 220. , 222.5,\n       225. , 227.5, 230. , 232.5, 235. , 237.5, 240. , 242.5, 245. , 247.5,\n       250. , 252.5, 255. , 257.5, 260. , 262.5, 265. , 267.5, 270. , 272.5,\n       275. , 277.5, 280. , 282.5, 285. , 287.5, 290. , 292.5, 295. , 297.5,\n       300. , 302.5, 305. , 307.5, 310. , 312.5, 315. , 317.5, 320. , 322.5,\n       325. , 327.5, 330. , 332.5, 335. , 337.5, 340. , 342.5, 345. , 347.5,\n       350. , 352.5, 355. , 357.5], dtype=float32)</pre></li><li>time(time)datetime64[ns]2023-01-01 ... 2023-12-31long_name :Timedelta_t :0000-00-01 00:00:00standard_name :timeaxis :Tavg_period :0000-00-01 00:00:00coordinate_defines :startactual_range :[1954776. 1963512.]<pre>array(['2023-01-01T00:00:00.000000000', '2023-01-02T00:00:00.000000000',\n       '2023-01-03T00:00:00.000000000', ..., '2023-12-29T00:00:00.000000000',\n       '2023-12-30T00:00:00.000000000', '2023-12-31T00:00:00.000000000'],\n      dtype='datetime64[ns]')</pre></li></ul></li><li>Indexes: (3)<ul><li>latPandasIndex<pre>PandasIndex(Index([ 90.0,  87.5,  85.0,  82.5,  80.0,  77.5,  75.0,  72.5,  70.0,  67.5,\n        65.0,  62.5,  60.0,  57.5,  55.0,  52.5,  50.0,  47.5,  45.0,  42.5,\n        40.0,  37.5,  35.0,  32.5,  30.0,  27.5,  25.0,  22.5,  20.0,  17.5,\n        15.0,  12.5,  10.0,   7.5,   5.0,   2.5,   0.0,  -2.5,  -5.0,  -7.5,\n       -10.0, -12.5, -15.0, -17.5, -20.0, -22.5, -25.0, -27.5, -30.0, -32.5,\n       -35.0, -37.5, -40.0, -42.5, -45.0, -47.5, -50.0, -52.5, -55.0, -57.5,\n       -60.0, -62.5, -65.0, -67.5, -70.0, -72.5, -75.0, -77.5, -80.0, -82.5,\n       -85.0, -87.5, -90.0],\n      dtype='float32', name='lat'))</pre></li><li>lonPandasIndex<pre>PandasIndex(Index([  0.0,   2.5,   5.0,   7.5,  10.0,  12.5,  15.0,  17.5,  20.0,  22.5,\n       ...\n       335.0, 337.5, 340.0, 342.5, 345.0, 347.5, 350.0, 352.5, 355.0, 357.5],\n      dtype='float32', name='lon', length=144))</pre></li><li>timePandasIndex<pre>PandasIndex(DatetimeIndex(['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04',\n               '2023-01-05', '2023-01-06', '2023-01-07', '2023-01-08',\n               '2023-01-09', '2023-01-10',\n               ...\n               '2023-12-22', '2023-12-23', '2023-12-24', '2023-12-25',\n               '2023-12-26', '2023-12-27', '2023-12-28', '2023-12-29',\n               '2023-12-30', '2023-12-31'],\n              dtype='datetime64[ns]', name='time', length=365, freq=None))</pre></li></ul></li><li>Attributes: (12)long_name :mean Daily Air temperature at sigma level 995units :degKprecision :2GRIB_id :11GRIB_name :TMPvar_desc :Air temperaturedataset :NCEP Reanalysis Daily Averagesstatistic :Meanparent_stat :Individual Obsvalid_range :[185.16 331.16]level_desc :0.995 sigmaactual_range :[191.4  318.05]</li></ul> <p>We can also access the data array directly:</p> In\u00a0[6]: Copied! <pre>ds.air.data\n</pre> ds.air.data   Out[6]: <pre>array([[[246.57498, 246.57498, 246.57498, ..., 246.57498, 246.57498,\n         246.57498],\n        [248.04999, 247.97498, 247.92499, ..., 248.29999, 248.19998,\n         248.12498],\n        [255.52498, 256.07498, 256.62497, ..., 253.99998, 254.47499,\n         254.99998],\n        ...,\n        [251.32498, 251.49997, 251.69998, ..., 250.97498, 251.04999,\n         251.14998],\n        [251.57498, 251.59998, 251.62497, ..., 251.575  , 251.575  ,\n         251.57498],\n        [251.22498, 251.22498, 251.22498, ..., 251.22498, 251.22498,\n         251.22498]],\n\n       [[248.19998, 248.19998, 248.19998, ..., 248.19998, 248.19998,\n         248.19998],\n        [253.39998, 253.39998, 253.34998, ..., 253.34998, 253.37497,\n         253.37498],\n        [259.3    , 259.97498, 260.55   , ..., 257.14996, 257.87497,\n         258.59998],\n        ...,\n        [252.89996, 253.32497, 253.64996, ..., 251.84998, 252.17497,\n         252.52498],\n        [252.72498, 252.79999, 252.84998, ..., 252.59998, 252.62497,\n         252.69998],\n        [252.79997, 252.79997, 252.79997, ..., 252.79997, 252.79997,\n         252.79997]],\n\n       [[248.20001, 248.20001, 248.20001, ..., 248.20001, 248.20001,\n         248.20001],\n        [256.15   , 255.94998, 255.725  , ..., 256.65   , 256.5    ,\n         256.325  ],\n        [263.32498, 263.625  , 263.925  , ..., 261.95   , 262.475  ,\n         262.925  ],\n        ...,\n        [253.27501, 253.40001, 253.52501, ..., 252.875  , 252.95   ,\n         253.1    ],\n        [252.475  , 252.475  , 252.5    , ..., 252.42499, 252.42499,\n         252.44998],\n        [252.025  , 252.025  , 252.025  , ..., 252.025  , 252.025  ,\n         252.025  ]],\n\n       ...,\n\n       [[248.025  , 248.025  , 248.025  , ..., 248.025  , 248.025  ,\n         248.025  ],\n        [248.34999, 248.17499, 247.99998, ..., 248.74998, 248.625  ,\n         248.47499],\n        [252.275  , 252.22499, 252.15   , ..., 252.22499, 252.24998,\n         252.29999],\n        ...,\n        [249.1    , 249.20001, 249.25   , ..., 248.92499, 248.975  ,\n         249.025  ],\n        [250.6    , 250.425  , 250.275  , ..., 251.125  , 250.925  ,\n         250.75   ],\n        [255.47499, 255.47499, 255.47499, ..., 255.47499, 255.47499,\n         255.47499]],\n\n       [[248.97499, 248.97499, 248.97499, ..., 248.97499, 248.97499,\n         248.97499],\n        [251.825  , 251.67499, 251.44998, ..., 252.29999, 252.15   ,\n         252.02498],\n        [258.95   , 259.175  , 259.325  , ..., 257.65   , 258.125  ,\n         258.6    ],\n        ...,\n        [249.72499, 249.8    , 249.87498, ..., 249.57501, 249.575  ,\n         249.62498],\n        [254.29999, 254.2    , 254.07498, ..., 254.84999, 254.65   ,\n         254.49998],\n        [258.1    , 258.1    , 258.1    , ..., 258.1    , 258.1    ,\n         258.1    ]],\n\n       [[253.82498, 253.82498, 253.82498, ..., 253.82498, 253.82498,\n         253.82498],\n        [257.3    , 257.4    , 257.47498, ..., 257.     , 257.07498,\n         257.19998],\n        [257.65   , 258.75   , 259.8    , ..., 254.42499, 255.44998,\n         256.57498],\n        ...,\n        [253.82498, 253.79999, 253.72499, ..., 253.87497, 253.84998,\n         253.84998],\n        [255.62498, 255.47499, 255.34998, ..., 256.12497, 255.92499,\n         255.72498],\n        [258.72498, 258.72498, 258.72498, ..., 258.72498, 258.72498,\n         258.72498]]], dtype=float32)</pre> In\u00a0[7]: Copied! <pre>ds.air.dims\n</pre> ds.air.dims Out[7]: <pre>('time', 'lat', 'lon')</pre> In\u00a0[8]: Copied! <pre>ds.air.coords\n</pre> ds.air.coords Out[8]: <pre>Coordinates:\n  * lat      (lat) float32 90.0 87.5 85.0 82.5 80.0 ... -82.5 -85.0 -87.5 -90.0\n  * lon      (lon) float32 0.0 2.5 5.0 7.5 10.0 ... 350.0 352.5 355.0 357.5\n  * time     (time) datetime64[ns] 2023-01-01 2023-01-02 ... 2023-12-31</pre> In\u00a0[9]: Copied! <pre>ds.air.attrs\n</pre> ds.air.attrs Out[9]: <pre>{'long_name': 'mean Daily Air temperature at sigma level 995',\n 'units': 'degK',\n 'precision': 2,\n 'GRIB_id': 11,\n 'GRIB_name': 'TMP',\n 'var_desc': 'Air temperature',\n 'dataset': 'NCEP Reanalysis Daily Averages',\n 'statistic': 'Mean',\n 'parent_stat': 'Individual Obs',\n 'valid_range': array([185.16, 331.16], dtype=float32),\n 'level_desc': '0.995 sigma',\n 'actual_range': array([191.4 , 318.05], dtype=float32)}</pre> In\u00a0[10]: Copied! <pre># assign your own attributes!\nds.air.attrs[\"new_attr\"] = \"trial dataset in class\"\nds.air.attrs\n</pre> # assign your own attributes! ds.air.attrs[\"new_attr\"] = \"trial dataset in class\" ds.air.attrs Out[10]: <pre>{'long_name': 'mean Daily Air temperature at sigma level 995',\n 'units': 'degK',\n 'precision': 2,\n 'GRIB_id': 11,\n 'GRIB_name': 'TMP',\n 'var_desc': 'Air temperature',\n 'dataset': 'NCEP Reanalysis Daily Averages',\n 'statistic': 'Mean',\n 'parent_stat': 'Individual Obs',\n 'valid_range': array([185.16, 331.16], dtype=float32),\n 'level_desc': '0.995 sigma',\n 'actual_range': array([191.4 , 318.05], dtype=float32),\n 'new_attr': 'trial dataset in class'}</pre> In\u00a0[11]: Copied! <pre>## Without Xarray, let's try to use matplotlib to plot the data\n\ntemp = ds.air.data\nplt.pcolormesh(temp[0,:,:])\n</pre> ## Without Xarray, let's try to use matplotlib to plot the data  temp = ds.air.data plt.pcolormesh(temp[0,:,:]) Out[11]: <pre>&lt;matplotlib.collections.QuadMesh at 0x192e430a0&gt;</pre> In\u00a0[12]: Copied! <pre>### Add Lat and Lon\n\ntemp = ds.air.data\nlat = ds.air.lat.data\nlon = ds.air.lon.data\nplt.pcolormesh(lon, lat, temp[0,:,:])\n</pre> ### Add Lat and Lon  temp = ds.air.data lat = ds.air.lat.data lon = ds.air.lon.data plt.pcolormesh(lon, lat, temp[0,:,:]) Out[12]: <pre>&lt;matplotlib.collections.QuadMesh at 0x1933156d0&gt;</pre> In\u00a0[13]: Copied! <pre>temp.mean(axis=1)  ## what did I just do? I can't tell by looking at this line.\n</pre> temp.mean(axis=1)  ## what did I just do? I can't tell by looking at this line.  Out[13]: <pre>array([[280.59583, 280.43628, 280.28867, ..., 280.75656, 280.65207,\n        280.58704],\n       [280.29794, 280.4586 , 280.45416, ..., 280.25885, 280.03458,\n        280.04657],\n       [280.10754, 280.03354, 279.92673, ..., 280.4538 , 280.11682,\n        280.101  ],\n       ...,\n       [280.65173, 280.88287, 280.90796, ..., 280.73325, 280.57697,\n        280.5192 ],\n       [280.89075, 281.15482, 281.1534 , ..., 281.20197, 280.81638,\n        280.6781 ],\n       [281.50757, 281.5658 , 281.36743, ..., 281.63388, 281.364  ,\n        281.33322]], dtype=float32)</pre> In\u00a0[14]: Copied! <pre>ds.air.isel(time=0).plot()\n</pre> ds.air.isel(time=0).plot()  Out[14]: <pre>&lt;matplotlib.collections.QuadMesh at 0x19339eb20&gt;</pre> In\u00a0[15]: Copied! <pre>ds.air.mean(dim=\"time\").plot()\n</pre> ds.air.mean(dim=\"time\").plot()  Out[15]: <pre>&lt;matplotlib.collections.QuadMesh at 0x1934e4550&gt;</pre> In\u00a0[19]: Copied! <pre># Select the data by the column and row index.\nda[:, 20, 40]\n</pre> # Select the data by the column and row index. da[:, 20, 40] Out[19]: <pre>&lt;xarray.DataArray 'air' (time: 365)&gt;\narray([264.69998, 265.     , 265.325  , ..., 270.22498, 268.325  , 266.59998],\n      dtype=float32)\nCoordinates:\n    lat      float32 40.0\n    lon      float32 100.0\n  * time     (time) datetime64[ns] 2023-01-01 2023-01-02 ... 2023-12-31\nAttributes: (12/13)\n    long_name:     mean Daily Air temperature at sigma level 995\n    units:         degK\n    precision:     2\n    GRIB_id:       11\n    GRIB_name:     TMP\n    var_desc:      Air temperature\n    ...            ...\n    statistic:     Mean\n    parent_stat:   Individual Obs\n    valid_range:   [185.16 331.16]\n    level_desc:    0.995 sigma\n    actual_range:  [191.4  318.05]\n    new_attr:      trial dataset in class</pre>xarray.DataArray'air'<ul><li>time: 365</li></ul><ul><li>264.7 265.0 265.3 267.8 267.6 273.0 ... 269.2 268.3 270.2 268.3 266.6<pre>array([264.69998, 265.     , 265.325  , ..., 270.22498, 268.325  , 266.59998],\n      dtype=float32)</pre></li><li>Coordinates: (3)<ul><li>lat()float3240.0units :degrees_northactual_range :[ 90. -90.]long_name :Latitudestandard_name :latitudeaxis :Y<pre>array(40., dtype=float32)</pre></li><li>lon()float32100.0units :degrees_eastlong_name :Longitudeactual_range :[  0.  357.5]standard_name :longitudeaxis :X<pre>array(100., dtype=float32)</pre></li><li>time(time)datetime64[ns]2023-01-01 ... 2023-12-31long_name :Timedelta_t :0000-00-01 00:00:00standard_name :timeaxis :Tavg_period :0000-00-01 00:00:00coordinate_defines :startactual_range :[1954776. 1963512.]<pre>array(['2023-01-01T00:00:00.000000000', '2023-01-02T00:00:00.000000000',\n       '2023-01-03T00:00:00.000000000', ..., '2023-12-29T00:00:00.000000000',\n       '2023-12-30T00:00:00.000000000', '2023-12-31T00:00:00.000000000'],\n      dtype='datetime64[ns]')</pre></li></ul></li><li>Indexes: (1)<ul><li>timePandasIndex<pre>PandasIndex(DatetimeIndex(['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04',\n               '2023-01-05', '2023-01-06', '2023-01-07', '2023-01-08',\n               '2023-01-09', '2023-01-10',\n               ...\n               '2023-12-22', '2023-12-23', '2023-12-24', '2023-12-25',\n               '2023-12-26', '2023-12-27', '2023-12-28', '2023-12-29',\n               '2023-12-30', '2023-12-31'],\n              dtype='datetime64[ns]', name='time', length=365, freq=None))</pre></li></ul></li><li>Attributes: (13)long_name :mean Daily Air temperature at sigma level 995units :degKprecision :2GRIB_id :11GRIB_name :TMPvar_desc :Air temperaturedataset :NCEP Reanalysis Daily Averagesstatistic :Meanparent_stat :Individual Obsvalid_range :[185.16 331.16]level_desc :0.995 sigmaactual_range :[191.4  318.05]new_attr :trial dataset in class</li></ul> In\u00a0[20]: Copied! <pre># The first element in the data.\nda[0,0,0]\n</pre> # The first element in the data. da[0,0,0] Out[20]: <pre>&lt;xarray.DataArray 'air' ()&gt;\narray(246.57498, dtype=float32)\nCoordinates:\n    lat      float32 90.0\n    lon      float32 0.0\n    time     datetime64[ns] 2023-01-01\nAttributes: (12/13)\n    long_name:     mean Daily Air temperature at sigma level 995\n    units:         degK\n    precision:     2\n    GRIB_id:       11\n    GRIB_name:     TMP\n    var_desc:      Air temperature\n    ...            ...\n    statistic:     Mean\n    parent_stat:   Individual Obs\n    valid_range:   [185.16 331.16]\n    level_desc:    0.995 sigma\n    actual_range:  [191.4  318.05]\n    new_attr:      trial dataset in class</pre>xarray.DataArray'air'<ul><li>246.6<pre>array(246.57498, dtype=float32)</pre></li><li>Coordinates: (3)<ul><li>lat()float3290.0units :degrees_northactual_range :[ 90. -90.]long_name :Latitudestandard_name :latitudeaxis :Y<pre>array(90., dtype=float32)</pre></li><li>lon()float320.0units :degrees_eastlong_name :Longitudeactual_range :[  0.  357.5]standard_name :longitudeaxis :X<pre>array(0., dtype=float32)</pre></li><li>time()datetime64[ns]2023-01-01long_name :Timedelta_t :0000-00-01 00:00:00standard_name :timeaxis :Tavg_period :0000-00-01 00:00:00coordinate_defines :startactual_range :[1954776. 1963512.]<pre>array('2023-01-01T00:00:00.000000000', dtype='datetime64[ns]')</pre></li></ul></li><li>Indexes: (0)<ul></ul></li><li>Attributes: (13)long_name :mean Daily Air temperature at sigma level 995units :degKprecision :2GRIB_id :11GRIB_name :TMPvar_desc :Air temperaturedataset :NCEP Reanalysis Daily Averagesstatistic :Meanparent_stat :Individual Obsvalid_range :[185.16 331.16]level_desc :0.995 sigmaactual_range :[191.4  318.05]new_attr :trial dataset in class</li></ul> <p>Remembering the axis order can be challenging even with 2D arrays:</p> <ul> <li>is <code>np_array[0,3]</code> the first row and third column or first column and third row?</li> <li>or did I store these samples by row or by column when I saved the data?!</li> </ul> <p>The difficulty is compounded with added dimensions.</p> <p>Xarray objects eliminate much of the mental overhead by allowing indexing using dimension names instead of axes numbers:</p> In\u00a0[22]: Copied! <pre>da.isel(lat=0, lon=0).plot();\n</pre> da.isel(lat=0, lon=0).plot(); <p>Slicing is also possible similarly:</p> In\u00a0[23]: Copied! <pre>da.isel(time=slice(0, 20), lat=0, lon=0).plot();\n</pre> da.isel(time=slice(0, 20), lat=0, lon=0).plot(); <p>Using the <code>isel</code> method, the user can choose/slice the specific elements from a Dataset or DataArray.</p> <p>So far, we have explored positional indexing, which relies on knowing the exact indices. But, what if you wanted to select data specifically for a particular latitude? It becomes challenging to determine the corresponding indices in such cases. Xarray reduce this complexity by introducing label-based indexing.</p> <p>For example, let's select all data for Lat 25 \u00b0N and Lon 210 \u00b0E using <code>sel</code> :</p> In\u00a0[24]: hide-output Copied! <pre>da.sel(lat=25, lon=210).plot();\n</pre> da.sel(lat=25, lon=210).plot(); <p>Similarly we can do slicing or filter a range using the <code>.slice</code> function:</p> In\u00a0[25]: Copied! <pre># demonstrate slicing\nda.sel(lon=slice(210, 215))\n</pre> # demonstrate slicing da.sel(lon=slice(210, 215)) Out[25]: <pre>&lt;xarray.DataArray 'air' (time: 365, lat: 73, lon: 3)&gt;\narray([[[246.57498, 246.57498, 246.57498],\n        [245.04999, 245.14998, 245.27498],\n        ...,\n        [254.42497, 254.54999, 254.64998],\n        [251.22498, 251.22498, 251.22498]],\n\n       [[248.19998, 248.19998, 248.19998],\n        [244.52498, 244.54997, 244.64996],\n        ...,\n        [257.07498, 257.24997, 257.34998],\n        [252.79997, 252.79997, 252.79997]],\n\n       ...,\n\n       [[248.97499, 248.97499, 248.97499],\n        [244.72499, 244.79999, 244.84999],\n        ...,\n        [260.625  , 260.82498, 260.97498],\n        [258.1    , 258.1    , 258.1    ]],\n\n       [[253.82498, 253.82498, 253.82498],\n        [248.75   , 248.9    , 249.07498],\n        ...,\n        [262.375  , 262.57498, 262.775  ],\n        [258.72498, 258.72498, 258.72498]]], dtype=float32)\nCoordinates:\n  * lat      (lat) float32 90.0 87.5 85.0 82.5 80.0 ... -82.5 -85.0 -87.5 -90.0\n  * lon      (lon) float32 210.0 212.5 215.0\n  * time     (time) datetime64[ns] 2023-01-01 2023-01-02 ... 2023-12-31\nAttributes: (12/13)\n    long_name:     mean Daily Air temperature at sigma level 995\n    units:         degK\n    precision:     2\n    GRIB_id:       11\n    GRIB_name:     TMP\n    var_desc:      Air temperature\n    ...            ...\n    statistic:     Mean\n    parent_stat:   Individual Obs\n    valid_range:   [185.16 331.16]\n    level_desc:    0.995 sigma\n    actual_range:  [191.4  318.05]\n    new_attr:      trial dataset in class</pre>xarray.DataArray'air'<ul><li>time: 365</li><li>lat: 73</li><li>lon: 3</li></ul><ul><li>246.6 246.6 246.6 245.0 245.1 245.3 ... 262.6 262.8 258.7 258.7 258.7<pre>array([[[246.57498, 246.57498, 246.57498],\n        [245.04999, 245.14998, 245.27498],\n        ...,\n        [254.42497, 254.54999, 254.64998],\n        [251.22498, 251.22498, 251.22498]],\n\n       [[248.19998, 248.19998, 248.19998],\n        [244.52498, 244.54997, 244.64996],\n        ...,\n        [257.07498, 257.24997, 257.34998],\n        [252.79997, 252.79997, 252.79997]],\n\n       ...,\n\n       [[248.97499, 248.97499, 248.97499],\n        [244.72499, 244.79999, 244.84999],\n        ...,\n        [260.625  , 260.82498, 260.97498],\n        [258.1    , 258.1    , 258.1    ]],\n\n       [[253.82498, 253.82498, 253.82498],\n        [248.75   , 248.9    , 249.07498],\n        ...,\n        [262.375  , 262.57498, 262.775  ],\n        [258.72498, 258.72498, 258.72498]]], dtype=float32)</pre></li><li>Coordinates: (3)<ul><li>lat(lat)float3290.0 87.5 85.0 ... -87.5 -90.0units :degrees_northactual_range :[ 90. -90.]long_name :Latitudestandard_name :latitudeaxis :Y<pre>array([ 90. ,  87.5,  85. ,  82.5,  80. ,  77.5,  75. ,  72.5,  70. ,  67.5,\n        65. ,  62.5,  60. ,  57.5,  55. ,  52.5,  50. ,  47.5,  45. ,  42.5,\n        40. ,  37.5,  35. ,  32.5,  30. ,  27.5,  25. ,  22.5,  20. ,  17.5,\n        15. ,  12.5,  10. ,   7.5,   5. ,   2.5,   0. ,  -2.5,  -5. ,  -7.5,\n       -10. , -12.5, -15. , -17.5, -20. , -22.5, -25. , -27.5, -30. , -32.5,\n       -35. , -37.5, -40. , -42.5, -45. , -47.5, -50. , -52.5, -55. , -57.5,\n       -60. , -62.5, -65. , -67.5, -70. , -72.5, -75. , -77.5, -80. , -82.5,\n       -85. , -87.5, -90. ], dtype=float32)</pre></li><li>lon(lon)float32210.0 212.5 215.0units :degrees_eastlong_name :Longitudeactual_range :[  0.  357.5]standard_name :longitudeaxis :X<pre>array([210. , 212.5, 215. ], dtype=float32)</pre></li><li>time(time)datetime64[ns]2023-01-01 ... 2023-12-31long_name :Timedelta_t :0000-00-01 00:00:00standard_name :timeaxis :Tavg_period :0000-00-01 00:00:00coordinate_defines :startactual_range :[1954776. 1963512.]<pre>array(['2023-01-01T00:00:00.000000000', '2023-01-02T00:00:00.000000000',\n       '2023-01-03T00:00:00.000000000', ..., '2023-12-29T00:00:00.000000000',\n       '2023-12-30T00:00:00.000000000', '2023-12-31T00:00:00.000000000'],\n      dtype='datetime64[ns]')</pre></li></ul></li><li>Indexes: (3)<ul><li>latPandasIndex<pre>PandasIndex(Index([ 90.0,  87.5,  85.0,  82.5,  80.0,  77.5,  75.0,  72.5,  70.0,  67.5,\n        65.0,  62.5,  60.0,  57.5,  55.0,  52.5,  50.0,  47.5,  45.0,  42.5,\n        40.0,  37.5,  35.0,  32.5,  30.0,  27.5,  25.0,  22.5,  20.0,  17.5,\n        15.0,  12.5,  10.0,   7.5,   5.0,   2.5,   0.0,  -2.5,  -5.0,  -7.5,\n       -10.0, -12.5, -15.0, -17.5, -20.0, -22.5, -25.0, -27.5, -30.0, -32.5,\n       -35.0, -37.5, -40.0, -42.5, -45.0, -47.5, -50.0, -52.5, -55.0, -57.5,\n       -60.0, -62.5, -65.0, -67.5, -70.0, -72.5, -75.0, -77.5, -80.0, -82.5,\n       -85.0, -87.5, -90.0],\n      dtype='float32', name='lat'))</pre></li><li>lonPandasIndex<pre>PandasIndex(Index([210.0, 212.5, 215.0], dtype='float32', name='lon'))</pre></li><li>timePandasIndex<pre>PandasIndex(DatetimeIndex(['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04',\n               '2023-01-05', '2023-01-06', '2023-01-07', '2023-01-08',\n               '2023-01-09', '2023-01-10',\n               ...\n               '2023-12-22', '2023-12-23', '2023-12-24', '2023-12-25',\n               '2023-12-26', '2023-12-27', '2023-12-28', '2023-12-29',\n               '2023-12-30', '2023-12-31'],\n              dtype='datetime64[ns]', name='time', length=365, freq=None))</pre></li></ul></li><li>Attributes: (13)long_name :mean Daily Air temperature at sigma level 995units :degKprecision :2GRIB_id :11GRIB_name :TMPvar_desc :Air temperaturedataset :NCEP Reanalysis Daily Averagesstatistic :Meanparent_stat :Individual Obsvalid_range :[185.16 331.16]level_desc :0.995 sigmaactual_range :[191.4  318.05]new_attr :trial dataset in class</li></ul> In\u00a0[26]: Copied! <pre># demonstrate slicing\nda.sel(lat=slice(25, 50))\n</pre> # demonstrate slicing da.sel(lat=slice(25, 50)) Out[26]: <pre>&lt;xarray.DataArray 'air' (time: 365, lat: 0, lon: 144)&gt;\narray([], shape=(365, 0, 144), dtype=float32)\nCoordinates:\n  * lat      (lat) float32 \n  * lon      (lon) float32 0.0 2.5 5.0 7.5 10.0 ... 350.0 352.5 355.0 357.5\n  * time     (time) datetime64[ns] 2023-01-01 2023-01-02 ... 2023-12-31\nAttributes: (12/13)\n    long_name:     mean Daily Air temperature at sigma level 995\n    units:         degK\n    precision:     2\n    GRIB_id:       11\n    GRIB_name:     TMP\n    var_desc:      Air temperature\n    ...            ...\n    statistic:     Mean\n    parent_stat:   Individual Obs\n    valid_range:   [185.16 331.16]\n    level_desc:    0.995 sigma\n    actual_range:  [191.4  318.05]\n    new_attr:      trial dataset in class</pre>xarray.DataArray'air'<ul><li>time: 365</li><li>lat: 0</li><li>lon: 144</li></ul><ul><li><pre>array([], shape=(365, 0, 144), dtype=float32)</pre></li><li>Coordinates: (3)<ul><li>lat(lat)float32units :degrees_northactual_range :[ 90. -90.]long_name :Latitudestandard_name :latitudeaxis :Y<pre>array([], dtype=float32)</pre></li><li>lon(lon)float320.0 2.5 5.0 ... 352.5 355.0 357.5units :degrees_eastlong_name :Longitudeactual_range :[  0.  357.5]standard_name :longitudeaxis :X<pre>array([  0. ,   2.5,   5. ,   7.5,  10. ,  12.5,  15. ,  17.5,  20. ,  22.5,\n        25. ,  27.5,  30. ,  32.5,  35. ,  37.5,  40. ,  42.5,  45. ,  47.5,\n        50. ,  52.5,  55. ,  57.5,  60. ,  62.5,  65. ,  67.5,  70. ,  72.5,\n        75. ,  77.5,  80. ,  82.5,  85. ,  87.5,  90. ,  92.5,  95. ,  97.5,\n       100. , 102.5, 105. , 107.5, 110. , 112.5, 115. , 117.5, 120. , 122.5,\n       125. , 127.5, 130. , 132.5, 135. , 137.5, 140. , 142.5, 145. , 147.5,\n       150. , 152.5, 155. , 157.5, 160. , 162.5, 165. , 167.5, 170. , 172.5,\n       175. , 177.5, 180. , 182.5, 185. , 187.5, 190. , 192.5, 195. , 197.5,\n       200. , 202.5, 205. , 207.5, 210. , 212.5, 215. , 217.5, 220. , 222.5,\n       225. , 227.5, 230. , 232.5, 235. , 237.5, 240. , 242.5, 245. , 247.5,\n       250. , 252.5, 255. , 257.5, 260. , 262.5, 265. , 267.5, 270. , 272.5,\n       275. , 277.5, 280. , 282.5, 285. , 287.5, 290. , 292.5, 295. , 297.5,\n       300. , 302.5, 305. , 307.5, 310. , 312.5, 315. , 317.5, 320. , 322.5,\n       325. , 327.5, 330. , 332.5, 335. , 337.5, 340. , 342.5, 345. , 347.5,\n       350. , 352.5, 355. , 357.5], dtype=float32)</pre></li><li>time(time)datetime64[ns]2023-01-01 ... 2023-12-31long_name :Timedelta_t :0000-00-01 00:00:00standard_name :timeaxis :Tavg_period :0000-00-01 00:00:00coordinate_defines :startactual_range :[1954776. 1963512.]<pre>array(['2023-01-01T00:00:00.000000000', '2023-01-02T00:00:00.000000000',\n       '2023-01-03T00:00:00.000000000', ..., '2023-12-29T00:00:00.000000000',\n       '2023-12-30T00:00:00.000000000', '2023-12-31T00:00:00.000000000'],\n      dtype='datetime64[ns]')</pre></li></ul></li><li>Indexes: (3)<ul><li>latPandasIndex<pre>PandasIndex(Index([], dtype='float32', name='lat'))</pre></li><li>lonPandasIndex<pre>PandasIndex(Index([  0.0,   2.5,   5.0,   7.5,  10.0,  12.5,  15.0,  17.5,  20.0,  22.5,\n       ...\n       335.0, 337.5, 340.0, 342.5, 345.0, 347.5, 350.0, 352.5, 355.0, 357.5],\n      dtype='float32', name='lon', length=144))</pre></li><li>timePandasIndex<pre>PandasIndex(DatetimeIndex(['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04',\n               '2023-01-05', '2023-01-06', '2023-01-07', '2023-01-08',\n               '2023-01-09', '2023-01-10',\n               ...\n               '2023-12-22', '2023-12-23', '2023-12-24', '2023-12-25',\n               '2023-12-26', '2023-12-27', '2023-12-28', '2023-12-29',\n               '2023-12-30', '2023-12-31'],\n              dtype='datetime64[ns]', name='time', length=365, freq=None))</pre></li></ul></li><li>Attributes: (13)long_name :mean Daily Air temperature at sigma level 995units :degKprecision :2GRIB_id :11GRIB_name :TMPvar_desc :Air temperaturedataset :NCEP Reanalysis Daily Averagesstatistic :Meanparent_stat :Individual Obsvalid_range :[185.16 331.16]level_desc :0.995 sigmaactual_range :[191.4  318.05]new_attr :trial dataset in class</li></ul> In\u00a0[27]: Copied! <pre># demonstrate slicing\nda.sel(lat=slice(50, 25), lon=slice(210, 215))\n</pre> # demonstrate slicing da.sel(lat=slice(50, 25), lon=slice(210, 215)) Out[27]: <pre>&lt;xarray.DataArray 'air' (time: 365, lat: 11, lon: 3)&gt;\narray([[[281.     , 281.22498, 282.09998],\n        [282.15   , 282.47498, 283.15   ],\n        ...,\n        [295.55   , 295.12497, 294.97498],\n        [295.8    , 295.59998, 295.55   ]],\n\n       [[279.425  , 279.47498, 280.09998],\n        [280.94998, 281.34998, 281.875  ],\n        ...,\n        [296.09998, 295.8    , 295.97498],\n        [296.25   , 295.9    , 295.8    ]],\n\n       ...,\n\n       [[278.875  , 278.22498, 277.925  ],\n        [279.575  , 279.525  , 279.55   ],\n        ...,\n        [292.47498, 291.675  , 291.625  ],\n        [293.675  , 292.82498, 292.475  ]],\n\n       [[278.2    , 278.02496, 278.97498],\n        [279.175  , 278.84998, 279.44998],\n        ...,\n        [293.22498, 292.675  , 292.975  ],\n        [293.97498, 293.2    , 292.925  ]]], dtype=float32)\nCoordinates:\n  * lat      (lat) float32 50.0 47.5 45.0 42.5 40.0 ... 35.0 32.5 30.0 27.5 25.0\n  * lon      (lon) float32 210.0 212.5 215.0\n  * time     (time) datetime64[ns] 2023-01-01 2023-01-02 ... 2023-12-31\nAttributes: (12/13)\n    long_name:     mean Daily Air temperature at sigma level 995\n    units:         degK\n    precision:     2\n    GRIB_id:       11\n    GRIB_name:     TMP\n    var_desc:      Air temperature\n    ...            ...\n    statistic:     Mean\n    parent_stat:   Individual Obs\n    valid_range:   [185.16 331.16]\n    level_desc:    0.995 sigma\n    actual_range:  [191.4  318.05]\n    new_attr:      trial dataset in class</pre>xarray.DataArray'air'<ul><li>time: 365</li><li>lat: 11</li><li>lon: 3</li></ul><ul><li>281.0 281.2 282.1 282.1 282.5 283.1 ... 292.7 293.0 294.0 293.2 292.9<pre>array([[[281.     , 281.22498, 282.09998],\n        [282.15   , 282.47498, 283.15   ],\n        ...,\n        [295.55   , 295.12497, 294.97498],\n        [295.8    , 295.59998, 295.55   ]],\n\n       [[279.425  , 279.47498, 280.09998],\n        [280.94998, 281.34998, 281.875  ],\n        ...,\n        [296.09998, 295.8    , 295.97498],\n        [296.25   , 295.9    , 295.8    ]],\n\n       ...,\n\n       [[278.875  , 278.22498, 277.925  ],\n        [279.575  , 279.525  , 279.55   ],\n        ...,\n        [292.47498, 291.675  , 291.625  ],\n        [293.675  , 292.82498, 292.475  ]],\n\n       [[278.2    , 278.02496, 278.97498],\n        [279.175  , 278.84998, 279.44998],\n        ...,\n        [293.22498, 292.675  , 292.975  ],\n        [293.97498, 293.2    , 292.925  ]]], dtype=float32)</pre></li><li>Coordinates: (3)<ul><li>lat(lat)float3250.0 47.5 45.0 ... 30.0 27.5 25.0units :degrees_northactual_range :[ 90. -90.]long_name :Latitudestandard_name :latitudeaxis :Y<pre>array([50. , 47.5, 45. , 42.5, 40. , 37.5, 35. , 32.5, 30. , 27.5, 25. ],\n      dtype=float32)</pre></li><li>lon(lon)float32210.0 212.5 215.0units :degrees_eastlong_name :Longitudeactual_range :[  0.  357.5]standard_name :longitudeaxis :X<pre>array([210. , 212.5, 215. ], dtype=float32)</pre></li><li>time(time)datetime64[ns]2023-01-01 ... 2023-12-31long_name :Timedelta_t :0000-00-01 00:00:00standard_name :timeaxis :Tavg_period :0000-00-01 00:00:00coordinate_defines :startactual_range :[1954776. 1963512.]<pre>array(['2023-01-01T00:00:00.000000000', '2023-01-02T00:00:00.000000000',\n       '2023-01-03T00:00:00.000000000', ..., '2023-12-29T00:00:00.000000000',\n       '2023-12-30T00:00:00.000000000', '2023-12-31T00:00:00.000000000'],\n      dtype='datetime64[ns]')</pre></li></ul></li><li>Indexes: (3)<ul><li>latPandasIndex<pre>PandasIndex(Index([50.0, 47.5, 45.0, 42.5, 40.0, 37.5, 35.0, 32.5, 30.0, 27.5, 25.0], dtype='float32', name='lat'))</pre></li><li>lonPandasIndex<pre>PandasIndex(Index([210.0, 212.5, 215.0], dtype='float32', name='lon'))</pre></li><li>timePandasIndex<pre>PandasIndex(DatetimeIndex(['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04',\n               '2023-01-05', '2023-01-06', '2023-01-07', '2023-01-08',\n               '2023-01-09', '2023-01-10',\n               ...\n               '2023-12-22', '2023-12-23', '2023-12-24', '2023-12-25',\n               '2023-12-26', '2023-12-27', '2023-12-28', '2023-12-29',\n               '2023-12-30', '2023-12-31'],\n              dtype='datetime64[ns]', name='time', length=365, freq=None))</pre></li></ul></li><li>Attributes: (13)long_name :mean Daily Air temperature at sigma level 995units :degKprecision :2GRIB_id :11GRIB_name :TMPvar_desc :Air temperaturedataset :NCEP Reanalysis Daily Averagesstatistic :Meanparent_stat :Individual Obsvalid_range :[185.16 331.16]level_desc :0.995 sigmaactual_range :[191.4  318.05]new_attr :trial dataset in class</li></ul> <p>So far, all the above will require us to specify exact coordinate values, but what if we don't have the exact values? We can use nearest neighbor lookups to address this issue:</p> In\u00a0[28]: Copied! <pre>da.sel(lat=52.25, lon=251.8998, method=\"nearest\")\n</pre> da.sel(lat=52.25, lon=251.8998, method=\"nearest\") Out[28]: <pre>&lt;xarray.DataArray 'air' (time: 365)&gt;\narray([261.24997, 266.07498, 266.8    , ..., 273.1    , 267.15   , 268.675  ],\n      dtype=float32)\nCoordinates:\n    lat      float32 52.5\n    lon      float32 252.5\n  * time     (time) datetime64[ns] 2023-01-01 2023-01-02 ... 2023-12-31\nAttributes: (12/13)\n    long_name:     mean Daily Air temperature at sigma level 995\n    units:         degK\n    precision:     2\n    GRIB_id:       11\n    GRIB_name:     TMP\n    var_desc:      Air temperature\n    ...            ...\n    statistic:     Mean\n    parent_stat:   Individual Obs\n    valid_range:   [185.16 331.16]\n    level_desc:    0.995 sigma\n    actual_range:  [191.4  318.05]\n    new_attr:      trial dataset in class</pre>xarray.DataArray'air'<ul><li>time: 365</li></ul><ul><li>261.2 266.1 266.8 266.9 262.3 260.7 ... 274.5 271.4 273.1 267.1 268.7<pre>array([261.24997, 266.07498, 266.8    , ..., 273.1    , 267.15   , 268.675  ],\n      dtype=float32)</pre></li><li>Coordinates: (3)<ul><li>lat()float3252.5units :degrees_northactual_range :[ 90. -90.]long_name :Latitudestandard_name :latitudeaxis :Y<pre>array(52.5, dtype=float32)</pre></li><li>lon()float32252.5units :degrees_eastlong_name :Longitudeactual_range :[  0.  357.5]standard_name :longitudeaxis :X<pre>array(252.5, dtype=float32)</pre></li><li>time(time)datetime64[ns]2023-01-01 ... 2023-12-31long_name :Timedelta_t :0000-00-01 00:00:00standard_name :timeaxis :Tavg_period :0000-00-01 00:00:00coordinate_defines :startactual_range :[1954776. 1963512.]<pre>array(['2023-01-01T00:00:00.000000000', '2023-01-02T00:00:00.000000000',\n       '2023-01-03T00:00:00.000000000', ..., '2023-12-29T00:00:00.000000000',\n       '2023-12-30T00:00:00.000000000', '2023-12-31T00:00:00.000000000'],\n      dtype='datetime64[ns]')</pre></li></ul></li><li>Indexes: (1)<ul><li>timePandasIndex<pre>PandasIndex(DatetimeIndex(['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04',\n               '2023-01-05', '2023-01-06', '2023-01-07', '2023-01-08',\n               '2023-01-09', '2023-01-10',\n               ...\n               '2023-12-22', '2023-12-23', '2023-12-24', '2023-12-25',\n               '2023-12-26', '2023-12-27', '2023-12-28', '2023-12-29',\n               '2023-12-30', '2023-12-31'],\n              dtype='datetime64[ns]', name='time', length=365, freq=None))</pre></li></ul></li><li>Attributes: (13)long_name :mean Daily Air temperature at sigma level 995units :degKprecision :2GRIB_id :11GRIB_name :TMPvar_desc :Air temperaturedataset :NCEP Reanalysis Daily Averagesstatistic :Meanparent_stat :Individual Obsvalid_range :[185.16 331.16]level_desc :0.995 sigmaactual_range :[191.4  318.05]new_attr :trial dataset in class</li></ul> In\u00a0[29]: Copied! <pre>da.sel(lat=52.25, lon=251.8998, method=\"ffill\")\n</pre> da.sel(lat=52.25, lon=251.8998, method=\"ffill\") Out[29]: <pre>&lt;xarray.DataArray 'air' (time: 365)&gt;\narray([264.99997, 268.32498, 266.5    , ..., 274.8    , 270.7    , 271.85   ],\n      dtype=float32)\nCoordinates:\n    lat      float32 52.5\n    lon      float32 250.0\n  * time     (time) datetime64[ns] 2023-01-01 2023-01-02 ... 2023-12-31\nAttributes: (12/13)\n    long_name:     mean Daily Air temperature at sigma level 995\n    units:         degK\n    precision:     2\n    GRIB_id:       11\n    GRIB_name:     TMP\n    var_desc:      Air temperature\n    ...            ...\n    statistic:     Mean\n    parent_stat:   Individual Obs\n    valid_range:   [185.16 331.16]\n    level_desc:    0.995 sigma\n    actual_range:  [191.4  318.05]\n    new_attr:      trial dataset in class</pre>xarray.DataArray'air'<ul><li>time: 365</li></ul><ul><li>265.0 268.3 266.5 267.7 263.6 266.2 ... 274.5 274.4 274.8 270.7 271.9<pre>array([264.99997, 268.32498, 266.5    , ..., 274.8    , 270.7    , 271.85   ],\n      dtype=float32)</pre></li><li>Coordinates: (3)<ul><li>lat()float3252.5units :degrees_northactual_range :[ 90. -90.]long_name :Latitudestandard_name :latitudeaxis :Y<pre>array(52.5, dtype=float32)</pre></li><li>lon()float32250.0units :degrees_eastlong_name :Longitudeactual_range :[  0.  357.5]standard_name :longitudeaxis :X<pre>array(250., dtype=float32)</pre></li><li>time(time)datetime64[ns]2023-01-01 ... 2023-12-31long_name :Timedelta_t :0000-00-01 00:00:00standard_name :timeaxis :Tavg_period :0000-00-01 00:00:00coordinate_defines :startactual_range :[1954776. 1963512.]<pre>array(['2023-01-01T00:00:00.000000000', '2023-01-02T00:00:00.000000000',\n       '2023-01-03T00:00:00.000000000', ..., '2023-12-29T00:00:00.000000000',\n       '2023-12-30T00:00:00.000000000', '2023-12-31T00:00:00.000000000'],\n      dtype='datetime64[ns]')</pre></li></ul></li><li>Indexes: (1)<ul><li>timePandasIndex<pre>PandasIndex(DatetimeIndex(['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04',\n               '2023-01-05', '2023-01-06', '2023-01-07', '2023-01-08',\n               '2023-01-09', '2023-01-10',\n               ...\n               '2023-12-22', '2023-12-23', '2023-12-24', '2023-12-25',\n               '2023-12-26', '2023-12-27', '2023-12-28', '2023-12-29',\n               '2023-12-30', '2023-12-31'],\n              dtype='datetime64[ns]', name='time', length=365, freq=None))</pre></li></ul></li><li>Attributes: (13)long_name :mean Daily Air temperature at sigma level 995units :degKprecision :2GRIB_id :11GRIB_name :TMPvar_desc :Air temperaturedataset :NCEP Reanalysis Daily Averagesstatistic :Meanparent_stat :Individual Obsvalid_range :[185.16 331.16]level_desc :0.995 sigmaactual_range :[191.4  318.05]new_attr :trial dataset in class</li></ul> <p><code>tolerance</code> argument limits the maximum distance for valid matches with an inexact lookup:</p> In\u00a0[30]: Copied! <pre>da.sel(lat=52.25, lon=251.8998, method=\"nearest\", tolerance=2)\n</pre> da.sel(lat=52.25, lon=251.8998, method=\"nearest\", tolerance=2) Out[30]: <pre>&lt;xarray.DataArray 'air' (time: 365)&gt;\narray([261.24997, 266.07498, 266.8    , ..., 273.1    , 267.15   , 268.675  ],\n      dtype=float32)\nCoordinates:\n    lat      float32 52.5\n    lon      float32 252.5\n  * time     (time) datetime64[ns] 2023-01-01 2023-01-02 ... 2023-12-31\nAttributes: (12/13)\n    long_name:     mean Daily Air temperature at sigma level 995\n    units:         degK\n    precision:     2\n    GRIB_id:       11\n    GRIB_name:     TMP\n    var_desc:      Air temperature\n    ...            ...\n    statistic:     Mean\n    parent_stat:   Individual Obs\n    valid_range:   [185.16 331.16]\n    level_desc:    0.995 sigma\n    actual_range:  [191.4  318.05]\n    new_attr:      trial dataset in class</pre>xarray.DataArray'air'<ul><li>time: 365</li></ul><ul><li>261.2 266.1 266.8 266.9 262.3 260.7 ... 274.5 271.4 273.1 267.1 268.7<pre>array([261.24997, 266.07498, 266.8    , ..., 273.1    , 267.15   , 268.675  ],\n      dtype=float32)</pre></li><li>Coordinates: (3)<ul><li>lat()float3252.5units :degrees_northactual_range :[ 90. -90.]long_name :Latitudestandard_name :latitudeaxis :Y<pre>array(52.5, dtype=float32)</pre></li><li>lon()float32252.5units :degrees_eastlong_name :Longitudeactual_range :[  0.  357.5]standard_name :longitudeaxis :X<pre>array(252.5, dtype=float32)</pre></li><li>time(time)datetime64[ns]2023-01-01 ... 2023-12-31long_name :Timedelta_t :0000-00-01 00:00:00standard_name :timeaxis :Tavg_period :0000-00-01 00:00:00coordinate_defines :startactual_range :[1954776. 1963512.]<pre>array(['2023-01-01T00:00:00.000000000', '2023-01-02T00:00:00.000000000',\n       '2023-01-03T00:00:00.000000000', ..., '2023-12-29T00:00:00.000000000',\n       '2023-12-30T00:00:00.000000000', '2023-12-31T00:00:00.000000000'],\n      dtype='datetime64[ns]')</pre></li></ul></li><li>Indexes: (1)<ul><li>timePandasIndex<pre>PandasIndex(DatetimeIndex(['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04',\n               '2023-01-05', '2023-01-06', '2023-01-07', '2023-01-08',\n               '2023-01-09', '2023-01-10',\n               ...\n               '2023-12-22', '2023-12-23', '2023-12-24', '2023-12-25',\n               '2023-12-26', '2023-12-27', '2023-12-28', '2023-12-29',\n               '2023-12-30', '2023-12-31'],\n              dtype='datetime64[ns]', name='time', length=365, freq=None))</pre></li></ul></li><li>Attributes: (13)long_name :mean Daily Air temperature at sigma level 995units :degKprecision :2GRIB_id :11GRIB_name :TMPvar_desc :Air temperaturedataset :NCEP Reanalysis Daily Averagesstatistic :Meanparent_stat :Individual Obsvalid_range :[185.16 331.16]level_desc :0.995 sigmaactual_range :[191.4  318.05]new_attr :trial dataset in class</li></ul> In\u00a0[31]: Copied! <pre>da.sel(lat=52.25, lon=198, method=\"nearest\", tolerance=2)\n</pre> da.sel(lat=52.25, lon=198, method=\"nearest\", tolerance=2) Out[31]: <pre>&lt;xarray.DataArray 'air' (time: 365)&gt;\narray([277.4    , 276.37497, 275.     , ..., 277.07498, 277.075  , 276.05   ],\n      dtype=float32)\nCoordinates:\n    lat      float32 52.5\n    lon      float32 197.5\n  * time     (time) datetime64[ns] 2023-01-01 2023-01-02 ... 2023-12-31\nAttributes: (12/13)\n    long_name:     mean Daily Air temperature at sigma level 995\n    units:         degK\n    precision:     2\n    GRIB_id:       11\n    GRIB_name:     TMP\n    var_desc:      Air temperature\n    ...            ...\n    statistic:     Mean\n    parent_stat:   Individual Obs\n    valid_range:   [185.16 331.16]\n    level_desc:    0.995 sigma\n    actual_range:  [191.4  318.05]\n    new_attr:      trial dataset in class</pre>xarray.DataArray'air'<ul><li>time: 365</li></ul><ul><li>277.4 276.4 275.0 274.7 274.9 275.7 ... 274.7 273.9 277.1 277.1 276.0<pre>array([277.4    , 276.37497, 275.     , ..., 277.07498, 277.075  , 276.05   ],\n      dtype=float32)</pre></li><li>Coordinates: (3)<ul><li>lat()float3252.5units :degrees_northactual_range :[ 90. -90.]long_name :Latitudestandard_name :latitudeaxis :Y<pre>array(52.5, dtype=float32)</pre></li><li>lon()float32197.5units :degrees_eastlong_name :Longitudeactual_range :[  0.  357.5]standard_name :longitudeaxis :X<pre>array(197.5, dtype=float32)</pre></li><li>time(time)datetime64[ns]2023-01-01 ... 2023-12-31long_name :Timedelta_t :0000-00-01 00:00:00standard_name :timeaxis :Tavg_period :0000-00-01 00:00:00coordinate_defines :startactual_range :[1954776. 1963512.]<pre>array(['2023-01-01T00:00:00.000000000', '2023-01-02T00:00:00.000000000',\n       '2023-01-03T00:00:00.000000000', ..., '2023-12-29T00:00:00.000000000',\n       '2023-12-30T00:00:00.000000000', '2023-12-31T00:00:00.000000000'],\n      dtype='datetime64[ns]')</pre></li></ul></li><li>Indexes: (1)<ul><li>timePandasIndex<pre>PandasIndex(DatetimeIndex(['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04',\n               '2023-01-05', '2023-01-06', '2023-01-07', '2023-01-08',\n               '2023-01-09', '2023-01-10',\n               ...\n               '2023-12-22', '2023-12-23', '2023-12-24', '2023-12-25',\n               '2023-12-26', '2023-12-27', '2023-12-28', '2023-12-29',\n               '2023-12-30', '2023-12-31'],\n              dtype='datetime64[ns]', name='time', length=365, freq=None))</pre></li></ul></li><li>Attributes: (13)long_name :mean Daily Air temperature at sigma level 995units :degKprecision :2GRIB_id :11GRIB_name :TMPvar_desc :Air temperaturedataset :NCEP Reanalysis Daily Averagesstatistic :Meanparent_stat :Individual Obsvalid_range :[185.16 331.16]level_desc :0.995 sigmaactual_range :[191.4  318.05]new_attr :trial dataset in class</li></ul> <pre><code>{tip}\nAll of these indexing methods work on the dataset too!\n</code></pre> <p>We can also use these methods to index all variables in a dataset simultaneously, returning a new dataset:</p> In\u00a0[32]: Copied! <pre>ds.sel(lat=52.25, lon=251.8998, method=\"nearest\")\n</pre> ds.sel(lat=52.25, lon=251.8998, method=\"nearest\") Out[32]: <pre>&lt;xarray.Dataset&gt;\nDimensions:    (time: 365, nbnds: 2)\nCoordinates:\n    lat        float32 52.5\n    lon        float32 252.5\n  * time       (time) datetime64[ns] 2023-01-01 2023-01-02 ... 2023-12-31\nDimensions without coordinates: nbnds\nData variables:\n    air        (time) float32 261.2 266.1 266.8 266.9 ... 273.1 267.1 268.7\n    time_bnds  (time, nbnds) float64 ...\nAttributes:\n    Conventions:    COARDS\n    title:          mean daily NMC reanalysis (2014)\n    history:        created 2017/12 by Hoop (netCDF2.3)\n    description:    Data is from NMC initialized reanalysis\\n(4x/day).  These...\n    platform:       Model\n    References:     http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reana...\n    dataset_title:  NCEP-NCAR Reanalysis 1</pre>xarray.Dataset<ul><li>Dimensions:<ul><li>time: 365</li><li>nbnds: 2</li></ul></li><li>Coordinates: (3)<ul><li>lat()float3252.5units :degrees_northactual_range :[ 90. -90.]long_name :Latitudestandard_name :latitudeaxis :Y<pre>array(52.5, dtype=float32)</pre></li><li>lon()float32252.5units :degrees_eastlong_name :Longitudeactual_range :[  0.  357.5]standard_name :longitudeaxis :X<pre>array(252.5, dtype=float32)</pre></li><li>time(time)datetime64[ns]2023-01-01 ... 2023-12-31long_name :Timedelta_t :0000-00-01 00:00:00standard_name :timeaxis :Tavg_period :0000-00-01 00:00:00coordinate_defines :startactual_range :[1954776. 1963512.]<pre>array(['2023-01-01T00:00:00.000000000', '2023-01-02T00:00:00.000000000',\n       '2023-01-03T00:00:00.000000000', ..., '2023-12-29T00:00:00.000000000',\n       '2023-12-30T00:00:00.000000000', '2023-12-31T00:00:00.000000000'],\n      dtype='datetime64[ns]')</pre></li></ul></li><li>Data variables: (2)<ul><li>air(time)float32261.2 266.1 266.8 ... 267.1 268.7long_name :mean Daily Air temperature at sigma level 995units :degKprecision :2GRIB_id :11GRIB_name :TMPvar_desc :Air temperaturedataset :NCEP Reanalysis Daily Averagesstatistic :Meanparent_stat :Individual Obsvalid_range :[185.16 331.16]level_desc :0.995 sigmaactual_range :[191.4  318.05]new_attr :trial dataset in class<pre>array([261.24997, 266.07498, 266.8    , ..., 273.1    , 267.15   , 268.675  ],\n      dtype=float32)</pre></li><li>time_bnds(time, nbnds)float64...<pre>[730 values with dtype=float64]</pre></li></ul></li><li>Indexes: (1)<ul><li>timePandasIndex<pre>PandasIndex(DatetimeIndex(['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04',\n               '2023-01-05', '2023-01-06', '2023-01-07', '2023-01-08',\n               '2023-01-09', '2023-01-10',\n               ...\n               '2023-12-22', '2023-12-23', '2023-12-24', '2023-12-25',\n               '2023-12-26', '2023-12-27', '2023-12-28', '2023-12-29',\n               '2023-12-30', '2023-12-31'],\n              dtype='datetime64[ns]', name='time', length=365, freq=None))</pre></li></ul></li><li>Attributes: (7)Conventions :COARDStitle :mean daily NMC reanalysis (2014)history :created 2017/12 by Hoop (netCDF2.3)description :Data is from NMC initialized reanalysis (4x/day).  These are the 0.9950 sigma level values.platform :ModelReferences :http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reanalysis.htmldataset_title :NCEP-NCAR Reanalysis 1</li></ul> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[36]: Copied! <pre>ds.sel(time='2023-05-01')\n</pre> ds.sel(time='2023-05-01') Out[36]: <pre>&lt;xarray.Dataset&gt;\nDimensions:    (lat: 73, lon: 144, nbnds: 2)\nCoordinates:\n  * lat        (lat) float32 90.0 87.5 85.0 82.5 ... -82.5 -85.0 -87.5 -90.0\n  * lon        (lon) float32 0.0 2.5 5.0 7.5 10.0 ... 350.0 352.5 355.0 357.5\n    time       datetime64[ns] 2023-05-01\nDimensions without coordinates: nbnds\nData variables:\n    air        (lat, lon) float32 259.0 259.0 259.0 259.0 ... 222.2 222.2 222.2\n    time_bnds  (nbnds) float64 ...\nAttributes:\n    Conventions:    COARDS\n    title:          mean daily NMC reanalysis (2014)\n    history:        created 2017/12 by Hoop (netCDF2.3)\n    description:    Data is from NMC initialized reanalysis\\n(4x/day).  These...\n    platform:       Model\n    References:     http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reana...\n    dataset_title:  NCEP-NCAR Reanalysis 1</pre>xarray.Dataset<ul><li>Dimensions:<ul><li>lat: 73</li><li>lon: 144</li><li>nbnds: 2</li></ul></li><li>Coordinates: (3)<ul><li>lat(lat)float3290.0 87.5 85.0 ... -87.5 -90.0units :degrees_northactual_range :[ 90. -90.]long_name :Latitudestandard_name :latitudeaxis :Y<pre>array([ 90. ,  87.5,  85. ,  82.5,  80. ,  77.5,  75. ,  72.5,  70. ,  67.5,\n        65. ,  62.5,  60. ,  57.5,  55. ,  52.5,  50. ,  47.5,  45. ,  42.5,\n        40. ,  37.5,  35. ,  32.5,  30. ,  27.5,  25. ,  22.5,  20. ,  17.5,\n        15. ,  12.5,  10. ,   7.5,   5. ,   2.5,   0. ,  -2.5,  -5. ,  -7.5,\n       -10. , -12.5, -15. , -17.5, -20. , -22.5, -25. , -27.5, -30. , -32.5,\n       -35. , -37.5, -40. , -42.5, -45. , -47.5, -50. , -52.5, -55. , -57.5,\n       -60. , -62.5, -65. , -67.5, -70. , -72.5, -75. , -77.5, -80. , -82.5,\n       -85. , -87.5, -90. ], dtype=float32)</pre></li><li>lon(lon)float320.0 2.5 5.0 ... 352.5 355.0 357.5units :degrees_eastlong_name :Longitudeactual_range :[  0.  357.5]standard_name :longitudeaxis :X<pre>array([  0. ,   2.5,   5. ,   7.5,  10. ,  12.5,  15. ,  17.5,  20. ,  22.5,\n        25. ,  27.5,  30. ,  32.5,  35. ,  37.5,  40. ,  42.5,  45. ,  47.5,\n        50. ,  52.5,  55. ,  57.5,  60. ,  62.5,  65. ,  67.5,  70. ,  72.5,\n        75. ,  77.5,  80. ,  82.5,  85. ,  87.5,  90. ,  92.5,  95. ,  97.5,\n       100. , 102.5, 105. , 107.5, 110. , 112.5, 115. , 117.5, 120. , 122.5,\n       125. , 127.5, 130. , 132.5, 135. , 137.5, 140. , 142.5, 145. , 147.5,\n       150. , 152.5, 155. , 157.5, 160. , 162.5, 165. , 167.5, 170. , 172.5,\n       175. , 177.5, 180. , 182.5, 185. , 187.5, 190. , 192.5, 195. , 197.5,\n       200. , 202.5, 205. , 207.5, 210. , 212.5, 215. , 217.5, 220. , 222.5,\n       225. , 227.5, 230. , 232.5, 235. , 237.5, 240. , 242.5, 245. , 247.5,\n       250. , 252.5, 255. , 257.5, 260. , 262.5, 265. , 267.5, 270. , 272.5,\n       275. , 277.5, 280. , 282.5, 285. , 287.5, 290. , 292.5, 295. , 297.5,\n       300. , 302.5, 305. , 307.5, 310. , 312.5, 315. , 317.5, 320. , 322.5,\n       325. , 327.5, 330. , 332.5, 335. , 337.5, 340. , 342.5, 345. , 347.5,\n       350. , 352.5, 355. , 357.5], dtype=float32)</pre></li><li>time()datetime64[ns]2023-05-01long_name :Timedelta_t :0000-00-01 00:00:00standard_name :timeaxis :Tavg_period :0000-00-01 00:00:00coordinate_defines :startactual_range :[1954776. 1963512.]<pre>array('2023-05-01T00:00:00.000000000', dtype='datetime64[ns]')</pre></li></ul></li><li>Data variables: (2)<ul><li>air(lat, lon)float32259.0 259.0 259.0 ... 222.2 222.2long_name :mean Daily Air temperature at sigma level 995units :degKprecision :2GRIB_id :11GRIB_name :TMPvar_desc :Air temperaturedataset :NCEP Reanalysis Daily Averagesstatistic :Meanparent_stat :Individual Obsvalid_range :[185.16 331.16]level_desc :0.995 sigmaactual_range :[191.4  318.05]new_attr :trial dataset in class<pre>array([[259.     , 259.     , 259.     , ..., 259.     , 259.     , 259.     ],\n       [258.375  , 258.32498, 258.3    , ..., 258.39996, 258.425  , 258.39996],\n       [257.425  , 257.47498, 257.5    , ..., 257.275  , 257.32498, 257.34998],\n       ...,\n       [219.4    , 219.69998, 220.09998, ..., 219.125  , 219.09998, 219.17499],\n       [221.87498, 221.75   , 221.54999, ..., 222.525  , 222.275  , 222.07498],\n       [222.22498, 222.22498, 222.22498, ..., 222.22498, 222.22498, 222.22498]],\n      dtype=float32)</pre></li><li>time_bnds(nbnds)float64...<pre>[2 values with dtype=float64]</pre></li></ul></li><li>Indexes: (2)<ul><li>latPandasIndex<pre>PandasIndex(Index([ 90.0,  87.5,  85.0,  82.5,  80.0,  77.5,  75.0,  72.5,  70.0,  67.5,\n        65.0,  62.5,  60.0,  57.5,  55.0,  52.5,  50.0,  47.5,  45.0,  42.5,\n        40.0,  37.5,  35.0,  32.5,  30.0,  27.5,  25.0,  22.5,  20.0,  17.5,\n        15.0,  12.5,  10.0,   7.5,   5.0,   2.5,   0.0,  -2.5,  -5.0,  -7.5,\n       -10.0, -12.5, -15.0, -17.5, -20.0, -22.5, -25.0, -27.5, -30.0, -32.5,\n       -35.0, -37.5, -40.0, -42.5, -45.0, -47.5, -50.0, -52.5, -55.0, -57.5,\n       -60.0, -62.5, -65.0, -67.5, -70.0, -72.5, -75.0, -77.5, -80.0, -82.5,\n       -85.0, -87.5, -90.0],\n      dtype='float32', name='lat'))</pre></li><li>lonPandasIndex<pre>PandasIndex(Index([  0.0,   2.5,   5.0,   7.5,  10.0,  12.5,  15.0,  17.5,  20.0,  22.5,\n       ...\n       335.0, 337.5, 340.0, 342.5, 345.0, 347.5, 350.0, 352.5, 355.0, 357.5],\n      dtype='float32', name='lon', length=144))</pre></li></ul></li><li>Attributes: (7)Conventions :COARDStitle :mean daily NMC reanalysis (2014)history :created 2017/12 by Hoop (netCDF2.3)description :Data is from NMC initialized reanalysis (4x/day).  These are the 0.9950 sigma level values.platform :ModelReferences :http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reanalysis.htmldataset_title :NCEP-NCAR Reanalysis 1</li></ul> <p>By default, datetime selection will return a range of values that match the provided string. For e.g. <code>time=\"2023-01\"</code> will return all timestamps for that month:</p> In\u00a0[38]: Copied! <pre>ds.sel(time=\"2023-01\")\n</pre> ds.sel(time=\"2023-01\") Out[38]: <pre>&lt;xarray.Dataset&gt;\nDimensions:    (lat: 73, lon: 144, time: 31, nbnds: 2)\nCoordinates:\n  * lat        (lat) float32 90.0 87.5 85.0 82.5 ... -82.5 -85.0 -87.5 -90.0\n  * lon        (lon) float32 0.0 2.5 5.0 7.5 10.0 ... 350.0 352.5 355.0 357.5\n  * time       (time) datetime64[ns] 2023-01-01 2023-01-02 ... 2023-01-31\nDimensions without coordinates: nbnds\nData variables:\n    air        (time, lat, lon) float32 246.6 246.6 246.6 ... 245.1 245.1 245.1\n    time_bnds  (time, nbnds) float64 ...\nAttributes:\n    Conventions:    COARDS\n    title:          mean daily NMC reanalysis (2014)\n    history:        created 2017/12 by Hoop (netCDF2.3)\n    description:    Data is from NMC initialized reanalysis\\n(4x/day).  These...\n    platform:       Model\n    References:     http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reana...\n    dataset_title:  NCEP-NCAR Reanalysis 1</pre>xarray.Dataset<ul><li>Dimensions:<ul><li>lat: 73</li><li>lon: 144</li><li>time: 31</li><li>nbnds: 2</li></ul></li><li>Coordinates: (3)<ul><li>lat(lat)float3290.0 87.5 85.0 ... -87.5 -90.0units :degrees_northactual_range :[ 90. -90.]long_name :Latitudestandard_name :latitudeaxis :Y<pre>array([ 90. ,  87.5,  85. ,  82.5,  80. ,  77.5,  75. ,  72.5,  70. ,  67.5,\n        65. ,  62.5,  60. ,  57.5,  55. ,  52.5,  50. ,  47.5,  45. ,  42.5,\n        40. ,  37.5,  35. ,  32.5,  30. ,  27.5,  25. ,  22.5,  20. ,  17.5,\n        15. ,  12.5,  10. ,   7.5,   5. ,   2.5,   0. ,  -2.5,  -5. ,  -7.5,\n       -10. , -12.5, -15. , -17.5, -20. , -22.5, -25. , -27.5, -30. , -32.5,\n       -35. , -37.5, -40. , -42.5, -45. , -47.5, -50. , -52.5, -55. , -57.5,\n       -60. , -62.5, -65. , -67.5, -70. , -72.5, -75. , -77.5, -80. , -82.5,\n       -85. , -87.5, -90. ], dtype=float32)</pre></li><li>lon(lon)float320.0 2.5 5.0 ... 352.5 355.0 357.5units :degrees_eastlong_name :Longitudeactual_range :[  0.  357.5]standard_name :longitudeaxis :X<pre>array([  0. ,   2.5,   5. ,   7.5,  10. ,  12.5,  15. ,  17.5,  20. ,  22.5,\n        25. ,  27.5,  30. ,  32.5,  35. ,  37.5,  40. ,  42.5,  45. ,  47.5,\n        50. ,  52.5,  55. ,  57.5,  60. ,  62.5,  65. ,  67.5,  70. ,  72.5,\n        75. ,  77.5,  80. ,  82.5,  85. ,  87.5,  90. ,  92.5,  95. ,  97.5,\n       100. , 102.5, 105. , 107.5, 110. , 112.5, 115. , 117.5, 120. , 122.5,\n       125. , 127.5, 130. , 132.5, 135. , 137.5, 140. , 142.5, 145. , 147.5,\n       150. , 152.5, 155. , 157.5, 160. , 162.5, 165. , 167.5, 170. , 172.5,\n       175. , 177.5, 180. , 182.5, 185. , 187.5, 190. , 192.5, 195. , 197.5,\n       200. , 202.5, 205. , 207.5, 210. , 212.5, 215. , 217.5, 220. , 222.5,\n       225. , 227.5, 230. , 232.5, 235. , 237.5, 240. , 242.5, 245. , 247.5,\n       250. , 252.5, 255. , 257.5, 260. , 262.5, 265. , 267.5, 270. , 272.5,\n       275. , 277.5, 280. , 282.5, 285. , 287.5, 290. , 292.5, 295. , 297.5,\n       300. , 302.5, 305. , 307.5, 310. , 312.5, 315. , 317.5, 320. , 322.5,\n       325. , 327.5, 330. , 332.5, 335. , 337.5, 340. , 342.5, 345. , 347.5,\n       350. , 352.5, 355. , 357.5], dtype=float32)</pre></li><li>time(time)datetime64[ns]2023-01-01 ... 2023-01-31long_name :Timedelta_t :0000-00-01 00:00:00standard_name :timeaxis :Tavg_period :0000-00-01 00:00:00coordinate_defines :startactual_range :[1954776. 1963512.]<pre>array(['2023-01-01T00:00:00.000000000', '2023-01-02T00:00:00.000000000',\n       '2023-01-03T00:00:00.000000000', '2023-01-04T00:00:00.000000000',\n       '2023-01-05T00:00:00.000000000', '2023-01-06T00:00:00.000000000',\n       '2023-01-07T00:00:00.000000000', '2023-01-08T00:00:00.000000000',\n       '2023-01-09T00:00:00.000000000', '2023-01-10T00:00:00.000000000',\n       '2023-01-11T00:00:00.000000000', '2023-01-12T00:00:00.000000000',\n       '2023-01-13T00:00:00.000000000', '2023-01-14T00:00:00.000000000',\n       '2023-01-15T00:00:00.000000000', '2023-01-16T00:00:00.000000000',\n       '2023-01-17T00:00:00.000000000', '2023-01-18T00:00:00.000000000',\n       '2023-01-19T00:00:00.000000000', '2023-01-20T00:00:00.000000000',\n       '2023-01-21T00:00:00.000000000', '2023-01-22T00:00:00.000000000',\n       '2023-01-23T00:00:00.000000000', '2023-01-24T00:00:00.000000000',\n       '2023-01-25T00:00:00.000000000', '2023-01-26T00:00:00.000000000',\n       '2023-01-27T00:00:00.000000000', '2023-01-28T00:00:00.000000000',\n       '2023-01-29T00:00:00.000000000', '2023-01-30T00:00:00.000000000',\n       '2023-01-31T00:00:00.000000000'], dtype='datetime64[ns]')</pre></li></ul></li><li>Data variables: (2)<ul><li>air(time, lat, lon)float32246.6 246.6 246.6 ... 245.1 245.1long_name :mean Daily Air temperature at sigma level 995units :degKprecision :2GRIB_id :11GRIB_name :TMPvar_desc :Air temperaturedataset :NCEP Reanalysis Daily Averagesstatistic :Meanparent_stat :Individual Obsvalid_range :[185.16 331.16]level_desc :0.995 sigmaactual_range :[191.4  318.05]new_attr :trial dataset in class<pre>array([[[246.57498, 246.57498, ..., 246.57498, 246.57498],\n        [248.04999, 247.97498, ..., 248.19998, 248.12498],\n        ...,\n        [251.57498, 251.59998, ..., 251.575  , 251.57498],\n        [251.22498, 251.22498, ..., 251.22498, 251.22498]],\n\n       [[248.19998, 248.19998, ..., 248.19998, 248.19998],\n        [253.39998, 253.39998, ..., 253.37497, 253.37498],\n        ...,\n        [252.72498, 252.79999, ..., 252.62497, 252.69998],\n        [252.79997, 252.79997, ..., 252.79997, 252.79997]],\n\n       ...,\n\n       [[244.62498, 244.62498, ..., 244.62498, 244.62498],\n        [245.425  , 245.17499, ..., 245.92499, 245.67499],\n        ...,\n        [246.9    , 246.97499, ..., 246.775  , 246.85   ],\n        [248.45   , 248.45   , ..., 248.45   , 248.45   ]],\n\n       [[246.29999, 246.29999, ..., 246.29999, 246.29999],\n        [245.34998, 245.32498, ..., 245.34998, 245.32498],\n        ...,\n        [248.29997, 248.22499, ..., 248.575  , 248.42499],\n        [245.15   , 245.15   , ..., 245.15   , 245.15   ]]], dtype=float32)</pre></li><li>time_bnds(time, nbnds)float64...<pre>[62 values with dtype=float64]</pre></li></ul></li><li>Indexes: (3)<ul><li>latPandasIndex<pre>PandasIndex(Index([ 90.0,  87.5,  85.0,  82.5,  80.0,  77.5,  75.0,  72.5,  70.0,  67.5,\n        65.0,  62.5,  60.0,  57.5,  55.0,  52.5,  50.0,  47.5,  45.0,  42.5,\n        40.0,  37.5,  35.0,  32.5,  30.0,  27.5,  25.0,  22.5,  20.0,  17.5,\n        15.0,  12.5,  10.0,   7.5,   5.0,   2.5,   0.0,  -2.5,  -5.0,  -7.5,\n       -10.0, -12.5, -15.0, -17.5, -20.0, -22.5, -25.0, -27.5, -30.0, -32.5,\n       -35.0, -37.5, -40.0, -42.5, -45.0, -47.5, -50.0, -52.5, -55.0, -57.5,\n       -60.0, -62.5, -65.0, -67.5, -70.0, -72.5, -75.0, -77.5, -80.0, -82.5,\n       -85.0, -87.5, -90.0],\n      dtype='float32', name='lat'))</pre></li><li>lonPandasIndex<pre>PandasIndex(Index([  0.0,   2.5,   5.0,   7.5,  10.0,  12.5,  15.0,  17.5,  20.0,  22.5,\n       ...\n       335.0, 337.5, 340.0, 342.5, 345.0, 347.5, 350.0, 352.5, 355.0, 357.5],\n      dtype='float32', name='lon', length=144))</pre></li><li>timePandasIndex<pre>PandasIndex(DatetimeIndex(['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04',\n               '2023-01-05', '2023-01-06', '2023-01-07', '2023-01-08',\n               '2023-01-09', '2023-01-10', '2023-01-11', '2023-01-12',\n               '2023-01-13', '2023-01-14', '2023-01-15', '2023-01-16',\n               '2023-01-17', '2023-01-18', '2023-01-19', '2023-01-20',\n               '2023-01-21', '2023-01-22', '2023-01-23', '2023-01-24',\n               '2023-01-25', '2023-01-26', '2023-01-27', '2023-01-28',\n               '2023-01-29', '2023-01-30', '2023-01-31'],\n              dtype='datetime64[ns]', name='time', freq=None))</pre></li></ul></li><li>Attributes: (7)Conventions :COARDStitle :mean daily NMC reanalysis (2014)history :created 2017/12 by Hoop (netCDF2.3)description :Data is from NMC initialized reanalysis (4x/day).  These are the 0.9950 sigma level values.platform :ModelReferences :http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reanalysis.htmldataset_title :NCEP-NCAR Reanalysis 1</li></ul> In\u00a0[39]: Copied! <pre># Or use month name\nds.sel(time=\"2023-May\")\n</pre> # Or use month name ds.sel(time=\"2023-May\") Out[39]: <pre>&lt;xarray.Dataset&gt;\nDimensions:    (lat: 73, lon: 144, time: 31, nbnds: 2)\nCoordinates:\n  * lat        (lat) float32 90.0 87.5 85.0 82.5 ... -82.5 -85.0 -87.5 -90.0\n  * lon        (lon) float32 0.0 2.5 5.0 7.5 10.0 ... 350.0 352.5 355.0 357.5\n  * time       (time) datetime64[ns] 2023-05-01 2023-05-02 ... 2023-05-31\nDimensions without coordinates: nbnds\nData variables:\n    air        (time, lat, lon) float32 259.0 259.0 259.0 ... 209.9 209.9 209.9\n    time_bnds  (time, nbnds) float64 ...\nAttributes:\n    Conventions:    COARDS\n    title:          mean daily NMC reanalysis (2014)\n    history:        created 2017/12 by Hoop (netCDF2.3)\n    description:    Data is from NMC initialized reanalysis\\n(4x/day).  These...\n    platform:       Model\n    References:     http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reana...\n    dataset_title:  NCEP-NCAR Reanalysis 1</pre>xarray.Dataset<ul><li>Dimensions:<ul><li>lat: 73</li><li>lon: 144</li><li>time: 31</li><li>nbnds: 2</li></ul></li><li>Coordinates: (3)<ul><li>lat(lat)float3290.0 87.5 85.0 ... -87.5 -90.0units :degrees_northactual_range :[ 90. -90.]long_name :Latitudestandard_name :latitudeaxis :Y<pre>array([ 90. ,  87.5,  85. ,  82.5,  80. ,  77.5,  75. ,  72.5,  70. ,  67.5,\n        65. ,  62.5,  60. ,  57.5,  55. ,  52.5,  50. ,  47.5,  45. ,  42.5,\n        40. ,  37.5,  35. ,  32.5,  30. ,  27.5,  25. ,  22.5,  20. ,  17.5,\n        15. ,  12.5,  10. ,   7.5,   5. ,   2.5,   0. ,  -2.5,  -5. ,  -7.5,\n       -10. , -12.5, -15. , -17.5, -20. , -22.5, -25. , -27.5, -30. , -32.5,\n       -35. , -37.5, -40. , -42.5, -45. , -47.5, -50. , -52.5, -55. , -57.5,\n       -60. , -62.5, -65. , -67.5, -70. , -72.5, -75. , -77.5, -80. , -82.5,\n       -85. , -87.5, -90. ], dtype=float32)</pre></li><li>lon(lon)float320.0 2.5 5.0 ... 352.5 355.0 357.5units :degrees_eastlong_name :Longitudeactual_range :[  0.  357.5]standard_name :longitudeaxis :X<pre>array([  0. ,   2.5,   5. ,   7.5,  10. ,  12.5,  15. ,  17.5,  20. ,  22.5,\n        25. ,  27.5,  30. ,  32.5,  35. ,  37.5,  40. ,  42.5,  45. ,  47.5,\n        50. ,  52.5,  55. ,  57.5,  60. ,  62.5,  65. ,  67.5,  70. ,  72.5,\n        75. ,  77.5,  80. ,  82.5,  85. ,  87.5,  90. ,  92.5,  95. ,  97.5,\n       100. , 102.5, 105. , 107.5, 110. , 112.5, 115. , 117.5, 120. , 122.5,\n       125. , 127.5, 130. , 132.5, 135. , 137.5, 140. , 142.5, 145. , 147.5,\n       150. , 152.5, 155. , 157.5, 160. , 162.5, 165. , 167.5, 170. , 172.5,\n       175. , 177.5, 180. , 182.5, 185. , 187.5, 190. , 192.5, 195. , 197.5,\n       200. , 202.5, 205. , 207.5, 210. , 212.5, 215. , 217.5, 220. , 222.5,\n       225. , 227.5, 230. , 232.5, 235. , 237.5, 240. , 242.5, 245. , 247.5,\n       250. , 252.5, 255. , 257.5, 260. , 262.5, 265. , 267.5, 270. , 272.5,\n       275. , 277.5, 280. , 282.5, 285. , 287.5, 290. , 292.5, 295. , 297.5,\n       300. , 302.5, 305. , 307.5, 310. , 312.5, 315. , 317.5, 320. , 322.5,\n       325. , 327.5, 330. , 332.5, 335. , 337.5, 340. , 342.5, 345. , 347.5,\n       350. , 352.5, 355. , 357.5], dtype=float32)</pre></li><li>time(time)datetime64[ns]2023-05-01 ... 2023-05-31long_name :Timedelta_t :0000-00-01 00:00:00standard_name :timeaxis :Tavg_period :0000-00-01 00:00:00coordinate_defines :startactual_range :[1954776. 1963512.]<pre>array(['2023-05-01T00:00:00.000000000', '2023-05-02T00:00:00.000000000',\n       '2023-05-03T00:00:00.000000000', '2023-05-04T00:00:00.000000000',\n       '2023-05-05T00:00:00.000000000', '2023-05-06T00:00:00.000000000',\n       '2023-05-07T00:00:00.000000000', '2023-05-08T00:00:00.000000000',\n       '2023-05-09T00:00:00.000000000', '2023-05-10T00:00:00.000000000',\n       '2023-05-11T00:00:00.000000000', '2023-05-12T00:00:00.000000000',\n       '2023-05-13T00:00:00.000000000', '2023-05-14T00:00:00.000000000',\n       '2023-05-15T00:00:00.000000000', '2023-05-16T00:00:00.000000000',\n       '2023-05-17T00:00:00.000000000', '2023-05-18T00:00:00.000000000',\n       '2023-05-19T00:00:00.000000000', '2023-05-20T00:00:00.000000000',\n       '2023-05-21T00:00:00.000000000', '2023-05-22T00:00:00.000000000',\n       '2023-05-23T00:00:00.000000000', '2023-05-24T00:00:00.000000000',\n       '2023-05-25T00:00:00.000000000', '2023-05-26T00:00:00.000000000',\n       '2023-05-27T00:00:00.000000000', '2023-05-28T00:00:00.000000000',\n       '2023-05-29T00:00:00.000000000', '2023-05-30T00:00:00.000000000',\n       '2023-05-31T00:00:00.000000000'], dtype='datetime64[ns]')</pre></li></ul></li><li>Data variables: (2)<ul><li>air(time, lat, lon)float32259.0 259.0 259.0 ... 209.9 209.9long_name :mean Daily Air temperature at sigma level 995units :degKprecision :2GRIB_id :11GRIB_name :TMPvar_desc :Air temperaturedataset :NCEP Reanalysis Daily Averagesstatistic :Meanparent_stat :Individual Obsvalid_range :[185.16 331.16]level_desc :0.995 sigmaactual_range :[191.4  318.05]new_attr :trial dataset in class<pre>array([[[259.     , 259.     , ..., 259.     , 259.     ],\n        [258.375  , 258.32498, ..., 258.425  , 258.39996],\n        ...,\n        [221.87498, 221.75   , ..., 222.275  , 222.07498],\n        [222.22498, 222.22498, ..., 222.22498, 222.22498]],\n\n       [[255.97499, 255.97499, ..., 255.97499, 255.97499],\n        [255.875  , 255.72499, ..., 256.175  , 256.025  ],\n        ...,\n        [223.5    , 223.37498, ..., 223.94998, 223.72499],\n        [223.325  , 223.325  , ..., 223.325  , 223.325  ]],\n\n       ...,\n\n       [[269.85   , 269.85   , ..., 269.85   , 269.85   ],\n        [267.875  , 267.80002, ..., 268.05   , 267.925  ],\n        ...,\n        [209.55   , 209.15   , ..., 210.45   , 209.975  ],\n        [212.25   , 212.25   , ..., 212.25   , 212.25   ]],\n\n       [[270.65002, 270.65002, ..., 270.65002, 270.65002],\n        [267.55   , 267.425  , ..., 267.77502, 267.65   ],\n        ...,\n        [211.9    , 211.5    , ..., 212.75   , 212.29999],\n        [209.92499, 209.92499, ..., 209.92499, 209.92499]]], dtype=float32)</pre></li><li>time_bnds(time, nbnds)float64...<pre>[62 values with dtype=float64]</pre></li></ul></li><li>Indexes: (3)<ul><li>latPandasIndex<pre>PandasIndex(Index([ 90.0,  87.5,  85.0,  82.5,  80.0,  77.5,  75.0,  72.5,  70.0,  67.5,\n        65.0,  62.5,  60.0,  57.5,  55.0,  52.5,  50.0,  47.5,  45.0,  42.5,\n        40.0,  37.5,  35.0,  32.5,  30.0,  27.5,  25.0,  22.5,  20.0,  17.5,\n        15.0,  12.5,  10.0,   7.5,   5.0,   2.5,   0.0,  -2.5,  -5.0,  -7.5,\n       -10.0, -12.5, -15.0, -17.5, -20.0, -22.5, -25.0, -27.5, -30.0, -32.5,\n       -35.0, -37.5, -40.0, -42.5, -45.0, -47.5, -50.0, -52.5, -55.0, -57.5,\n       -60.0, -62.5, -65.0, -67.5, -70.0, -72.5, -75.0, -77.5, -80.0, -82.5,\n       -85.0, -87.5, -90.0],\n      dtype='float32', name='lat'))</pre></li><li>lonPandasIndex<pre>PandasIndex(Index([  0.0,   2.5,   5.0,   7.5,  10.0,  12.5,  15.0,  17.5,  20.0,  22.5,\n       ...\n       335.0, 337.5, 340.0, 342.5, 345.0, 347.5, 350.0, 352.5, 355.0, 357.5],\n      dtype='float32', name='lon', length=144))</pre></li><li>timePandasIndex<pre>PandasIndex(DatetimeIndex(['2023-05-01', '2023-05-02', '2023-05-03', '2023-05-04',\n               '2023-05-05', '2023-05-06', '2023-05-07', '2023-05-08',\n               '2023-05-09', '2023-05-10', '2023-05-11', '2023-05-12',\n               '2023-05-13', '2023-05-14', '2023-05-15', '2023-05-16',\n               '2023-05-17', '2023-05-18', '2023-05-19', '2023-05-20',\n               '2023-05-21', '2023-05-22', '2023-05-23', '2023-05-24',\n               '2023-05-25', '2023-05-26', '2023-05-27', '2023-05-28',\n               '2023-05-29', '2023-05-30', '2023-05-31'],\n              dtype='datetime64[ns]', name='time', freq=None))</pre></li></ul></li><li>Attributes: (7)Conventions :COARDStitle :mean daily NMC reanalysis (2014)history :created 2017/12 by Hoop (netCDF2.3)description :Data is from NMC initialized reanalysis (4x/day).  These are the 0.9950 sigma level values.platform :ModelReferences :http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reanalysis.htmldataset_title :NCEP-NCAR Reanalysis 1</li></ul> In\u00a0[42]: Copied! <pre># This will return a subset of the dataset corresponding to Jan to March of 2023\nds.sel(time=slice('2023-01-01', '2023-03-31'))\n</pre> # This will return a subset of the dataset corresponding to Jan to March of 2023 ds.sel(time=slice('2023-01-01', '2023-03-31')) Out[42]: <pre>&lt;xarray.Dataset&gt;\nDimensions:    (lat: 73, lon: 144, time: 90, nbnds: 2)\nCoordinates:\n  * lat        (lat) float32 90.0 87.5 85.0 82.5 ... -82.5 -85.0 -87.5 -90.0\n  * lon        (lon) float32 0.0 2.5 5.0 7.5 10.0 ... 350.0 352.5 355.0 357.5\n  * time       (time) datetime64[ns] 2023-01-01 2023-01-02 ... 2023-03-31\nDimensions without coordinates: nbnds\nData variables:\n    air        (time, lat, lon) float32 246.6 246.6 246.6 ... 223.4 223.4 223.4\n    time_bnds  (time, nbnds) float64 ...\nAttributes:\n    Conventions:    COARDS\n    title:          mean daily NMC reanalysis (2014)\n    history:        created 2017/12 by Hoop (netCDF2.3)\n    description:    Data is from NMC initialized reanalysis\\n(4x/day).  These...\n    platform:       Model\n    References:     http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reana...\n    dataset_title:  NCEP-NCAR Reanalysis 1</pre>xarray.Dataset<ul><li>Dimensions:<ul><li>lat: 73</li><li>lon: 144</li><li>time: 90</li><li>nbnds: 2</li></ul></li><li>Coordinates: (3)<ul><li>lat(lat)float3290.0 87.5 85.0 ... -87.5 -90.0units :degrees_northactual_range :[ 90. -90.]long_name :Latitudestandard_name :latitudeaxis :Y<pre>array([ 90. ,  87.5,  85. ,  82.5,  80. ,  77.5,  75. ,  72.5,  70. ,  67.5,\n        65. ,  62.5,  60. ,  57.5,  55. ,  52.5,  50. ,  47.5,  45. ,  42.5,\n        40. ,  37.5,  35. ,  32.5,  30. ,  27.5,  25. ,  22.5,  20. ,  17.5,\n        15. ,  12.5,  10. ,   7.5,   5. ,   2.5,   0. ,  -2.5,  -5. ,  -7.5,\n       -10. , -12.5, -15. , -17.5, -20. , -22.5, -25. , -27.5, -30. , -32.5,\n       -35. , -37.5, -40. , -42.5, -45. , -47.5, -50. , -52.5, -55. , -57.5,\n       -60. , -62.5, -65. , -67.5, -70. , -72.5, -75. , -77.5, -80. , -82.5,\n       -85. , -87.5, -90. ], dtype=float32)</pre></li><li>lon(lon)float320.0 2.5 5.0 ... 352.5 355.0 357.5units :degrees_eastlong_name :Longitudeactual_range :[  0.  357.5]standard_name :longitudeaxis :X<pre>array([  0. ,   2.5,   5. ,   7.5,  10. ,  12.5,  15. ,  17.5,  20. ,  22.5,\n        25. ,  27.5,  30. ,  32.5,  35. ,  37.5,  40. ,  42.5,  45. ,  47.5,\n        50. ,  52.5,  55. ,  57.5,  60. ,  62.5,  65. ,  67.5,  70. ,  72.5,\n        75. ,  77.5,  80. ,  82.5,  85. ,  87.5,  90. ,  92.5,  95. ,  97.5,\n       100. , 102.5, 105. , 107.5, 110. , 112.5, 115. , 117.5, 120. , 122.5,\n       125. , 127.5, 130. , 132.5, 135. , 137.5, 140. , 142.5, 145. , 147.5,\n       150. , 152.5, 155. , 157.5, 160. , 162.5, 165. , 167.5, 170. , 172.5,\n       175. , 177.5, 180. , 182.5, 185. , 187.5, 190. , 192.5, 195. , 197.5,\n       200. , 202.5, 205. , 207.5, 210. , 212.5, 215. , 217.5, 220. , 222.5,\n       225. , 227.5, 230. , 232.5, 235. , 237.5, 240. , 242.5, 245. , 247.5,\n       250. , 252.5, 255. , 257.5, 260. , 262.5, 265. , 267.5, 270. , 272.5,\n       275. , 277.5, 280. , 282.5, 285. , 287.5, 290. , 292.5, 295. , 297.5,\n       300. , 302.5, 305. , 307.5, 310. , 312.5, 315. , 317.5, 320. , 322.5,\n       325. , 327.5, 330. , 332.5, 335. , 337.5, 340. , 342.5, 345. , 347.5,\n       350. , 352.5, 355. , 357.5], dtype=float32)</pre></li><li>time(time)datetime64[ns]2023-01-01 ... 2023-03-31long_name :Timedelta_t :0000-00-01 00:00:00standard_name :timeaxis :Tavg_period :0000-00-01 00:00:00coordinate_defines :startactual_range :[1954776. 1963512.]<pre>array(['2023-01-01T00:00:00.000000000', '2023-01-02T00:00:00.000000000',\n       '2023-01-03T00:00:00.000000000', '2023-01-04T00:00:00.000000000',\n       '2023-01-05T00:00:00.000000000', '2023-01-06T00:00:00.000000000',\n       '2023-01-07T00:00:00.000000000', '2023-01-08T00:00:00.000000000',\n       '2023-01-09T00:00:00.000000000', '2023-01-10T00:00:00.000000000',\n       '2023-01-11T00:00:00.000000000', '2023-01-12T00:00:00.000000000',\n       '2023-01-13T00:00:00.000000000', '2023-01-14T00:00:00.000000000',\n       '2023-01-15T00:00:00.000000000', '2023-01-16T00:00:00.000000000',\n       '2023-01-17T00:00:00.000000000', '2023-01-18T00:00:00.000000000',\n       '2023-01-19T00:00:00.000000000', '2023-01-20T00:00:00.000000000',\n       '2023-01-21T00:00:00.000000000', '2023-01-22T00:00:00.000000000',\n       '2023-01-23T00:00:00.000000000', '2023-01-24T00:00:00.000000000',\n       '2023-01-25T00:00:00.000000000', '2023-01-26T00:00:00.000000000',\n       '2023-01-27T00:00:00.000000000', '2023-01-28T00:00:00.000000000',\n       '2023-01-29T00:00:00.000000000', '2023-01-30T00:00:00.000000000',\n       '2023-01-31T00:00:00.000000000', '2023-02-01T00:00:00.000000000',\n       '2023-02-02T00:00:00.000000000', '2023-02-03T00:00:00.000000000',\n       '2023-02-04T00:00:00.000000000', '2023-02-05T00:00:00.000000000',\n       '2023-02-06T00:00:00.000000000', '2023-02-07T00:00:00.000000000',\n       '2023-02-08T00:00:00.000000000', '2023-02-09T00:00:00.000000000',\n       '2023-02-10T00:00:00.000000000', '2023-02-11T00:00:00.000000000',\n       '2023-02-12T00:00:00.000000000', '2023-02-13T00:00:00.000000000',\n       '2023-02-14T00:00:00.000000000', '2023-02-15T00:00:00.000000000',\n       '2023-02-16T00:00:00.000000000', '2023-02-17T00:00:00.000000000',\n       '2023-02-18T00:00:00.000000000', '2023-02-19T00:00:00.000000000',\n       '2023-02-20T00:00:00.000000000', '2023-02-21T00:00:00.000000000',\n       '2023-02-22T00:00:00.000000000', '2023-02-23T00:00:00.000000000',\n       '2023-02-24T00:00:00.000000000', '2023-02-25T00:00:00.000000000',\n       '2023-02-26T00:00:00.000000000', '2023-02-27T00:00:00.000000000',\n       '2023-02-28T00:00:00.000000000', '2023-03-01T00:00:00.000000000',\n       '2023-03-02T00:00:00.000000000', '2023-03-03T00:00:00.000000000',\n       '2023-03-04T00:00:00.000000000', '2023-03-05T00:00:00.000000000',\n       '2023-03-06T00:00:00.000000000', '2023-03-07T00:00:00.000000000',\n       '2023-03-08T00:00:00.000000000', '2023-03-09T00:00:00.000000000',\n       '2023-03-10T00:00:00.000000000', '2023-03-11T00:00:00.000000000',\n       '2023-03-12T00:00:00.000000000', '2023-03-13T00:00:00.000000000',\n       '2023-03-14T00:00:00.000000000', '2023-03-15T00:00:00.000000000',\n       '2023-03-16T00:00:00.000000000', '2023-03-17T00:00:00.000000000',\n       '2023-03-18T00:00:00.000000000', '2023-03-19T00:00:00.000000000',\n       '2023-03-20T00:00:00.000000000', '2023-03-21T00:00:00.000000000',\n       '2023-03-22T00:00:00.000000000', '2023-03-23T00:00:00.000000000',\n       '2023-03-24T00:00:00.000000000', '2023-03-25T00:00:00.000000000',\n       '2023-03-26T00:00:00.000000000', '2023-03-27T00:00:00.000000000',\n       '2023-03-28T00:00:00.000000000', '2023-03-29T00:00:00.000000000',\n       '2023-03-30T00:00:00.000000000', '2023-03-31T00:00:00.000000000'],\n      dtype='datetime64[ns]')</pre></li></ul></li><li>Data variables: (2)<ul><li>air(time, lat, lon)float32246.6 246.6 246.6 ... 223.4 223.4long_name :mean Daily Air temperature at sigma level 995units :degKprecision :2GRIB_id :11GRIB_name :TMPvar_desc :Air temperaturedataset :NCEP Reanalysis Daily Averagesstatistic :Meanparent_stat :Individual Obsvalid_range :[185.16 331.16]level_desc :0.995 sigmaactual_range :[191.4  318.05]new_attr :trial dataset in class<pre>array([[[246.57498, 246.57498, ..., 246.57498, 246.57498],\n        [248.04999, 247.97498, ..., 248.19998, 248.12498],\n        ...,\n        [251.57498, 251.59998, ..., 251.575  , 251.57498],\n        [251.22498, 251.22498, ..., 251.22498, 251.22498]],\n\n       [[248.19998, 248.19998, ..., 248.19998, 248.19998],\n        [253.39998, 253.39998, ..., 253.37497, 253.37498],\n        ...,\n        [252.72498, 252.79999, ..., 252.62497, 252.69998],\n        [252.79997, 252.79997, ..., 252.79997, 252.79997]],\n\n       ...,\n\n       [[252.375  , 252.375  , ..., 252.375  , 252.375  ],\n        [250.4    , 250.22498, ..., 250.775  , 250.57498],\n        ...,\n        [228.375  , 228.025  , ..., 229.07498, 228.72499],\n        [229.275  , 229.275  , ..., 229.275  , 229.275  ]],\n\n       [[251.97498, 251.97498, ..., 251.97498, 251.97498],\n        [250.84998, 250.775  , ..., 251.07497, 250.94998],\n        ...,\n        [226.69998, 226.72498, ..., 226.74998, 226.72498],\n        [223.37498, 223.37498, ..., 223.37498, 223.37498]]], dtype=float32)</pre></li><li>time_bnds(time, nbnds)float64...<pre>[180 values with dtype=float64]</pre></li></ul></li><li>Indexes: (3)<ul><li>latPandasIndex<pre>PandasIndex(Index([ 90.0,  87.5,  85.0,  82.5,  80.0,  77.5,  75.0,  72.5,  70.0,  67.5,\n        65.0,  62.5,  60.0,  57.5,  55.0,  52.5,  50.0,  47.5,  45.0,  42.5,\n        40.0,  37.5,  35.0,  32.5,  30.0,  27.5,  25.0,  22.5,  20.0,  17.5,\n        15.0,  12.5,  10.0,   7.5,   5.0,   2.5,   0.0,  -2.5,  -5.0,  -7.5,\n       -10.0, -12.5, -15.0, -17.5, -20.0, -22.5, -25.0, -27.5, -30.0, -32.5,\n       -35.0, -37.5, -40.0, -42.5, -45.0, -47.5, -50.0, -52.5, -55.0, -57.5,\n       -60.0, -62.5, -65.0, -67.5, -70.0, -72.5, -75.0, -77.5, -80.0, -82.5,\n       -85.0, -87.5, -90.0],\n      dtype='float32', name='lat'))</pre></li><li>lonPandasIndex<pre>PandasIndex(Index([  0.0,   2.5,   5.0,   7.5,  10.0,  12.5,  15.0,  17.5,  20.0,  22.5,\n       ...\n       335.0, 337.5, 340.0, 342.5, 345.0, 347.5, 350.0, 352.5, 355.0, 357.5],\n      dtype='float32', name='lon', length=144))</pre></li><li>timePandasIndex<pre>PandasIndex(DatetimeIndex(['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04',\n               '2023-01-05', '2023-01-06', '2023-01-07', '2023-01-08',\n               '2023-01-09', '2023-01-10', '2023-01-11', '2023-01-12',\n               '2023-01-13', '2023-01-14', '2023-01-15', '2023-01-16',\n               '2023-01-17', '2023-01-18', '2023-01-19', '2023-01-20',\n               '2023-01-21', '2023-01-22', '2023-01-23', '2023-01-24',\n               '2023-01-25', '2023-01-26', '2023-01-27', '2023-01-28',\n               '2023-01-29', '2023-01-30', '2023-01-31', '2023-02-01',\n               '2023-02-02', '2023-02-03', '2023-02-04', '2023-02-05',\n               '2023-02-06', '2023-02-07', '2023-02-08', '2023-02-09',\n               '2023-02-10', '2023-02-11', '2023-02-12', '2023-02-13',\n               '2023-02-14', '2023-02-15', '2023-02-16', '2023-02-17',\n               '2023-02-18', '2023-02-19', '2023-02-20', '2023-02-21',\n               '2023-02-22', '2023-02-23', '2023-02-24', '2023-02-25',\n               '2023-02-26', '2023-02-27', '2023-02-28', '2023-03-01',\n               '2023-03-02', '2023-03-03', '2023-03-04', '2023-03-05',\n               '2023-03-06', '2023-03-07', '2023-03-08', '2023-03-09',\n               '2023-03-10', '2023-03-11', '2023-03-12', '2023-03-13',\n               '2023-03-14', '2023-03-15', '2023-03-16', '2023-03-17',\n               '2023-03-18', '2023-03-19', '2023-03-20', '2023-03-21',\n               '2023-03-22', '2023-03-23', '2023-03-24', '2023-03-25',\n               '2023-03-26', '2023-03-27', '2023-03-28', '2023-03-29',\n               '2023-03-30', '2023-03-31'],\n              dtype='datetime64[ns]', name='time', freq=None))</pre></li></ul></li><li>Attributes: (7)Conventions :COARDStitle :mean daily NMC reanalysis (2014)history :created 2017/12 by Hoop (netCDF2.3)description :Data is from NMC initialized reanalysis (4x/day).  These are the 0.9950 sigma level values.platform :ModelReferences :http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reanalysis.htmldataset_title :NCEP-NCAR Reanalysis 1</li></ul> <p>The slice function takes two arguments, start and stop, to make a slice that includes these endpoints. When we use <code>slice</code> with the <code>sel</code> method, it provides an efficient way to select a range of dates. The above example shows the usage of slice for datetime indexing.</p> In\u00a0[44]: Copied! <pre>dates = ['2023-07-09', '2023-10-11', '2023-12-24']\nds.sel(time=dates)\n</pre> dates = ['2023-07-09', '2023-10-11', '2023-12-24'] ds.sel(time=dates) Out[44]: <pre>&lt;xarray.Dataset&gt;\nDimensions:    (lat: 73, lon: 144, time: 3, nbnds: 2)\nCoordinates:\n  * lat        (lat) float32 90.0 87.5 85.0 82.5 ... -82.5 -85.0 -87.5 -90.0\n  * lon        (lon) float32 0.0 2.5 5.0 7.5 10.0 ... 350.0 352.5 355.0 357.5\n  * time       (time) datetime64[ns] 2023-07-09 2023-10-11 2023-12-24\nDimensions without coordinates: nbnds\nData variables:\n    air        (time, lat, lon) float32 274.6 274.6 274.6 ... 248.4 248.4 248.4\n    time_bnds  (time, nbnds) float64 ...\nAttributes:\n    Conventions:    COARDS\n    title:          mean daily NMC reanalysis (2014)\n    history:        created 2017/12 by Hoop (netCDF2.3)\n    description:    Data is from NMC initialized reanalysis\\n(4x/day).  These...\n    platform:       Model\n    References:     http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reana...\n    dataset_title:  NCEP-NCAR Reanalysis 1</pre>xarray.Dataset<ul><li>Dimensions:<ul><li>lat: 73</li><li>lon: 144</li><li>time: 3</li><li>nbnds: 2</li></ul></li><li>Coordinates: (3)<ul><li>lat(lat)float3290.0 87.5 85.0 ... -87.5 -90.0units :degrees_northactual_range :[ 90. -90.]long_name :Latitudestandard_name :latitudeaxis :Y<pre>array([ 90. ,  87.5,  85. ,  82.5,  80. ,  77.5,  75. ,  72.5,  70. ,  67.5,\n        65. ,  62.5,  60. ,  57.5,  55. ,  52.5,  50. ,  47.5,  45. ,  42.5,\n        40. ,  37.5,  35. ,  32.5,  30. ,  27.5,  25. ,  22.5,  20. ,  17.5,\n        15. ,  12.5,  10. ,   7.5,   5. ,   2.5,   0. ,  -2.5,  -5. ,  -7.5,\n       -10. , -12.5, -15. , -17.5, -20. , -22.5, -25. , -27.5, -30. , -32.5,\n       -35. , -37.5, -40. , -42.5, -45. , -47.5, -50. , -52.5, -55. , -57.5,\n       -60. , -62.5, -65. , -67.5, -70. , -72.5, -75. , -77.5, -80. , -82.5,\n       -85. , -87.5, -90. ], dtype=float32)</pre></li><li>lon(lon)float320.0 2.5 5.0 ... 352.5 355.0 357.5units :degrees_eastlong_name :Longitudeactual_range :[  0.  357.5]standard_name :longitudeaxis :X<pre>array([  0. ,   2.5,   5. ,   7.5,  10. ,  12.5,  15. ,  17.5,  20. ,  22.5,\n        25. ,  27.5,  30. ,  32.5,  35. ,  37.5,  40. ,  42.5,  45. ,  47.5,\n        50. ,  52.5,  55. ,  57.5,  60. ,  62.5,  65. ,  67.5,  70. ,  72.5,\n        75. ,  77.5,  80. ,  82.5,  85. ,  87.5,  90. ,  92.5,  95. ,  97.5,\n       100. , 102.5, 105. , 107.5, 110. , 112.5, 115. , 117.5, 120. , 122.5,\n       125. , 127.5, 130. , 132.5, 135. , 137.5, 140. , 142.5, 145. , 147.5,\n       150. , 152.5, 155. , 157.5, 160. , 162.5, 165. , 167.5, 170. , 172.5,\n       175. , 177.5, 180. , 182.5, 185. , 187.5, 190. , 192.5, 195. , 197.5,\n       200. , 202.5, 205. , 207.5, 210. , 212.5, 215. , 217.5, 220. , 222.5,\n       225. , 227.5, 230. , 232.5, 235. , 237.5, 240. , 242.5, 245. , 247.5,\n       250. , 252.5, 255. , 257.5, 260. , 262.5, 265. , 267.5, 270. , 272.5,\n       275. , 277.5, 280. , 282.5, 285. , 287.5, 290. , 292.5, 295. , 297.5,\n       300. , 302.5, 305. , 307.5, 310. , 312.5, 315. , 317.5, 320. , 322.5,\n       325. , 327.5, 330. , 332.5, 335. , 337.5, 340. , 342.5, 345. , 347.5,\n       350. , 352.5, 355. , 357.5], dtype=float32)</pre></li><li>time(time)datetime64[ns]2023-07-09 2023-10-11 2023-12-24long_name :Timedelta_t :0000-00-01 00:00:00standard_name :timeaxis :Tavg_period :0000-00-01 00:00:00coordinate_defines :startactual_range :[1954776. 1963512.]<pre>array(['2023-07-09T00:00:00.000000000', '2023-10-11T00:00:00.000000000',\n       '2023-12-24T00:00:00.000000000'], dtype='datetime64[ns]')</pre></li></ul></li><li>Data variables: (2)<ul><li>air(time, lat, lon)float32274.6 274.6 274.6 ... 248.4 248.4long_name :mean Daily Air temperature at sigma level 995units :degKprecision :2GRIB_id :11GRIB_name :TMPvar_desc :Air temperaturedataset :NCEP Reanalysis Daily Averagesstatistic :Meanparent_stat :Individual Obsvalid_range :[185.16 331.16]level_desc :0.995 sigmaactual_range :[191.4  318.05]new_attr :trial dataset in class<pre>array([[[274.6    , 274.6    , ..., 274.6    , 274.6    ],\n        [273.925  , 273.9    , ..., 273.90002, 273.90002],\n        ...,\n        [215.875  , 215.45   , ..., 216.9    , 216.37498],\n        [230.95   , 230.95   , ..., 230.95   , 230.95   ]],\n\n       [[260.525  , 260.525  , ..., 260.525  , 260.525  ],\n        [257.125  , 256.94998, ..., 257.5    , 257.3    ],\n        ...,\n        [234.62498, 234.49997, ..., 234.9    , 234.72499],\n        [231.2    , 231.2    , ..., 231.2    , 231.2    ]],\n\n       [[251.15   , 251.15   , ..., 251.15   , 251.15   ],\n        [252.64998, 252.64998, ..., 252.54999, 252.62498],\n        ...,\n        [249.39998, 249.39998, ..., 249.44998, 249.44998],\n        [248.37498, 248.37498, ..., 248.37498, 248.37498]]], dtype=float32)</pre></li><li>time_bnds(time, nbnds)float64...<pre>[6 values with dtype=float64]</pre></li></ul></li><li>Indexes: (3)<ul><li>latPandasIndex<pre>PandasIndex(Index([ 90.0,  87.5,  85.0,  82.5,  80.0,  77.5,  75.0,  72.5,  70.0,  67.5,\n        65.0,  62.5,  60.0,  57.5,  55.0,  52.5,  50.0,  47.5,  45.0,  42.5,\n        40.0,  37.5,  35.0,  32.5,  30.0,  27.5,  25.0,  22.5,  20.0,  17.5,\n        15.0,  12.5,  10.0,   7.5,   5.0,   2.5,   0.0,  -2.5,  -5.0,  -7.5,\n       -10.0, -12.5, -15.0, -17.5, -20.0, -22.5, -25.0, -27.5, -30.0, -32.5,\n       -35.0, -37.5, -40.0, -42.5, -45.0, -47.5, -50.0, -52.5, -55.0, -57.5,\n       -60.0, -62.5, -65.0, -67.5, -70.0, -72.5, -75.0, -77.5, -80.0, -82.5,\n       -85.0, -87.5, -90.0],\n      dtype='float32', name='lat'))</pre></li><li>lonPandasIndex<pre>PandasIndex(Index([  0.0,   2.5,   5.0,   7.5,  10.0,  12.5,  15.0,  17.5,  20.0,  22.5,\n       ...\n       335.0, 337.5, 340.0, 342.5, 345.0, 347.5, 350.0, 352.5, 355.0, 357.5],\n      dtype='float32', name='lon', length=144))</pre></li><li>timePandasIndex<pre>PandasIndex(DatetimeIndex(['2023-07-09', '2023-10-11', '2023-12-24'], dtype='datetime64[ns]', name='time', freq=None))</pre></li></ul></li><li>Attributes: (7)Conventions :COARDStitle :mean daily NMC reanalysis (2014)history :created 2017/12 by Hoop (netCDF2.3)description :Data is from NMC initialized reanalysis (4x/day).  These are the 0.9950 sigma level values.platform :ModelReferences :http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reanalysis.htmldataset_title :NCEP-NCAR Reanalysis 1</li></ul> In\u00a0[45]: Copied! <pre>ds.sel(time=ds.time.dt.month == 7)\n</pre> ds.sel(time=ds.time.dt.month == 7) Out[45]: <pre>&lt;xarray.Dataset&gt;\nDimensions:    (lat: 73, lon: 144, time: 31, nbnds: 2)\nCoordinates:\n  * lat        (lat) float32 90.0 87.5 85.0 82.5 ... -82.5 -85.0 -87.5 -90.0\n  * lon        (lon) float32 0.0 2.5 5.0 7.5 10.0 ... 350.0 352.5 355.0 357.5\n  * time       (time) datetime64[ns] 2023-07-01 2023-07-02 ... 2023-07-31\nDimensions without coordinates: nbnds\nData variables:\n    air        (time, lat, lon) float32 275.8 275.8 275.8 ... 212.2 212.2 212.2\n    time_bnds  (time, nbnds) float64 ...\nAttributes:\n    Conventions:    COARDS\n    title:          mean daily NMC reanalysis (2014)\n    history:        created 2017/12 by Hoop (netCDF2.3)\n    description:    Data is from NMC initialized reanalysis\\n(4x/day).  These...\n    platform:       Model\n    References:     http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reana...\n    dataset_title:  NCEP-NCAR Reanalysis 1</pre>xarray.Dataset<ul><li>Dimensions:<ul><li>lat: 73</li><li>lon: 144</li><li>time: 31</li><li>nbnds: 2</li></ul></li><li>Coordinates: (3)<ul><li>lat(lat)float3290.0 87.5 85.0 ... -87.5 -90.0units :degrees_northactual_range :[ 90. -90.]long_name :Latitudestandard_name :latitudeaxis :Y<pre>array([ 90. ,  87.5,  85. ,  82.5,  80. ,  77.5,  75. ,  72.5,  70. ,  67.5,\n        65. ,  62.5,  60. ,  57.5,  55. ,  52.5,  50. ,  47.5,  45. ,  42.5,\n        40. ,  37.5,  35. ,  32.5,  30. ,  27.5,  25. ,  22.5,  20. ,  17.5,\n        15. ,  12.5,  10. ,   7.5,   5. ,   2.5,   0. ,  -2.5,  -5. ,  -7.5,\n       -10. , -12.5, -15. , -17.5, -20. , -22.5, -25. , -27.5, -30. , -32.5,\n       -35. , -37.5, -40. , -42.5, -45. , -47.5, -50. , -52.5, -55. , -57.5,\n       -60. , -62.5, -65. , -67.5, -70. , -72.5, -75. , -77.5, -80. , -82.5,\n       -85. , -87.5, -90. ], dtype=float32)</pre></li><li>lon(lon)float320.0 2.5 5.0 ... 352.5 355.0 357.5units :degrees_eastlong_name :Longitudeactual_range :[  0.  357.5]standard_name :longitudeaxis :X<pre>array([  0. ,   2.5,   5. ,   7.5,  10. ,  12.5,  15. ,  17.5,  20. ,  22.5,\n        25. ,  27.5,  30. ,  32.5,  35. ,  37.5,  40. ,  42.5,  45. ,  47.5,\n        50. ,  52.5,  55. ,  57.5,  60. ,  62.5,  65. ,  67.5,  70. ,  72.5,\n        75. ,  77.5,  80. ,  82.5,  85. ,  87.5,  90. ,  92.5,  95. ,  97.5,\n       100. , 102.5, 105. , 107.5, 110. , 112.5, 115. , 117.5, 120. , 122.5,\n       125. , 127.5, 130. , 132.5, 135. , 137.5, 140. , 142.5, 145. , 147.5,\n       150. , 152.5, 155. , 157.5, 160. , 162.5, 165. , 167.5, 170. , 172.5,\n       175. , 177.5, 180. , 182.5, 185. , 187.5, 190. , 192.5, 195. , 197.5,\n       200. , 202.5, 205. , 207.5, 210. , 212.5, 215. , 217.5, 220. , 222.5,\n       225. , 227.5, 230. , 232.5, 235. , 237.5, 240. , 242.5, 245. , 247.5,\n       250. , 252.5, 255. , 257.5, 260. , 262.5, 265. , 267.5, 270. , 272.5,\n       275. , 277.5, 280. , 282.5, 285. , 287.5, 290. , 292.5, 295. , 297.5,\n       300. , 302.5, 305. , 307.5, 310. , 312.5, 315. , 317.5, 320. , 322.5,\n       325. , 327.5, 330. , 332.5, 335. , 337.5, 340. , 342.5, 345. , 347.5,\n       350. , 352.5, 355. , 357.5], dtype=float32)</pre></li><li>time(time)datetime64[ns]2023-07-01 ... 2023-07-31long_name :Timedelta_t :0000-00-01 00:00:00standard_name :timeaxis :Tavg_period :0000-00-01 00:00:00coordinate_defines :startactual_range :[1954776. 1963512.]<pre>array(['2023-07-01T00:00:00.000000000', '2023-07-02T00:00:00.000000000',\n       '2023-07-03T00:00:00.000000000', '2023-07-04T00:00:00.000000000',\n       '2023-07-05T00:00:00.000000000', '2023-07-06T00:00:00.000000000',\n       '2023-07-07T00:00:00.000000000', '2023-07-08T00:00:00.000000000',\n       '2023-07-09T00:00:00.000000000', '2023-07-10T00:00:00.000000000',\n       '2023-07-11T00:00:00.000000000', '2023-07-12T00:00:00.000000000',\n       '2023-07-13T00:00:00.000000000', '2023-07-14T00:00:00.000000000',\n       '2023-07-15T00:00:00.000000000', '2023-07-16T00:00:00.000000000',\n       '2023-07-17T00:00:00.000000000', '2023-07-18T00:00:00.000000000',\n       '2023-07-19T00:00:00.000000000', '2023-07-20T00:00:00.000000000',\n       '2023-07-21T00:00:00.000000000', '2023-07-22T00:00:00.000000000',\n       '2023-07-23T00:00:00.000000000', '2023-07-24T00:00:00.000000000',\n       '2023-07-25T00:00:00.000000000', '2023-07-26T00:00:00.000000000',\n       '2023-07-27T00:00:00.000000000', '2023-07-28T00:00:00.000000000',\n       '2023-07-29T00:00:00.000000000', '2023-07-30T00:00:00.000000000',\n       '2023-07-31T00:00:00.000000000'], dtype='datetime64[ns]')</pre></li></ul></li><li>Data variables: (2)<ul><li>air(time, lat, lon)float32275.8 275.8 275.8 ... 212.2 212.2long_name :mean Daily Air temperature at sigma level 995units :degKprecision :2GRIB_id :11GRIB_name :TMPvar_desc :Air temperaturedataset :NCEP Reanalysis Daily Averagesstatistic :Meanparent_stat :Individual Obsvalid_range :[185.16 331.16]level_desc :0.995 sigmaactual_range :[191.4  318.05]new_attr :trial dataset in class<pre>array([[[275.8    , 275.8    , ..., 275.8    , 275.8    ],\n        [275.15   , 275.125  , ..., 275.2    , 275.175  ],\n        ...,\n        [209.7    , 209.5    , ..., 210.24998, 209.975  ],\n        [209.7    , 209.7    , ..., 209.7    , 209.7    ]],\n\n       [[276.     , 276.     , ..., 276.     , 276.     ],\n        [275.55   , 275.525  , ..., 275.59998, 275.59998],\n        ...,\n        [211.125  , 211.22499, ..., 211.07501, 211.07498],\n        [210.59999, 210.59999, ..., 210.59999, 210.59999]],\n\n       ...,\n\n       [[274.07498, 274.07498, ..., 274.07498, 274.07498],\n        [272.84998, 272.82498, ..., 272.925  , 272.90002],\n        ...,\n        [214.225  , 213.925  , ..., 214.9    , 214.5    ],\n        [217.05   , 217.05   , ..., 217.05   , 217.05   ]],\n\n       [[273.10004, 273.10004, ..., 273.10004, 273.10004],\n        [272.72498, 272.69998, ..., 272.75   , 272.75   ],\n        ...,\n        [212.2    , 212.05   , ..., 212.475  , 212.325  ],\n        [212.225  , 212.225  , ..., 212.225  , 212.225  ]]], dtype=float32)</pre></li><li>time_bnds(time, nbnds)float64...<pre>[62 values with dtype=float64]</pre></li></ul></li><li>Indexes: (3)<ul><li>latPandasIndex<pre>PandasIndex(Index([ 90.0,  87.5,  85.0,  82.5,  80.0,  77.5,  75.0,  72.5,  70.0,  67.5,\n        65.0,  62.5,  60.0,  57.5,  55.0,  52.5,  50.0,  47.5,  45.0,  42.5,\n        40.0,  37.5,  35.0,  32.5,  30.0,  27.5,  25.0,  22.5,  20.0,  17.5,\n        15.0,  12.5,  10.0,   7.5,   5.0,   2.5,   0.0,  -2.5,  -5.0,  -7.5,\n       -10.0, -12.5, -15.0, -17.5, -20.0, -22.5, -25.0, -27.5, -30.0, -32.5,\n       -35.0, -37.5, -40.0, -42.5, -45.0, -47.5, -50.0, -52.5, -55.0, -57.5,\n       -60.0, -62.5, -65.0, -67.5, -70.0, -72.5, -75.0, -77.5, -80.0, -82.5,\n       -85.0, -87.5, -90.0],\n      dtype='float32', name='lat'))</pre></li><li>lonPandasIndex<pre>PandasIndex(Index([  0.0,   2.5,   5.0,   7.5,  10.0,  12.5,  15.0,  17.5,  20.0,  22.5,\n       ...\n       335.0, 337.5, 340.0, 342.5, 345.0, 347.5, 350.0, 352.5, 355.0, 357.5],\n      dtype='float32', name='lon', length=144))</pre></li><li>timePandasIndex<pre>PandasIndex(DatetimeIndex(['2023-07-01', '2023-07-02', '2023-07-03', '2023-07-04',\n               '2023-07-05', '2023-07-06', '2023-07-07', '2023-07-08',\n               '2023-07-09', '2023-07-10', '2023-07-11', '2023-07-12',\n               '2023-07-13', '2023-07-14', '2023-07-15', '2023-07-16',\n               '2023-07-17', '2023-07-18', '2023-07-19', '2023-07-20',\n               '2023-07-21', '2023-07-22', '2023-07-23', '2023-07-24',\n               '2023-07-25', '2023-07-26', '2023-07-27', '2023-07-28',\n               '2023-07-29', '2023-07-30', '2023-07-31'],\n              dtype='datetime64[ns]', name='time', freq=None))</pre></li></ul></li><li>Attributes: (7)Conventions :COARDStitle :mean daily NMC reanalysis (2014)history :created 2017/12 by Hoop (netCDF2.3)description :Data is from NMC initialized reanalysis (4x/day).  These are the 0.9950 sigma level values.platform :ModelReferences :http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reanalysis.htmldataset_title :NCEP-NCAR Reanalysis 1</li></ul> <p>Or, if you wanted to select data from a specific day of each month, you could use:</p> In\u00a0[46]: Copied! <pre>ds.sel(time=ds.time.dt.day == 15)\n</pre> ds.sel(time=ds.time.dt.day == 15) Out[46]: <pre>&lt;xarray.Dataset&gt;\nDimensions:    (lat: 73, lon: 144, time: 12, nbnds: 2)\nCoordinates:\n  * lat        (lat) float32 90.0 87.5 85.0 82.5 ... -82.5 -85.0 -87.5 -90.0\n  * lon        (lon) float32 0.0 2.5 5.0 7.5 10.0 ... 350.0 352.5 355.0 357.5\n  * time       (time) datetime64[ns] 2023-01-15 2023-02-15 ... 2023-12-15\nDimensions without coordinates: nbnds\nData variables:\n    air        (time, lat, lon) float32 244.9 244.9 244.9 ... 250.2 250.2 250.2\n    time_bnds  (time, nbnds) float64 ...\nAttributes:\n    Conventions:    COARDS\n    title:          mean daily NMC reanalysis (2014)\n    history:        created 2017/12 by Hoop (netCDF2.3)\n    description:    Data is from NMC initialized reanalysis\\n(4x/day).  These...\n    platform:       Model\n    References:     http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reana...\n    dataset_title:  NCEP-NCAR Reanalysis 1</pre>xarray.Dataset<ul><li>Dimensions:<ul><li>lat: 73</li><li>lon: 144</li><li>time: 12</li><li>nbnds: 2</li></ul></li><li>Coordinates: (3)<ul><li>lat(lat)float3290.0 87.5 85.0 ... -87.5 -90.0units :degrees_northactual_range :[ 90. -90.]long_name :Latitudestandard_name :latitudeaxis :Y<pre>array([ 90. ,  87.5,  85. ,  82.5,  80. ,  77.5,  75. ,  72.5,  70. ,  67.5,\n        65. ,  62.5,  60. ,  57.5,  55. ,  52.5,  50. ,  47.5,  45. ,  42.5,\n        40. ,  37.5,  35. ,  32.5,  30. ,  27.5,  25. ,  22.5,  20. ,  17.5,\n        15. ,  12.5,  10. ,   7.5,   5. ,   2.5,   0. ,  -2.5,  -5. ,  -7.5,\n       -10. , -12.5, -15. , -17.5, -20. , -22.5, -25. , -27.5, -30. , -32.5,\n       -35. , -37.5, -40. , -42.5, -45. , -47.5, -50. , -52.5, -55. , -57.5,\n       -60. , -62.5, -65. , -67.5, -70. , -72.5, -75. , -77.5, -80. , -82.5,\n       -85. , -87.5, -90. ], dtype=float32)</pre></li><li>lon(lon)float320.0 2.5 5.0 ... 352.5 355.0 357.5units :degrees_eastlong_name :Longitudeactual_range :[  0.  357.5]standard_name :longitudeaxis :X<pre>array([  0. ,   2.5,   5. ,   7.5,  10. ,  12.5,  15. ,  17.5,  20. ,  22.5,\n        25. ,  27.5,  30. ,  32.5,  35. ,  37.5,  40. ,  42.5,  45. ,  47.5,\n        50. ,  52.5,  55. ,  57.5,  60. ,  62.5,  65. ,  67.5,  70. ,  72.5,\n        75. ,  77.5,  80. ,  82.5,  85. ,  87.5,  90. ,  92.5,  95. ,  97.5,\n       100. , 102.5, 105. , 107.5, 110. , 112.5, 115. , 117.5, 120. , 122.5,\n       125. , 127.5, 130. , 132.5, 135. , 137.5, 140. , 142.5, 145. , 147.5,\n       150. , 152.5, 155. , 157.5, 160. , 162.5, 165. , 167.5, 170. , 172.5,\n       175. , 177.5, 180. , 182.5, 185. , 187.5, 190. , 192.5, 195. , 197.5,\n       200. , 202.5, 205. , 207.5, 210. , 212.5, 215. , 217.5, 220. , 222.5,\n       225. , 227.5, 230. , 232.5, 235. , 237.5, 240. , 242.5, 245. , 247.5,\n       250. , 252.5, 255. , 257.5, 260. , 262.5, 265. , 267.5, 270. , 272.5,\n       275. , 277.5, 280. , 282.5, 285. , 287.5, 290. , 292.5, 295. , 297.5,\n       300. , 302.5, 305. , 307.5, 310. , 312.5, 315. , 317.5, 320. , 322.5,\n       325. , 327.5, 330. , 332.5, 335. , 337.5, 340. , 342.5, 345. , 347.5,\n       350. , 352.5, 355. , 357.5], dtype=float32)</pre></li><li>time(time)datetime64[ns]2023-01-15 ... 2023-12-15long_name :Timedelta_t :0000-00-01 00:00:00standard_name :timeaxis :Tavg_period :0000-00-01 00:00:00coordinate_defines :startactual_range :[1954776. 1963512.]<pre>array(['2023-01-15T00:00:00.000000000', '2023-02-15T00:00:00.000000000',\n       '2023-03-15T00:00:00.000000000', '2023-04-15T00:00:00.000000000',\n       '2023-05-15T00:00:00.000000000', '2023-06-15T00:00:00.000000000',\n       '2023-07-15T00:00:00.000000000', '2023-08-15T00:00:00.000000000',\n       '2023-09-15T00:00:00.000000000', '2023-10-15T00:00:00.000000000',\n       '2023-11-15T00:00:00.000000000', '2023-12-15T00:00:00.000000000'],\n      dtype='datetime64[ns]')</pre></li></ul></li><li>Data variables: (2)<ul><li>air(time, lat, lon)float32244.9 244.9 244.9 ... 250.2 250.2long_name :mean Daily Air temperature at sigma level 995units :degKprecision :2GRIB_id :11GRIB_name :TMPvar_desc :Air temperaturedataset :NCEP Reanalysis Daily Averagesstatistic :Meanparent_stat :Individual Obsvalid_range :[185.16 331.16]level_desc :0.995 sigmaactual_range :[191.4  318.05]new_attr :trial dataset in class<pre>array([[[244.89998, 244.89998, ..., 244.89998, 244.89998],\n        [244.22498, 243.87497, ..., 244.87497, 244.54997],\n        ...,\n        [243.27498, 243.22498, ..., 243.47498, 243.34998],\n        [246.54997, 246.54997, ..., 246.54997, 246.54997]],\n\n       [[242.075  , 242.075  , ..., 242.075  , 242.075  ],\n        [237.95   , 237.92499, ..., 238.025  , 238.     ],\n        ...,\n        [235.     , 235.025  , ..., 235.04999, 235.025  ],\n        [236.05   , 236.05   , ..., 236.05   , 236.05   ]],\n\n       ...,\n\n       [[255.52498, 255.52498, ..., 255.52498, 255.52498],\n        [254.19998, 254.19998, ..., 254.24998, 254.22499],\n        ...,\n        [248.44998, 248.22498, ..., 248.92499, 248.72498],\n        [244.525  , 244.525  , ..., 244.525  , 244.525  ]],\n\n       [[258.575  , 258.575  , ..., 258.575  , 258.575  ],\n        [256.8    , 256.775  , ..., 256.875  , 256.825  ],\n        ...,\n        [251.375  , 251.35   , ..., 251.525  , 251.45001],\n        [250.15001, 250.15001, ..., 250.15001, 250.15001]]], dtype=float32)</pre></li><li>time_bnds(time, nbnds)float64...<pre>[24 values with dtype=float64]</pre></li></ul></li><li>Indexes: (3)<ul><li>latPandasIndex<pre>PandasIndex(Index([ 90.0,  87.5,  85.0,  82.5,  80.0,  77.5,  75.0,  72.5,  70.0,  67.5,\n        65.0,  62.5,  60.0,  57.5,  55.0,  52.5,  50.0,  47.5,  45.0,  42.5,\n        40.0,  37.5,  35.0,  32.5,  30.0,  27.5,  25.0,  22.5,  20.0,  17.5,\n        15.0,  12.5,  10.0,   7.5,   5.0,   2.5,   0.0,  -2.5,  -5.0,  -7.5,\n       -10.0, -12.5, -15.0, -17.5, -20.0, -22.5, -25.0, -27.5, -30.0, -32.5,\n       -35.0, -37.5, -40.0, -42.5, -45.0, -47.5, -50.0, -52.5, -55.0, -57.5,\n       -60.0, -62.5, -65.0, -67.5, -70.0, -72.5, -75.0, -77.5, -80.0, -82.5,\n       -85.0, -87.5, -90.0],\n      dtype='float32', name='lat'))</pre></li><li>lonPandasIndex<pre>PandasIndex(Index([  0.0,   2.5,   5.0,   7.5,  10.0,  12.5,  15.0,  17.5,  20.0,  22.5,\n       ...\n       335.0, 337.5, 340.0, 342.5, 345.0, 347.5, 350.0, 352.5, 355.0, 357.5],\n      dtype='float32', name='lon', length=144))</pre></li><li>timePandasIndex<pre>PandasIndex(DatetimeIndex(['2023-01-15', '2023-02-15', '2023-03-15', '2023-04-15',\n               '2023-05-15', '2023-06-15', '2023-07-15', '2023-08-15',\n               '2023-09-15', '2023-10-15', '2023-11-15', '2023-12-15'],\n              dtype='datetime64[ns]', name='time', freq=None))</pre></li></ul></li><li>Attributes: (7)Conventions :COARDStitle :mean daily NMC reanalysis (2014)history :created 2017/12 by Hoop (netCDF2.3)description :Data is from NMC initialized reanalysis (4x/day).  These are the 0.9950 sigma level values.platform :ModelReferences :http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reanalysis.htmldataset_title :NCEP-NCAR Reanalysis 1</li></ul> In\u00a0[\u00a0]: Copied! <pre>\n</pre> <p>Similar to Pandas, xarray supports different kinds of arithmetic operations</p> In\u00a0[54]: Copied! <pre>ds['air_C'] = ds['air'] - 273.15\n</pre> ds['air_C'] = ds['air'] - 273.15 In\u00a0[55]: Copied! <pre>ds['air_C']\n</pre> ds['air_C'] Out[55]: <pre>&lt;xarray.DataArray 'air_C' (time: 365, lat: 73, lon: 144)&gt;\narray([[[-26.575012, -26.575012, -26.575012, ..., -26.575012,\n         -26.575012, -26.575012],\n        [-25.100006, -25.175018, -25.225006, ..., -24.850006,\n         -24.950012, -25.02501 ],\n        [-17.625015, -17.075012, -16.525024, ..., -19.15001 ,\n         -18.675003, -18.15001 ],\n        ...,\n        [-21.825012, -21.650024, -21.450012, ..., -22.175018,\n         -22.100006, -22.000015],\n        [-21.575012, -21.550018, -21.525024, ..., -21.574997,\n         -21.574997, -21.575012],\n        [-21.925018, -21.925018, -21.925018, ..., -21.925018,\n         -21.925018, -21.925018]],\n\n       [[-24.950012, -24.950012, -24.950012, ..., -24.950012,\n         -24.950012, -24.950012],\n        [-19.750015, -19.750015, -19.800018, ..., -19.800018,\n         -19.775024, -19.77501 ],\n        [-13.850006, -13.175018, -12.600006, ..., -16.00003 ,\n         -15.275024, -14.550018],\n...\n        [-23.425003, -23.34999 , -23.27501 , ..., -23.574982,\n         -23.574997, -23.52501 ],\n        [-18.850006, -18.949997, -19.075012, ..., -18.300003,\n         -18.5     , -18.65001 ],\n        [-15.049988, -15.049988, -15.049988, ..., -15.049988,\n         -15.049988, -15.049988]],\n\n       [[-19.325012, -19.325012, -19.325012, ..., -19.325012,\n         -19.325012, -19.325012],\n        [-15.850006, -15.75    , -15.675018, ..., -16.149994,\n         -16.075012, -15.950012],\n        [-15.5     , -14.399994, -13.350006, ..., -18.725006,\n         -17.700012, -16.575012],\n        ...,\n        [-19.325012, -19.350006, -19.425003, ..., -19.275024,\n         -19.300018, -19.300018],\n        [-17.52501 , -17.675003, -17.800018, ..., -17.025024,\n         -17.225006, -17.425018],\n        [-14.425018, -14.425018, -14.425018, ..., -14.425018,\n         -14.425018, -14.425018]]], dtype=float32)\nCoordinates:\n  * lat      (lat) float32 90.0 87.5 85.0 82.5 80.0 ... -82.5 -85.0 -87.5 -90.0\n  * lon      (lon) float32 0.0 2.5 5.0 7.5 10.0 ... 350.0 352.5 355.0 357.5\n  * time     (time) datetime64[ns] 2023-01-01 2023-01-02 ... 2023-12-31</pre>xarray.DataArray'air_C'<ul><li>time: 365</li><li>lat: 73</li><li>lon: 144</li></ul><ul><li>-26.58 -26.58 -26.58 -26.58 -26.58 ... -14.43 -14.43 -14.43 -14.43<pre>array([[[-26.575012, -26.575012, -26.575012, ..., -26.575012,\n         -26.575012, -26.575012],\n        [-25.100006, -25.175018, -25.225006, ..., -24.850006,\n         -24.950012, -25.02501 ],\n        [-17.625015, -17.075012, -16.525024, ..., -19.15001 ,\n         -18.675003, -18.15001 ],\n        ...,\n        [-21.825012, -21.650024, -21.450012, ..., -22.175018,\n         -22.100006, -22.000015],\n        [-21.575012, -21.550018, -21.525024, ..., -21.574997,\n         -21.574997, -21.575012],\n        [-21.925018, -21.925018, -21.925018, ..., -21.925018,\n         -21.925018, -21.925018]],\n\n       [[-24.950012, -24.950012, -24.950012, ..., -24.950012,\n         -24.950012, -24.950012],\n        [-19.750015, -19.750015, -19.800018, ..., -19.800018,\n         -19.775024, -19.77501 ],\n        [-13.850006, -13.175018, -12.600006, ..., -16.00003 ,\n         -15.275024, -14.550018],\n...\n        [-23.425003, -23.34999 , -23.27501 , ..., -23.574982,\n         -23.574997, -23.52501 ],\n        [-18.850006, -18.949997, -19.075012, ..., -18.300003,\n         -18.5     , -18.65001 ],\n        [-15.049988, -15.049988, -15.049988, ..., -15.049988,\n         -15.049988, -15.049988]],\n\n       [[-19.325012, -19.325012, -19.325012, ..., -19.325012,\n         -19.325012, -19.325012],\n        [-15.850006, -15.75    , -15.675018, ..., -16.149994,\n         -16.075012, -15.950012],\n        [-15.5     , -14.399994, -13.350006, ..., -18.725006,\n         -17.700012, -16.575012],\n        ...,\n        [-19.325012, -19.350006, -19.425003, ..., -19.275024,\n         -19.300018, -19.300018],\n        [-17.52501 , -17.675003, -17.800018, ..., -17.025024,\n         -17.225006, -17.425018],\n        [-14.425018, -14.425018, -14.425018, ..., -14.425018,\n         -14.425018, -14.425018]]], dtype=float32)</pre></li><li>Coordinates: (3)<ul><li>lat(lat)float3290.0 87.5 85.0 ... -87.5 -90.0units :degrees_northactual_range :[ 90. -90.]long_name :Latitudestandard_name :latitudeaxis :Y<pre>array([ 90. ,  87.5,  85. ,  82.5,  80. ,  77.5,  75. ,  72.5,  70. ,  67.5,\n        65. ,  62.5,  60. ,  57.5,  55. ,  52.5,  50. ,  47.5,  45. ,  42.5,\n        40. ,  37.5,  35. ,  32.5,  30. ,  27.5,  25. ,  22.5,  20. ,  17.5,\n        15. ,  12.5,  10. ,   7.5,   5. ,   2.5,   0. ,  -2.5,  -5. ,  -7.5,\n       -10. , -12.5, -15. , -17.5, -20. , -22.5, -25. , -27.5, -30. , -32.5,\n       -35. , -37.5, -40. , -42.5, -45. , -47.5, -50. , -52.5, -55. , -57.5,\n       -60. , -62.5, -65. , -67.5, -70. , -72.5, -75. , -77.5, -80. , -82.5,\n       -85. , -87.5, -90. ], dtype=float32)</pre></li><li>lon(lon)float320.0 2.5 5.0 ... 352.5 355.0 357.5units :degrees_eastlong_name :Longitudeactual_range :[  0.  357.5]standard_name :longitudeaxis :X<pre>array([  0. ,   2.5,   5. ,   7.5,  10. ,  12.5,  15. ,  17.5,  20. ,  22.5,\n        25. ,  27.5,  30. ,  32.5,  35. ,  37.5,  40. ,  42.5,  45. ,  47.5,\n        50. ,  52.5,  55. ,  57.5,  60. ,  62.5,  65. ,  67.5,  70. ,  72.5,\n        75. ,  77.5,  80. ,  82.5,  85. ,  87.5,  90. ,  92.5,  95. ,  97.5,\n       100. , 102.5, 105. , 107.5, 110. , 112.5, 115. , 117.5, 120. , 122.5,\n       125. , 127.5, 130. , 132.5, 135. , 137.5, 140. , 142.5, 145. , 147.5,\n       150. , 152.5, 155. , 157.5, 160. , 162.5, 165. , 167.5, 170. , 172.5,\n       175. , 177.5, 180. , 182.5, 185. , 187.5, 190. , 192.5, 195. , 197.5,\n       200. , 202.5, 205. , 207.5, 210. , 212.5, 215. , 217.5, 220. , 222.5,\n       225. , 227.5, 230. , 232.5, 235. , 237.5, 240. , 242.5, 245. , 247.5,\n       250. , 252.5, 255. , 257.5, 260. , 262.5, 265. , 267.5, 270. , 272.5,\n       275. , 277.5, 280. , 282.5, 285. , 287.5, 290. , 292.5, 295. , 297.5,\n       300. , 302.5, 305. , 307.5, 310. , 312.5, 315. , 317.5, 320. , 322.5,\n       325. , 327.5, 330. , 332.5, 335. , 337.5, 340. , 342.5, 345. , 347.5,\n       350. , 352.5, 355. , 357.5], dtype=float32)</pre></li><li>time(time)datetime64[ns]2023-01-01 ... 2023-12-31long_name :Timedelta_t :0000-00-01 00:00:00standard_name :timeaxis :Tavg_period :0000-00-01 00:00:00coordinate_defines :startactual_range :[1954776. 1963512.]<pre>array(['2023-01-01T00:00:00.000000000', '2023-01-02T00:00:00.000000000',\n       '2023-01-03T00:00:00.000000000', ..., '2023-12-29T00:00:00.000000000',\n       '2023-12-30T00:00:00.000000000', '2023-12-31T00:00:00.000000000'],\n      dtype='datetime64[ns]')</pre></li></ul></li><li>Indexes: (3)<ul><li>latPandasIndex<pre>PandasIndex(Index([ 90.0,  87.5,  85.0,  82.5,  80.0,  77.5,  75.0,  72.5,  70.0,  67.5,\n        65.0,  62.5,  60.0,  57.5,  55.0,  52.5,  50.0,  47.5,  45.0,  42.5,\n        40.0,  37.5,  35.0,  32.5,  30.0,  27.5,  25.0,  22.5,  20.0,  17.5,\n        15.0,  12.5,  10.0,   7.5,   5.0,   2.5,   0.0,  -2.5,  -5.0,  -7.5,\n       -10.0, -12.5, -15.0, -17.5, -20.0, -22.5, -25.0, -27.5, -30.0, -32.5,\n       -35.0, -37.5, -40.0, -42.5, -45.0, -47.5, -50.0, -52.5, -55.0, -57.5,\n       -60.0, -62.5, -65.0, -67.5, -70.0, -72.5, -75.0, -77.5, -80.0, -82.5,\n       -85.0, -87.5, -90.0],\n      dtype='float32', name='lat'))</pre></li><li>lonPandasIndex<pre>PandasIndex(Index([  0.0,   2.5,   5.0,   7.5,  10.0,  12.5,  15.0,  17.5,  20.0,  22.5,\n       ...\n       335.0, 337.5, 340.0, 342.5, 345.0, 347.5, 350.0, 352.5, 355.0, 357.5],\n      dtype='float32', name='lon', length=144))</pre></li><li>timePandasIndex<pre>PandasIndex(DatetimeIndex(['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04',\n               '2023-01-05', '2023-01-06', '2023-01-07', '2023-01-08',\n               '2023-01-09', '2023-01-10',\n               ...\n               '2023-12-22', '2023-12-23', '2023-12-24', '2023-12-25',\n               '2023-12-26', '2023-12-27', '2023-12-28', '2023-12-29',\n               '2023-12-30', '2023-12-31'],\n              dtype='datetime64[ns]', name='time', length=365, freq=None))</pre></li></ul></li><li>Attributes: (0)</li></ul> In\u00a0[56]: Copied! <pre># Generate a boolean mask where temperature is higher than 0\u02daC\nds['air_C'] &gt;  0\n</pre> # Generate a boolean mask where temperature is higher than 0\u02daC ds['air_C'] &gt;  0  Out[56]: <pre>&lt;xarray.DataArray 'air_C' (time: 365, lat: 73, lon: 144)&gt;\narray([[[False, False, False, ..., False, False, False],\n        [False, False, False, ..., False, False, False],\n        [False, False, False, ..., False, False, False],\n        ...,\n        [False, False, False, ..., False, False, False],\n        [False, False, False, ..., False, False, False],\n        [False, False, False, ..., False, False, False]],\n\n       [[False, False, False, ..., False, False, False],\n        [False, False, False, ..., False, False, False],\n        [False, False, False, ..., False, False, False],\n        ...,\n        [False, False, False, ..., False, False, False],\n        [False, False, False, ..., False, False, False],\n        [False, False, False, ..., False, False, False]],\n\n       [[False, False, False, ..., False, False, False],\n        [False, False, False, ..., False, False, False],\n        [False, False, False, ..., False, False, False],\n        ...,\n...\n        ...,\n        [False, False, False, ..., False, False, False],\n        [False, False, False, ..., False, False, False],\n        [False, False, False, ..., False, False, False]],\n\n       [[False, False, False, ..., False, False, False],\n        [False, False, False, ..., False, False, False],\n        [False, False, False, ..., False, False, False],\n        ...,\n        [False, False, False, ..., False, False, False],\n        [False, False, False, ..., False, False, False],\n        [False, False, False, ..., False, False, False]],\n\n       [[False, False, False, ..., False, False, False],\n        [False, False, False, ..., False, False, False],\n        [False, False, False, ..., False, False, False],\n        ...,\n        [False, False, False, ..., False, False, False],\n        [False, False, False, ..., False, False, False],\n        [False, False, False, ..., False, False, False]]])\nCoordinates:\n  * lat      (lat) float32 90.0 87.5 85.0 82.5 80.0 ... -82.5 -85.0 -87.5 -90.0\n  * lon      (lon) float32 0.0 2.5 5.0 7.5 10.0 ... 350.0 352.5 355.0 357.5\n  * time     (time) datetime64[ns] 2023-01-01 2023-01-02 ... 2023-12-31</pre>xarray.DataArray'air_C'<ul><li>time: 365</li><li>lat: 73</li><li>lon: 144</li></ul><ul><li>False False False False False False ... False False False False False<pre>array([[[False, False, False, ..., False, False, False],\n        [False, False, False, ..., False, False, False],\n        [False, False, False, ..., False, False, False],\n        ...,\n        [False, False, False, ..., False, False, False],\n        [False, False, False, ..., False, False, False],\n        [False, False, False, ..., False, False, False]],\n\n       [[False, False, False, ..., False, False, False],\n        [False, False, False, ..., False, False, False],\n        [False, False, False, ..., False, False, False],\n        ...,\n        [False, False, False, ..., False, False, False],\n        [False, False, False, ..., False, False, False],\n        [False, False, False, ..., False, False, False]],\n\n       [[False, False, False, ..., False, False, False],\n        [False, False, False, ..., False, False, False],\n        [False, False, False, ..., False, False, False],\n        ...,\n...\n        ...,\n        [False, False, False, ..., False, False, False],\n        [False, False, False, ..., False, False, False],\n        [False, False, False, ..., False, False, False]],\n\n       [[False, False, False, ..., False, False, False],\n        [False, False, False, ..., False, False, False],\n        [False, False, False, ..., False, False, False],\n        ...,\n        [False, False, False, ..., False, False, False],\n        [False, False, False, ..., False, False, False],\n        [False, False, False, ..., False, False, False]],\n\n       [[False, False, False, ..., False, False, False],\n        [False, False, False, ..., False, False, False],\n        [False, False, False, ..., False, False, False],\n        ...,\n        [False, False, False, ..., False, False, False],\n        [False, False, False, ..., False, False, False],\n        [False, False, False, ..., False, False, False]]])</pre></li><li>Coordinates: (3)<ul><li>lat(lat)float3290.0 87.5 85.0 ... -87.5 -90.0units :degrees_northactual_range :[ 90. -90.]long_name :Latitudestandard_name :latitudeaxis :Y<pre>array([ 90. ,  87.5,  85. ,  82.5,  80. ,  77.5,  75. ,  72.5,  70. ,  67.5,\n        65. ,  62.5,  60. ,  57.5,  55. ,  52.5,  50. ,  47.5,  45. ,  42.5,\n        40. ,  37.5,  35. ,  32.5,  30. ,  27.5,  25. ,  22.5,  20. ,  17.5,\n        15. ,  12.5,  10. ,   7.5,   5. ,   2.5,   0. ,  -2.5,  -5. ,  -7.5,\n       -10. , -12.5, -15. , -17.5, -20. , -22.5, -25. , -27.5, -30. , -32.5,\n       -35. , -37.5, -40. , -42.5, -45. , -47.5, -50. , -52.5, -55. , -57.5,\n       -60. , -62.5, -65. , -67.5, -70. , -72.5, -75. , -77.5, -80. , -82.5,\n       -85. , -87.5, -90. ], dtype=float32)</pre></li><li>lon(lon)float320.0 2.5 5.0 ... 352.5 355.0 357.5units :degrees_eastlong_name :Longitudeactual_range :[  0.  357.5]standard_name :longitudeaxis :X<pre>array([  0. ,   2.5,   5. ,   7.5,  10. ,  12.5,  15. ,  17.5,  20. ,  22.5,\n        25. ,  27.5,  30. ,  32.5,  35. ,  37.5,  40. ,  42.5,  45. ,  47.5,\n        50. ,  52.5,  55. ,  57.5,  60. ,  62.5,  65. ,  67.5,  70. ,  72.5,\n        75. ,  77.5,  80. ,  82.5,  85. ,  87.5,  90. ,  92.5,  95. ,  97.5,\n       100. , 102.5, 105. , 107.5, 110. , 112.5, 115. , 117.5, 120. , 122.5,\n       125. , 127.5, 130. , 132.5, 135. , 137.5, 140. , 142.5, 145. , 147.5,\n       150. , 152.5, 155. , 157.5, 160. , 162.5, 165. , 167.5, 170. , 172.5,\n       175. , 177.5, 180. , 182.5, 185. , 187.5, 190. , 192.5, 195. , 197.5,\n       200. , 202.5, 205. , 207.5, 210. , 212.5, 215. , 217.5, 220. , 222.5,\n       225. , 227.5, 230. , 232.5, 235. , 237.5, 240. , 242.5, 245. , 247.5,\n       250. , 252.5, 255. , 257.5, 260. , 262.5, 265. , 267.5, 270. , 272.5,\n       275. , 277.5, 280. , 282.5, 285. , 287.5, 290. , 292.5, 295. , 297.5,\n       300. , 302.5, 305. , 307.5, 310. , 312.5, 315. , 317.5, 320. , 322.5,\n       325. , 327.5, 330. , 332.5, 335. , 337.5, 340. , 342.5, 345. , 347.5,\n       350. , 352.5, 355. , 357.5], dtype=float32)</pre></li><li>time(time)datetime64[ns]2023-01-01 ... 2023-12-31long_name :Timedelta_t :0000-00-01 00:00:00standard_name :timeaxis :Tavg_period :0000-00-01 00:00:00coordinate_defines :startactual_range :[1954776. 1963512.]<pre>array(['2023-01-01T00:00:00.000000000', '2023-01-02T00:00:00.000000000',\n       '2023-01-03T00:00:00.000000000', ..., '2023-12-29T00:00:00.000000000',\n       '2023-12-30T00:00:00.000000000', '2023-12-31T00:00:00.000000000'],\n      dtype='datetime64[ns]')</pre></li></ul></li><li>Indexes: (3)<ul><li>latPandasIndex<pre>PandasIndex(Index([ 90.0,  87.5,  85.0,  82.5,  80.0,  77.5,  75.0,  72.5,  70.0,  67.5,\n        65.0,  62.5,  60.0,  57.5,  55.0,  52.5,  50.0,  47.5,  45.0,  42.5,\n        40.0,  37.5,  35.0,  32.5,  30.0,  27.5,  25.0,  22.5,  20.0,  17.5,\n        15.0,  12.5,  10.0,   7.5,   5.0,   2.5,   0.0,  -2.5,  -5.0,  -7.5,\n       -10.0, -12.5, -15.0, -17.5, -20.0, -22.5, -25.0, -27.5, -30.0, -32.5,\n       -35.0, -37.5, -40.0, -42.5, -45.0, -47.5, -50.0, -52.5, -55.0, -57.5,\n       -60.0, -62.5, -65.0, -67.5, -70.0, -72.5, -75.0, -77.5, -80.0, -82.5,\n       -85.0, -87.5, -90.0],\n      dtype='float32', name='lat'))</pre></li><li>lonPandasIndex<pre>PandasIndex(Index([  0.0,   2.5,   5.0,   7.5,  10.0,  12.5,  15.0,  17.5,  20.0,  22.5,\n       ...\n       335.0, 337.5, 340.0, 342.5, 345.0, 347.5, 350.0, 352.5, 355.0, 357.5],\n      dtype='float32', name='lon', length=144))</pre></li><li>timePandasIndex<pre>PandasIndex(DatetimeIndex(['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04',\n               '2023-01-05', '2023-01-06', '2023-01-07', '2023-01-08',\n               '2023-01-09', '2023-01-10',\n               ...\n               '2023-12-22', '2023-12-23', '2023-12-24', '2023-12-25',\n               '2023-12-26', '2023-12-27', '2023-12-28', '2023-12-29',\n               '2023-12-30', '2023-12-31'],\n              dtype='datetime64[ns]', name='time', length=365, freq=None))</pre></li></ul></li><li>Attributes: (0)</li></ul> In\u00a0[57]: Copied! <pre># Generate a boolean mask where annual mean temperature is higher than 0\u02daC\nds['air_C'].mean(dim='time') &gt;  0\n</pre> # Generate a boolean mask where annual mean temperature is higher than 0\u02daC ds['air_C'].mean(dim='time') &gt;  0  Out[57]: <pre>&lt;xarray.DataArray 'air_C' (lat: 73, lon: 144)&gt;\narray([[False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False],\n       ...,\n       [False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False]])\nCoordinates:\n  * lat      (lat) float32 90.0 87.5 85.0 82.5 80.0 ... -82.5 -85.0 -87.5 -90.0\n  * lon      (lon) float32 0.0 2.5 5.0 7.5 10.0 ... 350.0 352.5 355.0 357.5</pre>xarray.DataArray'air_C'<ul><li>lat: 73</li><li>lon: 144</li></ul><ul><li>False False False False False False ... False False False False False<pre>array([[False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False],\n       ...,\n       [False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False]])</pre></li><li>Coordinates: (2)<ul><li>lat(lat)float3290.0 87.5 85.0 ... -87.5 -90.0units :degrees_northactual_range :[ 90. -90.]long_name :Latitudestandard_name :latitudeaxis :Y<pre>array([ 90. ,  87.5,  85. ,  82.5,  80. ,  77.5,  75. ,  72.5,  70. ,  67.5,\n        65. ,  62.5,  60. ,  57.5,  55. ,  52.5,  50. ,  47.5,  45. ,  42.5,\n        40. ,  37.5,  35. ,  32.5,  30. ,  27.5,  25. ,  22.5,  20. ,  17.5,\n        15. ,  12.5,  10. ,   7.5,   5. ,   2.5,   0. ,  -2.5,  -5. ,  -7.5,\n       -10. , -12.5, -15. , -17.5, -20. , -22.5, -25. , -27.5, -30. , -32.5,\n       -35. , -37.5, -40. , -42.5, -45. , -47.5, -50. , -52.5, -55. , -57.5,\n       -60. , -62.5, -65. , -67.5, -70. , -72.5, -75. , -77.5, -80. , -82.5,\n       -85. , -87.5, -90. ], dtype=float32)</pre></li><li>lon(lon)float320.0 2.5 5.0 ... 352.5 355.0 357.5units :degrees_eastlong_name :Longitudeactual_range :[  0.  357.5]standard_name :longitudeaxis :X<pre>array([  0. ,   2.5,   5. ,   7.5,  10. ,  12.5,  15. ,  17.5,  20. ,  22.5,\n        25. ,  27.5,  30. ,  32.5,  35. ,  37.5,  40. ,  42.5,  45. ,  47.5,\n        50. ,  52.5,  55. ,  57.5,  60. ,  62.5,  65. ,  67.5,  70. ,  72.5,\n        75. ,  77.5,  80. ,  82.5,  85. ,  87.5,  90. ,  92.5,  95. ,  97.5,\n       100. , 102.5, 105. , 107.5, 110. , 112.5, 115. , 117.5, 120. , 122.5,\n       125. , 127.5, 130. , 132.5, 135. , 137.5, 140. , 142.5, 145. , 147.5,\n       150. , 152.5, 155. , 157.5, 160. , 162.5, 165. , 167.5, 170. , 172.5,\n       175. , 177.5, 180. , 182.5, 185. , 187.5, 190. , 192.5, 195. , 197.5,\n       200. , 202.5, 205. , 207.5, 210. , 212.5, 215. , 217.5, 220. , 222.5,\n       225. , 227.5, 230. , 232.5, 235. , 237.5, 240. , 242.5, 245. , 247.5,\n       250. , 252.5, 255. , 257.5, 260. , 262.5, 265. , 267.5, 270. , 272.5,\n       275. , 277.5, 280. , 282.5, 285. , 287.5, 290. , 292.5, 295. , 297.5,\n       300. , 302.5, 305. , 307.5, 310. , 312.5, 315. , 317.5, 320. , 322.5,\n       325. , 327.5, 330. , 332.5, 335. , 337.5, 340. , 342.5, 345. , 347.5,\n       350. , 352.5, 355. , 357.5], dtype=float32)</pre></li></ul></li><li>Indexes: (2)<ul><li>latPandasIndex<pre>PandasIndex(Index([ 90.0,  87.5,  85.0,  82.5,  80.0,  77.5,  75.0,  72.5,  70.0,  67.5,\n        65.0,  62.5,  60.0,  57.5,  55.0,  52.5,  50.0,  47.5,  45.0,  42.5,\n        40.0,  37.5,  35.0,  32.5,  30.0,  27.5,  25.0,  22.5,  20.0,  17.5,\n        15.0,  12.5,  10.0,   7.5,   5.0,   2.5,   0.0,  -2.5,  -5.0,  -7.5,\n       -10.0, -12.5, -15.0, -17.5, -20.0, -22.5, -25.0, -27.5, -30.0, -32.5,\n       -35.0, -37.5, -40.0, -42.5, -45.0, -47.5, -50.0, -52.5, -55.0, -57.5,\n       -60.0, -62.5, -65.0, -67.5, -70.0, -72.5, -75.0, -77.5, -80.0, -82.5,\n       -85.0, -87.5, -90.0],\n      dtype='float32', name='lat'))</pre></li><li>lonPandasIndex<pre>PandasIndex(Index([  0.0,   2.5,   5.0,   7.5,  10.0,  12.5,  15.0,  17.5,  20.0,  22.5,\n       ...\n       335.0, 337.5, 340.0, 342.5, 345.0, 347.5, 350.0, 352.5, 355.0, 357.5],\n      dtype='float32', name='lon', length=144))</pre></li></ul></li><li>Attributes: (0)</li></ul> In\u00a0[58]: Copied! <pre>(ds['air_C'].mean(dim='time') &gt;  0).plot()\n</pre> (ds['air_C'].mean(dim='time') &gt;  0).plot() Out[58]: <pre>&lt;matplotlib.collections.QuadMesh at 0x195485310&gt;</pre> In\u00a0[59]: Copied! <pre># Apply the mask:\nds.where(ds['air_C'].mean(dim='time') &gt;  0).mean(dim = 'time').air.plot()\n</pre> # Apply the mask: ds.where(ds['air_C'].mean(dim='time') &gt;  0).mean(dim = 'time').air.plot() Out[59]: <pre>&lt;matplotlib.collections.QuadMesh at 0x1955a9910&gt;</pre> In\u00a0[60]: Copied! <pre>ds['air_C'].mean(dim='time').plot()\n</pre> ds['air_C'].mean(dim='time').plot() Out[60]: <pre>&lt;matplotlib.collections.QuadMesh at 0x195688a90&gt;</pre> In\u00a0[61]: Copied! <pre>(ds['air_C'].mean(dim='time')*np.cos(np.deg2rad(ds.lat))).plot()\n</pre> (ds['air_C'].mean(dim='time')*np.cos(np.deg2rad(ds.lat))).plot() Out[61]: <pre>&lt;matplotlib.collections.QuadMesh at 0x195764460&gt;</pre> In\u00a0[63]: Copied! <pre># Make cos(lat) two dimensional\n(xr.ones_like(ds['air_C'].mean(dim='time'))*np.cos(np.deg2rad(ds.lat))).plot()\n</pre> # Make cos(lat) two dimensional (xr.ones_like(ds['air_C'].mean(dim='time'))*np.cos(np.deg2rad(ds.lat))).plot() Out[63]: <pre>&lt;matplotlib.collections.QuadMesh at 0x1953c84c0&gt;</pre> In\u00a0[66]: Copied! <pre># Group by season\nds.groupby(\"time.season\")\n</pre> # Group by season ds.groupby(\"time.season\") Out[66]: <pre>DatasetGroupBy, grouped over 'season'\n4 groups with labels 'DJF', 'JJA', 'MAM', 'SON'.</pre> In\u00a0[67]: Copied! <pre># make a seasonal mean\nseasonal_mean = ds.groupby(\"time.season\").mean()\nseasonal_mean\n</pre> # make a seasonal mean seasonal_mean = ds.groupby(\"time.season\").mean() seasonal_mean Out[67]: <pre>&lt;xarray.Dataset&gt;\nDimensions:    (lat: 73, lon: 144, season: 4, nbnds: 2)\nCoordinates:\n  * lat        (lat) float32 90.0 87.5 85.0 82.5 ... -82.5 -85.0 -87.5 -90.0\n  * lon        (lon) float32 0.0 2.5 5.0 7.5 10.0 ... 350.0 352.5 355.0 357.5\n  * season     (season) object 'DJF' 'JJA' 'MAM' 'SON'\nDimensions without coordinates: nbnds\nData variables:\n    air        (season, lat, lon) float32 249.7 249.7 249.7 ... 231.8 231.8\n    time_bnds  (season, nbnds) float64 1.958e+06 1.958e+06 ... 1.962e+06\n    air_C      (season, lat, lon) float32 -23.49 -23.49 -23.49 ... -41.3 -41.3\nAttributes:\n    Conventions:    COARDS\n    title:          mean daily NMC reanalysis (2014)\n    history:        created 2017/12 by Hoop (netCDF2.3)\n    description:    Data is from NMC initialized reanalysis\\n(4x/day).  These...\n    platform:       Model\n    References:     http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reana...\n    dataset_title:  NCEP-NCAR Reanalysis 1</pre>xarray.Dataset<ul><li>Dimensions:<ul><li>lat: 73</li><li>lon: 144</li><li>season: 4</li><li>nbnds: 2</li></ul></li><li>Coordinates: (3)<ul><li>lat(lat)float3290.0 87.5 85.0 ... -87.5 -90.0units :degrees_northactual_range :[ 90. -90.]long_name :Latitudestandard_name :latitudeaxis :Y<pre>array([ 90. ,  87.5,  85. ,  82.5,  80. ,  77.5,  75. ,  72.5,  70. ,  67.5,\n        65. ,  62.5,  60. ,  57.5,  55. ,  52.5,  50. ,  47.5,  45. ,  42.5,\n        40. ,  37.5,  35. ,  32.5,  30. ,  27.5,  25. ,  22.5,  20. ,  17.5,\n        15. ,  12.5,  10. ,   7.5,   5. ,   2.5,   0. ,  -2.5,  -5. ,  -7.5,\n       -10. , -12.5, -15. , -17.5, -20. , -22.5, -25. , -27.5, -30. , -32.5,\n       -35. , -37.5, -40. , -42.5, -45. , -47.5, -50. , -52.5, -55. , -57.5,\n       -60. , -62.5, -65. , -67.5, -70. , -72.5, -75. , -77.5, -80. , -82.5,\n       -85. , -87.5, -90. ], dtype=float32)</pre></li><li>lon(lon)float320.0 2.5 5.0 ... 352.5 355.0 357.5units :degrees_eastlong_name :Longitudeactual_range :[  0.  357.5]standard_name :longitudeaxis :X<pre>array([  0. ,   2.5,   5. ,   7.5,  10. ,  12.5,  15. ,  17.5,  20. ,  22.5,\n        25. ,  27.5,  30. ,  32.5,  35. ,  37.5,  40. ,  42.5,  45. ,  47.5,\n        50. ,  52.5,  55. ,  57.5,  60. ,  62.5,  65. ,  67.5,  70. ,  72.5,\n        75. ,  77.5,  80. ,  82.5,  85. ,  87.5,  90. ,  92.5,  95. ,  97.5,\n       100. , 102.5, 105. , 107.5, 110. , 112.5, 115. , 117.5, 120. , 122.5,\n       125. , 127.5, 130. , 132.5, 135. , 137.5, 140. , 142.5, 145. , 147.5,\n       150. , 152.5, 155. , 157.5, 160. , 162.5, 165. , 167.5, 170. , 172.5,\n       175. , 177.5, 180. , 182.5, 185. , 187.5, 190. , 192.5, 195. , 197.5,\n       200. , 202.5, 205. , 207.5, 210. , 212.5, 215. , 217.5, 220. , 222.5,\n       225. , 227.5, 230. , 232.5, 235. , 237.5, 240. , 242.5, 245. , 247.5,\n       250. , 252.5, 255. , 257.5, 260. , 262.5, 265. , 267.5, 270. , 272.5,\n       275. , 277.5, 280. , 282.5, 285. , 287.5, 290. , 292.5, 295. , 297.5,\n       300. , 302.5, 305. , 307.5, 310. , 312.5, 315. , 317.5, 320. , 322.5,\n       325. , 327.5, 330. , 332.5, 335. , 337.5, 340. , 342.5, 345. , 347.5,\n       350. , 352.5, 355. , 357.5], dtype=float32)</pre></li><li>season(season)object'DJF' 'JJA' 'MAM' 'SON'<pre>array(['DJF', 'JJA', 'MAM', 'SON'], dtype=object)</pre></li></ul></li><li>Data variables: (3)<ul><li>air(season, lat, lon)float32249.7 249.7 249.7 ... 231.8 231.8long_name :mean Daily Air temperature at sigma level 995units :degKprecision :2GRIB_id :11GRIB_name :TMPvar_desc :Air temperaturedataset :NCEP Reanalysis Daily Averagesstatistic :Meanparent_stat :Individual Obsvalid_range :[185.16 331.16]level_desc :0.995 sigmaactual_range :[191.4  318.05]new_attr :trial dataset in class<pre>array([[[249.66248, 249.66248, 249.66248, ..., 249.66248, 249.66248,\n         249.66248],\n        [249.47447, 249.43034, 249.3883 , ..., 249.59448, 249.55675,\n         249.51605],\n        [251.40558, 251.77364, 252.1219 , ..., 250.34584, 250.68887,\n         251.04605],\n        ...,\n        [246.88249, 247.04944, 247.2267 , ..., 246.61916, 246.65111,\n         246.74338],\n        [247.05777, 247.02469, 246.99976, ..., 247.2275 , 247.16055,\n         247.10136],\n        [246.13889, 246.13889, 246.13889, ..., 246.13889, 246.13889,\n         246.13889]],\n\n       [[273.9883 , 273.9883 , 273.9883 , ..., 273.9883 , 273.9883 ,\n         273.9883 ],\n        [273.57007, 273.5505 , 273.5334 , ..., 273.63535, 273.6117 ,\n         273.59268],\n        [273.94943, 273.94342, 273.9385 , ..., 273.9731 , 273.96576,\n         273.95624],\n...\n        [224.47337, 224.37366, 224.32877, ..., 225.2992 , 224.9196 ,\n         224.6486 ],\n        [225.49403, 225.25516, 225.0416 , ..., 226.3419 , 226.03479,\n         225.75435],\n        [225.40898, 225.40898, 225.40898, ..., 225.40898, 225.40898,\n         225.40898]],\n\n       [[260.0237 , 260.0237 , 260.0237 , ..., 260.0237 , 260.0237 ,\n         260.0237 ],\n        [258.5824 , 258.6247 , 258.6637 , ..., 258.46753, 258.50467,\n         258.54642],\n        [257.5351 , 257.7901 , 258.05328, ..., 256.922  , 257.09897,\n         257.30157],\n        ...,\n        [234.2973 , 234.38106, 234.50986, ..., 234.48547, 234.33018,\n         234.27284],\n        [233.31377, 233.17357, 233.05106, ..., 233.84811, 233.65442,\n         233.47386],\n        [231.84583, 231.84583, 231.84583, ..., 231.84583, 231.84583,\n         231.84583]]], dtype=float32)</pre></li><li>time_bnds(season, nbnds)float641.958e+06 1.958e+06 ... 1.962e+06<pre>array([[1958117.33333333, 1958141.33333333],\n       [1959492.        , 1959516.        ],\n       [1957284.        , 1957308.        ],\n       [1961688.        , 1961712.        ]])</pre></li><li>air_C(season, lat, lon)float32-23.49 -23.49 ... -41.3 -41.3<pre>array([[[-23.4875    , -23.4875    , -23.4875    , ..., -23.4875    ,\n         -23.4875    , -23.4875    ],\n        [-23.675562  , -23.719732  , -23.76167   , ..., -23.555561  ,\n         -23.593338  , -23.633894  ],\n        [-21.744452  , -21.376392  , -21.028063  , ..., -22.804173  ,\n         -22.461111  , -22.10389   ],\n        ...,\n        [-26.2675    , -26.100561  , -25.92334   , ..., -26.530838  ,\n         -26.4989    , -26.406666  ],\n        [-26.092234  , -26.125282  , -26.15028   , ..., -25.922504  ,\n         -25.98945   , -26.048609  ],\n        [-27.011114  , -27.011114  , -27.011114  , ..., -27.011114  ,\n         -27.011114  , -27.011114  ]],\n\n       [[  0.83831453,   0.83831453,   0.83831453, ...,   0.83831453,\n           0.83831453,   0.83831453],\n        [  0.42010897,   0.4005442 ,   0.38342518, ...,   0.48532933,\n           0.46168685,   0.44266477],\n        [  0.7994557 ,   0.79348123,   0.78858817, ...,   0.8230979 ,\n           0.81575876,   0.8062492 ],\n...\n        [-48.67664   , -48.776363  , -48.821198  , ..., -47.850815  ,\n         -48.230442  , -48.501366  ],\n        [-47.65598   , -47.89484   , -48.108425  , ..., -46.808147  ,\n         -47.11523   , -47.395645  ],\n        [-47.741035  , -47.741035  , -47.741035  , ..., -47.741035  ,\n         -47.741035  , -47.741035  ]],\n\n       [[-13.126376  , -13.126376  , -13.126376  , ..., -13.126376  ,\n         -13.126376  , -13.126376  ],\n        [-14.567581  , -14.525279  , -14.486265  , ..., -14.682419  ,\n         -14.645333  , -14.603572  ],\n        [-15.614838  , -15.35989   , -15.096706  , ..., -16.228025  ,\n         -16.051104  , -15.848355  ],\n        ...,\n        [-38.852757  , -38.768967  , -38.64011   , ..., -38.664574  ,\n         -38.819782  , -38.87719   ],\n        [-39.83627   , -39.97638   , -40.09892   , ..., -39.301926  ,\n         -39.4956    , -39.6761    ],\n        [-41.304108  , -41.304108  , -41.304108  , ..., -41.304108  ,\n         -41.304108  , -41.304108  ]]], dtype=float32)</pre></li></ul></li><li>Indexes: (3)<ul><li>latPandasIndex<pre>PandasIndex(Index([ 90.0,  87.5,  85.0,  82.5,  80.0,  77.5,  75.0,  72.5,  70.0,  67.5,\n        65.0,  62.5,  60.0,  57.5,  55.0,  52.5,  50.0,  47.5,  45.0,  42.5,\n        40.0,  37.5,  35.0,  32.5,  30.0,  27.5,  25.0,  22.5,  20.0,  17.5,\n        15.0,  12.5,  10.0,   7.5,   5.0,   2.5,   0.0,  -2.5,  -5.0,  -7.5,\n       -10.0, -12.5, -15.0, -17.5, -20.0, -22.5, -25.0, -27.5, -30.0, -32.5,\n       -35.0, -37.5, -40.0, -42.5, -45.0, -47.5, -50.0, -52.5, -55.0, -57.5,\n       -60.0, -62.5, -65.0, -67.5, -70.0, -72.5, -75.0, -77.5, -80.0, -82.5,\n       -85.0, -87.5, -90.0],\n      dtype='float32', name='lat'))</pre></li><li>lonPandasIndex<pre>PandasIndex(Index([  0.0,   2.5,   5.0,   7.5,  10.0,  12.5,  15.0,  17.5,  20.0,  22.5,\n       ...\n       335.0, 337.5, 340.0, 342.5, 345.0, 347.5, 350.0, 352.5, 355.0, 357.5],\n      dtype='float32', name='lon', length=144))</pre></li><li>seasonPandasIndex<pre>PandasIndex(Index(['DJF', 'JJA', 'MAM', 'SON'], dtype='object', name='season'))</pre></li></ul></li><li>Attributes: (7)Conventions :COARDStitle :mean daily NMC reanalysis (2014)history :created 2017/12 by Hoop (netCDF2.3)description :Data is from NMC initialized reanalysis (4x/day).  These are the 0.9950 sigma level values.platform :ModelReferences :http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reanalysis.htmldataset_title :NCEP-NCAR Reanalysis 1</li></ul> <p>The seasons are out of order (they are alphabetically sorted). This is a common annoyance. The solution is to use <code>.sel</code> to change the order of labels</p> In\u00a0[68]: Copied! <pre>seasonal_mean = seasonal_mean.sel(season=[\"DJF\", \"MAM\", \"JJA\", \"SON\"])\nseasonal_mean\n</pre> seasonal_mean = seasonal_mean.sel(season=[\"DJF\", \"MAM\", \"JJA\", \"SON\"]) seasonal_mean Out[68]: <pre>&lt;xarray.Dataset&gt;\nDimensions:    (lat: 73, lon: 144, season: 4, nbnds: 2)\nCoordinates:\n  * lat        (lat) float32 90.0 87.5 85.0 82.5 ... -82.5 -85.0 -87.5 -90.0\n  * lon        (lon) float32 0.0 2.5 5.0 7.5 10.0 ... 350.0 352.5 355.0 357.5\n  * season     (season) object 'DJF' 'MAM' 'JJA' 'SON'\nDimensions without coordinates: nbnds\nData variables:\n    air        (season, lat, lon) float32 249.7 249.7 249.7 ... 231.8 231.8\n    time_bnds  (season, nbnds) float64 1.958e+06 1.958e+06 ... 1.962e+06\n    air_C      (season, lat, lon) float32 -23.49 -23.49 -23.49 ... -41.3 -41.3\nAttributes:\n    Conventions:    COARDS\n    title:          mean daily NMC reanalysis (2014)\n    history:        created 2017/12 by Hoop (netCDF2.3)\n    description:    Data is from NMC initialized reanalysis\\n(4x/day).  These...\n    platform:       Model\n    References:     http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reana...\n    dataset_title:  NCEP-NCAR Reanalysis 1</pre>xarray.Dataset<ul><li>Dimensions:<ul><li>lat: 73</li><li>lon: 144</li><li>season: 4</li><li>nbnds: 2</li></ul></li><li>Coordinates: (3)<ul><li>lat(lat)float3290.0 87.5 85.0 ... -87.5 -90.0units :degrees_northactual_range :[ 90. -90.]long_name :Latitudestandard_name :latitudeaxis :Y<pre>array([ 90. ,  87.5,  85. ,  82.5,  80. ,  77.5,  75. ,  72.5,  70. ,  67.5,\n        65. ,  62.5,  60. ,  57.5,  55. ,  52.5,  50. ,  47.5,  45. ,  42.5,\n        40. ,  37.5,  35. ,  32.5,  30. ,  27.5,  25. ,  22.5,  20. ,  17.5,\n        15. ,  12.5,  10. ,   7.5,   5. ,   2.5,   0. ,  -2.5,  -5. ,  -7.5,\n       -10. , -12.5, -15. , -17.5, -20. , -22.5, -25. , -27.5, -30. , -32.5,\n       -35. , -37.5, -40. , -42.5, -45. , -47.5, -50. , -52.5, -55. , -57.5,\n       -60. , -62.5, -65. , -67.5, -70. , -72.5, -75. , -77.5, -80. , -82.5,\n       -85. , -87.5, -90. ], dtype=float32)</pre></li><li>lon(lon)float320.0 2.5 5.0 ... 352.5 355.0 357.5units :degrees_eastlong_name :Longitudeactual_range :[  0.  357.5]standard_name :longitudeaxis :X<pre>array([  0. ,   2.5,   5. ,   7.5,  10. ,  12.5,  15. ,  17.5,  20. ,  22.5,\n        25. ,  27.5,  30. ,  32.5,  35. ,  37.5,  40. ,  42.5,  45. ,  47.5,\n        50. ,  52.5,  55. ,  57.5,  60. ,  62.5,  65. ,  67.5,  70. ,  72.5,\n        75. ,  77.5,  80. ,  82.5,  85. ,  87.5,  90. ,  92.5,  95. ,  97.5,\n       100. , 102.5, 105. , 107.5, 110. , 112.5, 115. , 117.5, 120. , 122.5,\n       125. , 127.5, 130. , 132.5, 135. , 137.5, 140. , 142.5, 145. , 147.5,\n       150. , 152.5, 155. , 157.5, 160. , 162.5, 165. , 167.5, 170. , 172.5,\n       175. , 177.5, 180. , 182.5, 185. , 187.5, 190. , 192.5, 195. , 197.5,\n       200. , 202.5, 205. , 207.5, 210. , 212.5, 215. , 217.5, 220. , 222.5,\n       225. , 227.5, 230. , 232.5, 235. , 237.5, 240. , 242.5, 245. , 247.5,\n       250. , 252.5, 255. , 257.5, 260. , 262.5, 265. , 267.5, 270. , 272.5,\n       275. , 277.5, 280. , 282.5, 285. , 287.5, 290. , 292.5, 295. , 297.5,\n       300. , 302.5, 305. , 307.5, 310. , 312.5, 315. , 317.5, 320. , 322.5,\n       325. , 327.5, 330. , 332.5, 335. , 337.5, 340. , 342.5, 345. , 347.5,\n       350. , 352.5, 355. , 357.5], dtype=float32)</pre></li><li>season(season)object'DJF' 'MAM' 'JJA' 'SON'<pre>array(['DJF', 'MAM', 'JJA', 'SON'], dtype=object)</pre></li></ul></li><li>Data variables: (3)<ul><li>air(season, lat, lon)float32249.7 249.7 249.7 ... 231.8 231.8long_name :mean Daily Air temperature at sigma level 995units :degKprecision :2GRIB_id :11GRIB_name :TMPvar_desc :Air temperaturedataset :NCEP Reanalysis Daily Averagesstatistic :Meanparent_stat :Individual Obsvalid_range :[185.16 331.16]level_desc :0.995 sigmaactual_range :[191.4  318.05]new_attr :trial dataset in class<pre>array([[[249.66248, 249.66248, 249.66248, ..., 249.66248, 249.66248,\n         249.66248],\n        [249.47447, 249.43034, 249.3883 , ..., 249.59448, 249.55675,\n         249.51605],\n        [251.40558, 251.77364, 252.1219 , ..., 250.34584, 250.68887,\n         251.04605],\n        ...,\n        [246.88249, 247.04944, 247.2267 , ..., 246.61916, 246.65111,\n         246.74338],\n        [247.05777, 247.02469, 246.99976, ..., 247.2275 , 247.16055,\n         247.10136],\n        [246.13889, 246.13889, 246.13889, ..., 246.13889, 246.13889,\n         246.13889]],\n\n       [[253.25874, 253.25874, 253.25874, ..., 253.25874, 253.25874,\n         253.25874],\n        [251.96465, 251.8867 , 251.81406, ..., 252.22148, 252.13123,\n         252.04564],\n        [252.13638, 252.12886, 252.14508, ..., 252.34135, 252.24133,\n         252.16872],\n...\n        [220.36171, 220.23828, 220.18068, ..., 221.33562, 220.89696,\n         220.57715],\n        [219.63971, 219.37181, 219.12527, ..., 220.60193, 220.2584 ,\n         219.93428],\n        [218.4688 , 218.4688 , 218.4688 , ..., 218.4688 , 218.4688 ,\n         218.4688 ]],\n\n       [[260.0237 , 260.0237 , 260.0237 , ..., 260.0237 , 260.0237 ,\n         260.0237 ],\n        [258.5824 , 258.6247 , 258.6637 , ..., 258.46753, 258.50467,\n         258.54642],\n        [257.5351 , 257.7901 , 258.05328, ..., 256.922  , 257.09897,\n         257.30157],\n        ...,\n        [234.2973 , 234.38106, 234.50986, ..., 234.48547, 234.33018,\n         234.27284],\n        [233.31377, 233.17357, 233.05106, ..., 233.84811, 233.65442,\n         233.47386],\n        [231.84583, 231.84583, 231.84583, ..., 231.84583, 231.84583,\n         231.84583]]], dtype=float32)</pre></li><li>time_bnds(season, nbnds)float641.958e+06 1.958e+06 ... 1.962e+06<pre>array([[1958117.33333333, 1958141.33333333],\n       [1957284.        , 1957308.        ],\n       [1959492.        , 1959516.        ],\n       [1961688.        , 1961712.        ]])</pre></li><li>air_C(season, lat, lon)float32-23.49 -23.49 ... -41.3 -41.3<pre>array([[[-23.4875    , -23.4875    , -23.4875    , ..., -23.4875    ,\n         -23.4875    , -23.4875    ],\n        [-23.675562  , -23.719732  , -23.76167   , ..., -23.555561  ,\n         -23.593338  , -23.633894  ],\n        [-21.744452  , -21.376392  , -21.028063  , ..., -22.804173  ,\n         -22.461111  , -22.10389   ],\n        ...,\n        [-26.2675    , -26.100561  , -25.92334   , ..., -26.530838  ,\n         -26.4989    , -26.406666  ],\n        [-26.092234  , -26.125282  , -26.15028   , ..., -25.922504  ,\n         -25.98945   , -26.048609  ],\n        [-27.011114  , -27.011114  , -27.011114  , ..., -27.011114  ,\n         -27.011114  , -27.011114  ]],\n\n       [[-19.891304  , -19.891304  , -19.891304  , ..., -19.891304  ,\n         -19.891304  , -19.891304  ],\n        [-21.185331  , -21.26332   , -21.335876  , ..., -20.928526  ,\n         -21.018751  , -21.104353  ],\n        [-21.013592  , -21.021198  , -21.004896  , ..., -20.808697  ,\n         -20.908697  , -20.981255  ],\n...\n        [-52.788326  , -52.91168   , -52.969307  , ..., -51.81439   ,\n         -52.252983  , -52.572826  ],\n        [-53.510334  , -53.77825   , -54.024727  , ..., -52.5481    ,\n         -52.89159   , -53.21577   ],\n        [-54.68125   , -54.68125   , -54.68125   , ..., -54.68125   ,\n         -54.68125   , -54.68125   ]],\n\n       [[-13.126376  , -13.126376  , -13.126376  , ..., -13.126376  ,\n         -13.126376  , -13.126376  ],\n        [-14.567581  , -14.525279  , -14.486265  , ..., -14.682419  ,\n         -14.645333  , -14.603572  ],\n        [-15.614838  , -15.35989   , -15.096706  , ..., -16.228025  ,\n         -16.051104  , -15.848355  ],\n        ...,\n        [-38.852757  , -38.768967  , -38.64011   , ..., -38.664574  ,\n         -38.819782  , -38.87719   ],\n        [-39.83627   , -39.97638   , -40.09892   , ..., -39.301926  ,\n         -39.4956    , -39.6761    ],\n        [-41.304108  , -41.304108  , -41.304108  , ..., -41.304108  ,\n         -41.304108  , -41.304108  ]]], dtype=float32)</pre></li></ul></li><li>Indexes: (3)<ul><li>latPandasIndex<pre>PandasIndex(Index([ 90.0,  87.5,  85.0,  82.5,  80.0,  77.5,  75.0,  72.5,  70.0,  67.5,\n        65.0,  62.5,  60.0,  57.5,  55.0,  52.5,  50.0,  47.5,  45.0,  42.5,\n        40.0,  37.5,  35.0,  32.5,  30.0,  27.5,  25.0,  22.5,  20.0,  17.5,\n        15.0,  12.5,  10.0,   7.5,   5.0,   2.5,   0.0,  -2.5,  -5.0,  -7.5,\n       -10.0, -12.5, -15.0, -17.5, -20.0, -22.5, -25.0, -27.5, -30.0, -32.5,\n       -35.0, -37.5, -40.0, -42.5, -45.0, -47.5, -50.0, -52.5, -55.0, -57.5,\n       -60.0, -62.5, -65.0, -67.5, -70.0, -72.5, -75.0, -77.5, -80.0, -82.5,\n       -85.0, -87.5, -90.0],\n      dtype='float32', name='lat'))</pre></li><li>lonPandasIndex<pre>PandasIndex(Index([  0.0,   2.5,   5.0,   7.5,  10.0,  12.5,  15.0,  17.5,  20.0,  22.5,\n       ...\n       335.0, 337.5, 340.0, 342.5, 345.0, 347.5, 350.0, 352.5, 355.0, 357.5],\n      dtype='float32', name='lon', length=144))</pre></li><li>seasonPandasIndex<pre>PandasIndex(Index(['DJF', 'MAM', 'JJA', 'SON'], dtype='object', name='season'))</pre></li></ul></li><li>Attributes: (7)Conventions :COARDStitle :mean daily NMC reanalysis (2014)history :created 2017/12 by Hoop (netCDF2.3)description :Data is from NMC initialized reanalysis (4x/day).  These are the 0.9950 sigma level values.platform :ModelReferences :http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reanalysis.htmldataset_title :NCEP-NCAR Reanalysis 1</li></ul> In\u00a0[69]: Copied! <pre>seasonal_mean.air.plot(col=\"season\")\n</pre> seasonal_mean.air.plot(col=\"season\") Out[69]: <pre>&lt;xarray.plot.facetgrid.FacetGrid at 0x1958cccd0&gt;</pre> In\u00a0[70]: Copied! <pre># Make the figure to 2x2 plots:\nseasonal_mean.air.plot(col=\"season\", col_wrap=2);\n</pre> # Make the figure to 2x2 plots: seasonal_mean.air.plot(col=\"season\", col_wrap=2); In\u00a0[71]: Copied! <pre># Calculate zonal average\nseasonal_mean.air.mean(\"lon\").plot.line(hue=\"season\", y=\"lat\");\n</pre> # Calculate zonal average seasonal_mean.air.mean(\"lon\").plot.line(hue=\"season\", y=\"lat\"); In\u00a0[72]: Copied! <pre># resample to monthly frequency\nds.resample(time=\"M\").mean()\n</pre> # resample to monthly frequency ds.resample(time=\"M\").mean() Out[72]: <pre>&lt;xarray.Dataset&gt;\nDimensions:    (lat: 73, lon: 144, time: 12, nbnds: 2)\nCoordinates:\n  * lat        (lat) float32 90.0 87.5 85.0 82.5 ... -82.5 -85.0 -87.5 -90.0\n  * lon        (lon) float32 0.0 2.5 5.0 7.5 10.0 ... 350.0 352.5 355.0 357.5\n  * time       (time) datetime64[ns] 2023-01-31 2023-02-28 ... 2023-12-31\nDimensions without coordinates: nbnds\nData variables:\n    air        (time, lat, lon) float32 249.3 249.3 249.3 ... 250.2 250.2 250.2\n    time_bnds  (time, nbnds) float64 1.955e+06 1.955e+06 ... 1.963e+06 1.963e+06\n    air_C      (time, lat, lon) float32 -23.9 -23.9 -23.9 ... -22.92 -22.92\nAttributes:\n    Conventions:    COARDS\n    title:          mean daily NMC reanalysis (2014)\n    history:        created 2017/12 by Hoop (netCDF2.3)\n    description:    Data is from NMC initialized reanalysis\\n(4x/day).  These...\n    platform:       Model\n    References:     http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reana...\n    dataset_title:  NCEP-NCAR Reanalysis 1</pre>xarray.Dataset<ul><li>Dimensions:<ul><li>lat: 73</li><li>lon: 144</li><li>time: 12</li><li>nbnds: 2</li></ul></li><li>Coordinates: (3)<ul><li>lat(lat)float3290.0 87.5 85.0 ... -87.5 -90.0units :degrees_northactual_range :[ 90. -90.]long_name :Latitudestandard_name :latitudeaxis :Y<pre>array([ 90. ,  87.5,  85. ,  82.5,  80. ,  77.5,  75. ,  72.5,  70. ,  67.5,\n        65. ,  62.5,  60. ,  57.5,  55. ,  52.5,  50. ,  47.5,  45. ,  42.5,\n        40. ,  37.5,  35. ,  32.5,  30. ,  27.5,  25. ,  22.5,  20. ,  17.5,\n        15. ,  12.5,  10. ,   7.5,   5. ,   2.5,   0. ,  -2.5,  -5. ,  -7.5,\n       -10. , -12.5, -15. , -17.5, -20. , -22.5, -25. , -27.5, -30. , -32.5,\n       -35. , -37.5, -40. , -42.5, -45. , -47.5, -50. , -52.5, -55. , -57.5,\n       -60. , -62.5, -65. , -67.5, -70. , -72.5, -75. , -77.5, -80. , -82.5,\n       -85. , -87.5, -90. ], dtype=float32)</pre></li><li>lon(lon)float320.0 2.5 5.0 ... 352.5 355.0 357.5units :degrees_eastlong_name :Longitudeactual_range :[  0.  357.5]standard_name :longitudeaxis :X<pre>array([  0. ,   2.5,   5. ,   7.5,  10. ,  12.5,  15. ,  17.5,  20. ,  22.5,\n        25. ,  27.5,  30. ,  32.5,  35. ,  37.5,  40. ,  42.5,  45. ,  47.5,\n        50. ,  52.5,  55. ,  57.5,  60. ,  62.5,  65. ,  67.5,  70. ,  72.5,\n        75. ,  77.5,  80. ,  82.5,  85. ,  87.5,  90. ,  92.5,  95. ,  97.5,\n       100. , 102.5, 105. , 107.5, 110. , 112.5, 115. , 117.5, 120. , 122.5,\n       125. , 127.5, 130. , 132.5, 135. , 137.5, 140. , 142.5, 145. , 147.5,\n       150. , 152.5, 155. , 157.5, 160. , 162.5, 165. , 167.5, 170. , 172.5,\n       175. , 177.5, 180. , 182.5, 185. , 187.5, 190. , 192.5, 195. , 197.5,\n       200. , 202.5, 205. , 207.5, 210. , 212.5, 215. , 217.5, 220. , 222.5,\n       225. , 227.5, 230. , 232.5, 235. , 237.5, 240. , 242.5, 245. , 247.5,\n       250. , 252.5, 255. , 257.5, 260. , 262.5, 265. , 267.5, 270. , 272.5,\n       275. , 277.5, 280. , 282.5, 285. , 287.5, 290. , 292.5, 295. , 297.5,\n       300. , 302.5, 305. , 307.5, 310. , 312.5, 315. , 317.5, 320. , 322.5,\n       325. , 327.5, 330. , 332.5, 335. , 337.5, 340. , 342.5, 345. , 347.5,\n       350. , 352.5, 355. , 357.5], dtype=float32)</pre></li><li>time(time)datetime64[ns]2023-01-31 ... 2023-12-31long_name :Timedelta_t :0000-00-01 00:00:00standard_name :timeaxis :Tavg_period :0000-00-01 00:00:00coordinate_defines :startactual_range :[1954776. 1963512.]<pre>array(['2023-01-31T00:00:00.000000000', '2023-02-28T00:00:00.000000000',\n       '2023-03-31T00:00:00.000000000', '2023-04-30T00:00:00.000000000',\n       '2023-05-31T00:00:00.000000000', '2023-06-30T00:00:00.000000000',\n       '2023-07-31T00:00:00.000000000', '2023-08-31T00:00:00.000000000',\n       '2023-09-30T00:00:00.000000000', '2023-10-31T00:00:00.000000000',\n       '2023-11-30T00:00:00.000000000', '2023-12-31T00:00:00.000000000'],\n      dtype='datetime64[ns]')</pre></li></ul></li><li>Data variables: (3)<ul><li>air(time, lat, lon)float32249.3 249.3 249.3 ... 250.2 250.2long_name :mean Daily Air temperature at sigma level 995units :degKprecision :2GRIB_id :11GRIB_name :TMPvar_desc :Air temperaturedataset :NCEP Reanalysis Daily Averagesstatistic :Meanparent_stat :Individual Obsvalid_range :[185.16 331.16]level_desc :0.995 sigmaactual_range :[191.4  318.05]new_attr :trial dataset in class<pre>array([[[249.25404, 249.25404, 249.25404, ..., 249.25404, 249.25404,\n         249.25404],\n        [250.1645 , 250.11533, 250.06937, ..., 250.28467, 250.24837,\n         250.20566],\n        [252.17662, 252.6492 , 253.10486, ..., 250.85965, 251.27663,\n         251.72337],\n        ...,\n        [248.71613, 248.8895 , 249.06369, ..., 248.43631, 248.47179,\n         248.57176],\n        [249.34111, 249.29839, 249.2702 , ..., 249.52336, 249.45242,\n         249.39192],\n        [248.15158, 248.15158, 248.15158, ..., 248.15158, 248.15158,\n         248.15158]],\n\n       [[245.69106, 245.69106, 245.69106, ..., 245.69106, 245.69106,\n         245.69106],\n        [244.88034, 244.76427, 244.65627, ..., 245.25356, 245.12854,\n         245.00537],\n        [247.7393 , 248.01787, 248.28928, ..., 247.01872, 247.24197,\n         247.48215],\n...\n        [246.80746, 246.93416, 247.06586, ..., 246.63998, 246.6442 ,\n         246.70418],\n        [245.22916, 245.14754, 245.07668, ..., 245.55415, 245.43668,\n         245.325  ],\n        [243.23   , 243.23   , 243.23   , ..., 243.23   , 243.23   ,\n         243.23   ]],\n\n       [[253.65807, 253.65807, 253.65807, ..., 253.65807, 253.65807,\n         253.65807],\n        [252.93388, 252.95966, 252.98146, ..., 252.82494, 252.86449,\n         252.90082],\n        [253.94598, 254.29033, 254.60078, ..., 252.83708, 253.21451,\n         253.58792],\n        ...,\n        [252.20403, 252.33546, 252.45724, ..., 251.92905, 251.98788,\n         252.08304],\n        [250.57176, 250.50484, 250.4395 , ..., 250.84596, 250.74434,\n         250.65242],\n        [250.22662, 250.22662, 250.22662, ..., 250.22662, 250.22662,\n         250.22662]]], dtype=float32)</pre></li><li>time_bnds(time, nbnds)float641.955e+06 1.955e+06 ... 1.963e+06<pre>array([[1955136., 1955160.],\n       [1955844., 1955868.],\n       [1956552., 1956576.],\n       [1957284., 1957308.],\n       [1958016., 1958040.],\n       [1958748., 1958772.],\n       [1959480., 1959504.],\n       [1960224., 1960248.],\n       [1960956., 1960980.],\n       [1961688., 1961712.],\n       [1962420., 1962444.],\n       [1963152., 1963176.]])</pre></li><li>air_C(time, lat, lon)float32-23.9 -23.9 -23.9 ... -22.92 -22.92<pre>array([[[-23.89597 , -23.89597 , -23.89597 , ..., -23.89597 ,\n         -23.89597 , -23.89597 ],\n        [-22.985489, -23.034681, -23.080648, ..., -22.86533 ,\n         -22.901627, -22.94436 ],\n        [-20.973396, -20.500813, -20.045166, ..., -22.29033 ,\n         -21.87339 , -21.426617],\n        ...,\n        [-24.43388 , -24.26049 , -24.086296, ..., -24.71372 ,\n         -24.678234, -24.578232],\n        [-23.80888 , -23.851618, -23.879847, ..., -23.62662 ,\n         -23.697588, -23.758068],\n        [-24.998394, -24.998394, -24.998394, ..., -24.998394,\n         -24.998394, -24.998394]],\n\n       [[-27.458937, -27.458937, -27.458937, ..., -27.458937,\n         -27.458937, -27.458937],\n        [-28.269644, -28.385715, -28.493748, ..., -27.896435,\n         -28.021433, -28.14465 ],\n        [-25.41072 , -25.132145, -24.86072 , ..., -26.131254,\n         -25.908037, -25.66786 ],\n...\n        [-26.3425  , -26.215832, -26.084166, ..., -26.510004,\n         -26.505836, -26.445837],\n        [-27.920837, -28.002506, -28.073338, ..., -27.595842,\n         -27.71334 , -27.825006],\n        [-29.920004, -29.920004, -29.920004, ..., -29.920004,\n         -29.920004, -29.920004]],\n\n       [[-19.49194 , -19.49194 , -19.49194 , ..., -19.49194 ,\n         -19.49194 , -19.49194 ],\n        [-20.216139, -20.190327, -20.168552, ..., -20.325006,\n         -20.285484, -20.2492  ],\n        [-19.204035, -18.859686, -18.549198, ..., -20.31291 ,\n         -19.93549 , -19.562101],\n        ...,\n        [-20.945976, -20.814516, -20.692747, ..., -21.22097 ,\n         -21.162102, -21.066942],\n        [-22.578236, -22.645164, -22.71049 , ..., -22.304039,\n         -22.405651, -22.497585],\n        [-22.923388, -22.923388, -22.923388, ..., -22.923388,\n         -22.923388, -22.923388]]], dtype=float32)</pre></li></ul></li><li>Indexes: (3)<ul><li>latPandasIndex<pre>PandasIndex(Index([ 90.0,  87.5,  85.0,  82.5,  80.0,  77.5,  75.0,  72.5,  70.0,  67.5,\n        65.0,  62.5,  60.0,  57.5,  55.0,  52.5,  50.0,  47.5,  45.0,  42.5,\n        40.0,  37.5,  35.0,  32.5,  30.0,  27.5,  25.0,  22.5,  20.0,  17.5,\n        15.0,  12.5,  10.0,   7.5,   5.0,   2.5,   0.0,  -2.5,  -5.0,  -7.5,\n       -10.0, -12.5, -15.0, -17.5, -20.0, -22.5, -25.0, -27.5, -30.0, -32.5,\n       -35.0, -37.5, -40.0, -42.5, -45.0, -47.5, -50.0, -52.5, -55.0, -57.5,\n       -60.0, -62.5, -65.0, -67.5, -70.0, -72.5, -75.0, -77.5, -80.0, -82.5,\n       -85.0, -87.5, -90.0],\n      dtype='float32', name='lat'))</pre></li><li>lonPandasIndex<pre>PandasIndex(Index([  0.0,   2.5,   5.0,   7.5,  10.0,  12.5,  15.0,  17.5,  20.0,  22.5,\n       ...\n       335.0, 337.5, 340.0, 342.5, 345.0, 347.5, 350.0, 352.5, 355.0, 357.5],\n      dtype='float32', name='lon', length=144))</pre></li><li>timePandasIndex<pre>PandasIndex(DatetimeIndex(['2023-01-31', '2023-02-28', '2023-03-31', '2023-04-30',\n               '2023-05-31', '2023-06-30', '2023-07-31', '2023-08-31',\n               '2023-09-30', '2023-10-31', '2023-11-30', '2023-12-31'],\n              dtype='datetime64[ns]', name='time', freq='M'))</pre></li></ul></li><li>Attributes: (7)Conventions :COARDStitle :mean daily NMC reanalysis (2014)history :created 2017/12 by Hoop (netCDF2.3)description :Data is from NMC initialized reanalysis (4x/day).  These are the 0.9950 sigma level values.platform :ModelReferences :http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reanalysis.htmldataset_title :NCEP-NCAR Reanalysis 1</li></ul> In\u00a0[73]: Copied! <pre>ds.resample(time=\"M\").mean().mean(dim =['lat','lon']).air.plot()\n</pre> ds.resample(time=\"M\").mean().mean(dim =['lat','lon']).air.plot() Out[73]: <pre>[&lt;matplotlib.lines.Line2D at 0x195ddcfd0&gt;]</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> <p>In this assignment, we will use Xarray to analyze top-of-atmosphere radiation data from NASA's CERES project.</p> <p> Public domain, by NASA, from Wikimedia Commons</p> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> <p>The answer is that each \"pixel\" or \"grid point\" of this dataset does not represent an equal area of Earth's surface. So naively taking the mean, i.e. giving equal weight to each point, gives the wrong answer.</p> <p>On a lat / lon grid, the relative area of each grid point is proportional to $\\cos(\\lambda)$. ($\\lambda$ is latitude)</p> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"Week_9_Xarray/#week-9-xarray-for-multidimensional-gridded-data","title":"Week 9: Xarray for multidimensional gridded data\u00b6","text":"<p>In previous lecture, we saw how Pandas provided a way to keep track of additional \"metadata\" surrounding tabular datasets, including \"indexes\" for each row and labels for each column. These features, together with Pandas' many useful routines for all kinds of data munging and analysis, have made Pandas one of the most popular python packages in the world.</p> <p>However, not all environmental science datasets easily fit into the \"tabular\" model (i.e. rows and columns) imposed by Pandas. In particular, we often deal with multidimensional data. By multidimensional data (also often called N-dimensional), I mean data with many independent dimensions or axes. For example, we might represent Earth's surface temperature $T$ as a three dimensional variable</p> <p>$$ T(x, y, t) $$</p> <p>where $x$ is longitude, $y$ is latitude, and $t$ is time.</p> <p>The point of xarray is to provide pandas-level convenience for working with this type of data.</p>"},{"location":"Week_9_Xarray/#1-what-is-xarray","title":"1. What is Xarray?\u00b6","text":""},{"location":"Week_9_Xarray/#11-xarray-data-model","title":"1.1 Xarray data model\u00b6","text":""},{"location":"Week_9_Xarray/#12-xarray-functionality","title":"1.2 Xarray functionality\u00b6","text":""},{"location":"Week_9_Xarray/#13-xarray-data-structures","title":"1.3 Xarray data structures\u00b6","text":"<p>Like Pandas, xarray has two fundamental data structures:</p> <ul> <li>a <code>DataArray</code>, which holds a single multi-dimensional variable and its coordinates</li> <li>a <code>Dataset</code>, which holds multiple variables that potentially share the same coordinates</li> </ul>"},{"location":"Week_9_Xarray/#14-import-xarray-packages","title":"1.4 Import Xarray packages\u00b6","text":""},{"location":"Week_9_Xarray/#2-exploring-xarray-data-structure","title":"2. Exploring Xarray data structure\u00b6","text":"<p>Array data can be stored in the following standard formats:</p> <ul> <li>Hierarchical Data Format (HDF5) - Container for many arrays</li> <li>Network Common Data Form (NetCDF) - Container for many arrays which conform to the NetCDF data model</li> <li>Zarr - New cloud-optimized format for array storage</li> </ul>"},{"location":"Week_9_Xarray/#21-reading-xarray-data","title":"2.1 Reading Xarray data\u00b6","text":""},{"location":"Week_9_Xarray/#22-what-is-included-in-xarray-dataset","title":"2.2 What is included in xarray <code>Dataset</code>?\u00b6","text":"<p>The output consists of:</p> <ul> <li>a summary of all dimensions of the <code>Dataset</code> <code>(time: 365, lat: 73, lon: 144)</code>: this tells us that the first dimension is named <code>time</code> and has a size of <code>365</code>, the second dimension is named <code>lat</code> and has a size of <code>73</code>, and the third dimension is named <code>lon</code> and has a size of <code>365</code>. Because we will access the dimensions by name, the order doesn't matter.</li> <li>an unordered list of coordinates or dimensions with coordinates with one item per line. Each item has a name, one or more dimensions in parentheses, a dtype and a preview of the values.</li> <li>an alphabetically sorted list of dimensions without coordinates (if there are any)</li> <li>an unordered list of attributes, or metadata</li> </ul>"},{"location":"Week_9_Xarray/#dataarray","title":"DataArray\u00b6","text":"<p>The <code>DataArray</code> class consists of an array (data) and its associated dimension names, labels, and attributes (metadata).</p>"},{"location":"Week_9_Xarray/#named-dimensions","title":"Named dimensions\u00b6","text":"<p><code>.dims</code> are the named axes of your data. They may (dimension coordinates) or may not (dimensions without coordinates) have associated values.</p> <p>In this case we have 2 spatial dimensions (<code>latitude</code> and <code>longitude</code> are stored with shorthand names <code>lat</code> and <code>lon</code>) and one temporal dimension (<code>time</code>).</p>"},{"location":"Week_9_Xarray/#coordinates","title":"Coordinates\u00b6","text":"<p><code>.coords</code> is a simple dict-like data container for mapping coordinate names to values.</p> <p>Here we see the actual timestamps and spatial positions of our air temperature data:</p>"},{"location":"Week_9_Xarray/#attributes","title":"Attributes\u00b6","text":"<p><code>.attrs</code> is a dictionary that can contain arbitrary Python objects (strings, lists, integers, dictionaries, etc.) containing information about your data. Your only limitation is that some attributes may not be writeable to certain file formats.</p>"},{"location":"Week_9_Xarray/#3-working-with-labelled-data","title":"3. Working with Labelled Data\u00b6","text":"<p>Xarray's labels make working with multidimensional data much easier. Metadata provides context and provides code that is more legible. This reduces the likelihood of errors from typos and makes analysis more intuitive and fun!</p>"},{"location":"Week_9_Xarray/#31-plot-labelled-data","title":"3.1 Plot labelled data\u00b6","text":""},{"location":"Week_9_Xarray/#32-selecting-data-indexing","title":"3.2 Selecting Data (Indexing)\u00b6","text":"<p>We can always use regular numpy indexing and slicing on DataArrays</p>"},{"location":"Week_9_Xarray/#321-position-based-indexing","title":"3.2.1 Position-based Indexing\u00b6","text":"<p>Indexing a <code>DataArray</code> directly works (mostly) just like it does for numpy <code>ndarrays</code>, except that the returned object is always another <code>DataArray</code>:</p> <p>This approach however does not take advantage of the dimension names and coordinate location information that is present in a Xarray object.</p>"},{"location":"Week_9_Xarray/#322-positional-indexing-using-dimension-names","title":"3.2.2 Positional Indexing Using Dimension Names\u00b6","text":""},{"location":"Week_9_Xarray/#323-label-based-indexing","title":"3.2.3 Label-based Indexing\u00b6","text":"<p>To select data by coordinate labels instead of integer indices we can use <code>sel</code> instead of <code>isel</code>:</p>"},{"location":"Week_9_Xarray/#324-nearest-neighbor-lookups","title":"3.2.4 Nearest Neighbor Lookups\u00b6","text":"<p>The label based selection methods <code>sel()</code> support <code>method</code> and <code>tolerance</code> keyword argument. The <code>method</code> parameter allows for enabling nearest neighbor (inexact) lookups by use of the methods <code>ffill</code> (propagate last valid index forward), <code>backfill</code> or <code>nearest</code>:</p>"},{"location":"Week_9_Xarray/#exercise-1-select-and-plot-the-air-temperature-of-new-brunswicknj-465653-n-664619-w","title":"Exercise 1: Select and plot the air temperature of New Brunswick,NJ (46.5653\u00b0 N, 66.4619\u00b0 W).\u00b6","text":"<p>Note: You will need to convert western degrees to a degree ranging from 0 to 360, subtract it from 360.</p>"},{"location":"Week_9_Xarray/#33-datetime-indexing","title":"3.3 Datetime Indexing\u00b6","text":"<p>Datetime indexing is a critical feature when working with time series data, which is a common occurrence in environmental sciences. Essentially, datetime indexing allows you to select data points or a series of data points that correspond to certain date or time criteria. This becomes essential for time-series analysis where the date or time information associated with each data point can be as critical as the data point itself.</p> <p>Let's see some of the techniques to perform datetime indexing in Xarray:</p>"},{"location":"Week_9_Xarray/#331-selecting-data-based-on-single-datetime","title":"3.3.1 Selecting data based on single datetime\u00b6","text":"<p>Let's say we have a Dataset ds and we want to select data at a particular date and time, for instance, '2013-01-01' at 6AM. We can do this by using the <code>sel</code> (select) method, like so:</p>"},{"location":"Week_9_Xarray/#332-selecting-data-for-a-range-of-dates","title":"3.3.2 Selecting data for a range of dates\u00b6","text":"<p>Now, let's say we want to select data between a certain range of dates. We can still use the <code>sel</code> method, but this time we will combine it with slice:</p>"},{"location":"Week_9_Xarray/#333-indexing-with-a-datetimeindex-or-date-string-list","title":"3.3.3 Indexing with a DatetimeIndex or date string list\u00b6","text":"<p>Another technique is to use a list of datetime objects or date strings for indexing. For example, you could select data for specific, non-contiguous dates like this:</p>"},{"location":"Week_9_Xarray/#334-fancy-indexing-based-on-year-month-day-or-other-datetime-components","title":"3.3.4 Fancy indexing based on year, month, day, or other datetime components\u00b6","text":"<p>In addition to the basic datetime indexing techniques, Xarray also supports \"fancy\" indexing options, which can provide more flexibility and efficiency in your data analysis tasks. You can directly access datetime components such as year, month, day, hour, day of week, etc. using the <code>.dt</code> accessor. Here is an example of selecting all data points from July across all years:</p>"},{"location":"Week_9_Xarray/#exercise-2-select-all-data-on-sunday-only","title":"Exercise 2: Select all data on Sunday only.\u00b6","text":"<p>Hint: Use the dayofweek function.</p>"},{"location":"Week_9_Xarray/#4-xarray-computation","title":"4. Xarray Computation\u00b6","text":""},{"location":"Week_9_Xarray/#41-arithmetic-operations","title":"4.1 Arithmetic Operations\u00b6","text":""},{"location":"Week_9_Xarray/#42-broadcasting-expanding-data","title":"4.2 Broadcasting: expanding data\u00b6","text":""},{"location":"Week_9_Xarray/#5-xarray-groupby-and-resample","title":"5. Xarray Groupby and Resample\u00b6","text":""},{"location":"Week_9_Xarray/#51-groupby","title":"5.1 groupby\u00b6","text":"<p>We learned groupby in pandas, which can similary be applied to Xarray.</p>"},{"location":"Week_9_Xarray/#52-resample","title":"5.2 Resample\u00b6","text":""},{"location":"Week_9_Xarray/#exercise-3-make-a-time-series-plot-of-the-monthly-mean-temperature-over-northern-hemisphere","title":"Exercise 3: Make a time series plot of the monthly mean temperature over Northern Hemisphere.\u00b6","text":""},{"location":"Week_9_Xarray/#6-assignment","title":"6. Assignment\u00b6","text":""},{"location":"Week_9_Xarray/#61-open-the-dataset-ceres_ebaf-toa_edition40_200003-201701nc-and-display-its-contents","title":"6.1 Open the dataset ('CERES_EBAF-TOA_Edition4.0_200003-201701.nc') and display its contents.\u00b6","text":""},{"location":"Week_9_Xarray/#62-print-out-the-long_name-attribute-of-each-variable","title":"6.2 Print out the <code>long_name</code> attribute of each variable\u00b6","text":""},{"location":"Week_9_Xarray/#63-calculate-the-time-mean-of-the-entire-dataset","title":"6.3 Calculate the time-mean of the entire dataset\u00b6","text":""},{"location":"Week_9_Xarray/#64-from-63-make-a-2d-plot-of-the-the-time-mean-toa-longwave-shortwave-and-incoming-solar-radiation-flux","title":"6.4 From 6.3, make a 2D plot of the the time-mean TOA longwave, shortwave, and incoming solar radiation flux\u00b6","text":"<p>(All-Sky conditions)</p> <p>Note the sign conventions on each variable.</p>"},{"location":"Week_9_Xarray/#65-add-up-the-three-variables-above-and-verify-visually-that-they-are-equivalent-to-the-toa-net-flux","title":"6.5 Add up the three variables above and verify (visually) that they are equivalent to the TOA net flux\u00b6","text":"<p>You have to pay attention to and think about the sign conventions for each variable in order to get this to work.</p>"},{"location":"Week_9_Xarray/#66-calculate-the-global-mean-of-toa-net-radiation-directly-from-the-dataset","title":"6.6 Calculate the global mean of TOA net radiation directly from the dataset\u00b6","text":"<p>Since the Earth is approximately in radiative balance, the net TOA radiation should be zero. But taking the naive mean from this dataset, you should find a number far from zero. Why?</p>"},{"location":"Week_9_Xarray/#67-create-a-weight-array-proportional-to-coslambda-with-a-mean-value-of-1","title":"6.7 Create a <code>weight</code> array proportional to $\\cos(\\lambda)$ with a mean value of 1\u00b6","text":"<p>Verify its mean is 1 and plot it. Be careful about radians vs. degrees.</p>"},{"location":"Week_9_Xarray/#68-redo-your-global-mean-toa-net-radiation-calculation-with-this-weight-factor","title":"6.8 Redo your global mean TOA net radiation calculation with this weight factor\u00b6","text":"<p>Remember Xarray's handling of broadcasting. Don't make this harder than it needs to be.</p>"},{"location":"Week_9_Xarray/#69-plot-the-time-mean-cloud-area-fraction-day-and-night","title":"6.9 Plot the time-mean cloud area fraction (day and night)\u00b6","text":""},{"location":"Week_9_Xarray/#610-define-boolean-masks-for-low-cloud-area-le-25-and-high-cloud-area-ge-75","title":"6.10 Define boolean masks for low cloud area ($\\le$ 25%) and high cloud area ($\\ge$ 75%)\u00b6","text":"<p>Use the whole dataset, not the time mean.</p>"},{"location":"Week_9_Xarray/#611-calculate-and-plot-composites-of-time-mean-outgoing-shortwave-radiation-for-low-and-high-cloud-area-regions","title":"6.11 Calculate and plot composites of time-mean outgoing shortwave radiation for low and high cloud area regions\u00b6","text":"<p>Your results should be 2D maps.</p> <p>Xarray's where function will be helpful.</p>"},{"location":"Week_9_Xarray/#612-subset-the-dataset-for-nj-region-74-w-756-w-388-n-415-n-and-calculate-the-monthly-climatology-of-cloud-area-fraction","title":"6.12 Subset the dataset for NJ region (74\u02daW - 75.6\u02daW, 38.8\u02daN - 41.5\u02daN) and calculate the monthly climatology of cloud area fraction\u00b6","text":""}]}